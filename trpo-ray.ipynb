{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of trpo-ray.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/denklewer/ray-custom-agents/blob/master/trpo-ray.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAGWDBl0Cxk6",
        "colab_type": "code",
        "outputId": "87e6980f-4929-444b-b97f-ce1b301b3988",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47161
        }
      },
      "source": [
        "!sudo apt-get install -y build-essential curl unzip psmisc\n",
        "!pip install cython==0.29.0\n",
        "!git clone https://github.com/ray-project/ray.git\n",
        "!ray/ci/travis/install-bazel.sh\n",
        "!pip install lz4\n",
        "!pip install setproctitle\n",
        "!mv ray ray-distr\n",
        "!pip install -e ray-distr/python/. --verbose  # Add --user if you see a permission denied error."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.4ubuntu1).\n",
            "unzip is already the newest version (6.0-21ubuntu1).\n",
            "curl is already the newest version (7.58.0-2ubuntu3.6).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  psmisc\n",
            "0 upgraded, 1 newly installed, 0 to remove and 7 not upgraded.\n",
            "Need to get 52.5 kB of archives.\n",
            "After this operation, 266 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 psmisc amd64 23.1-1ubuntu0.1 [52.5 kB]\n",
            "Fetched 52.5 kB in 0s (114 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package psmisc.\n",
            "(Reading database ... 130824 files and directories currently installed.)\n",
            "Preparing to unpack .../psmisc_23.1-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking psmisc (23.1-1ubuntu0.1) ...\n",
            "Setting up psmisc (23.1-1ubuntu0.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting cython==0.29.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/3f/cac281f3f019b825bbc03fa8cb7eb03d9c355f4aa9eef978279a4966cb21/Cython-0.29-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 2.8MB/s \n",
            "\u001b[?25hInstalling collected packages: cython\n",
            "  Found existing installation: Cython 0.29.7\n",
            "    Uninstalling Cython-0.29.7:\n",
            "      Successfully uninstalled Cython-0.29.7\n",
            "Successfully installed cython-0.29\n",
            "Cloning into 'ray'...\n",
            "remote: Enumerating objects: 37802, done.\u001b[K\n",
            "remote: Total 37802 (delta 0), reused 0 (delta 0), pack-reused 37802\u001b[K\n",
            "Receiving objects: 100% (37802/37802), 21.74 MiB | 29.57 MiB/s, done.\n",
            "Resolving deltas: 100% (25611/25611), done.\n",
            "Platform is linux.\n",
            "--2019-05-19 20:23:36--  https://github.com/bazelbuild/bazel/releases/download/0.21.0/bazel-0.21.0-installer-linux-x86_64.sh\n",
            "Resolving github.com (github.com)... 192.30.253.112\n",
            "Connecting to github.com (github.com)|192.30.253.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/20773773/a9ccd400-039e-11e9-8d60-728c955d8b00?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20190519%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20190519T202336Z&X-Amz-Expires=300&X-Amz-Signature=56a74596222724a828b3ab4a31ae6763a6923f48a2f06c267c90831e5de88bf2&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dbazel-0.21.0-installer-linux-x86_64.sh&response-content-type=application%2Foctet-stream [following]\n",
            "--2019-05-19 20:23:36--  https://github-production-release-asset-2e65be.s3.amazonaws.com/20773773/a9ccd400-039e-11e9-8d60-728c955d8b00?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20190519%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20190519T202336Z&X-Amz-Expires=300&X-Amz-Signature=56a74596222724a828b3ab4a31ae6763a6923f48a2f06c267c90831e5de88bf2&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dbazel-0.21.0-installer-linux-x86_64.sh&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.102.83\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.102.83|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168600313 (161M) [application/octet-stream]\n",
            "Saving to: ‘install.sh’\n",
            "\n",
            "install.sh          100%[===================>] 160.79M  98.4MB/s    in 1.6s    \n",
            "\n",
            "2019-05-19 20:23:38 (98.4 MB/s) - ‘install.sh’ saved [168600313/168600313]\n",
            "\n",
            "Bazel installer\n",
            "---------------\n",
            "\n",
            "Bazel is bundled with software licensed under the GPLv2 with Classpath exception.\n",
            "You can find the sources next to the installer on our release page:\n",
            "   https://github.com/bazelbuild/bazel/releases\n",
            "\n",
            "# Release 0.21.0 (2018-12-19)\n",
            "\n",
            "Baseline: cb9b2afbba3f8d3a1db8bf68e65d06f1b36902f5\n",
            "\n",
            "Cherry picks:\n",
            "\n",
            "   + 12b96466ee0d6ab83f7d4cd24be110bb5021281d:\n",
            "     Windows, test wrapper: rename the associated flag\n",
            "   + 7fc967c4d6435de2bb4e34aac00ca2e499f55fca:\n",
            "     Use a fixed thread pool in ByteStreamBuildEventArtifactUploader\n",
            "   + 798b9a989aa793655d29504edb5fb85f3143db84:\n",
            "     Add --build_event_upload_max_threads option\n",
            "   + dbe05df23ccf4c919379e0294e0701fd3f66739c:\n",
            "     Update the version of  skylib bundled in the distfile\n",
            "\n",
            "Incompatible changes:\n",
            "\n",
            "  - The --experimental_stl command line option is removed.\n",
            "  - aquery defaults to human readable output format.\n",
            "\n",
            "New features:\n",
            "\n",
            "  - repository_ctx.download and repository_ctx.download_and_extract\n",
            "    now return a struct.\n",
            "  - Android Databinding v2 can be enabled with\n",
            "    --experimental_android_databinding_v2.\n",
            "\n",
            "Important changes:\n",
            "\n",
            "  - The deprecated and unmaintained Docker rules in\n",
            "    tools/build_defs/docker were removed. Please use\n",
            "    https://github.com/bazelbuild/rules_docker instead.\n",
            "  - The new --upload_query_output_using_bep query/cquery/aquery flag\n",
            "    causes query outputs to be uploaded via BEP.\n",
            "  - New incompatible flag --incompatible_strict_argument_ordering\n",
            "  - --strict_android_deps and --strict_java_deps were renamed to\n",
            "    --experimental_strict_java_deps\n",
            "  - config_settings that select on \"compiler\" value instead of values\n",
            "    = {\"compiler\" : \"x\"} should use flag_values =\n",
            "    {\"@bazel_tools//tools/cpp:compiler\": \"x\"}.\n",
            "  - The new --upload_query_output_using_bep query/cquery/aquery flag\n",
            "    causes query outputs to be uploaded via BEP.\n",
            "  - Turn on --incompatible_disable_sysroot_from_configuration\n",
            "  - We revamped our Android with Bazel tutorial! Check it out\n",
            "    [here](https://docs.bazel.build/versions/master/tutorial/android-a\n",
            "    pp.html).\n",
            "  - --incompatible_disallow_slash_operator is now on by default\n",
            "  - Enable --experimental_check_desugar_deps by default.  This flag\n",
            "    rules out several types of invalid Android builds at compile-time.\n",
            "  - The --max_config_changes_to_show option lists the names of\n",
            "    options which\n",
            "    have changed and thus caused the analysis cache to be dropped.\n",
            "  - The --experimental_strict_action_env option has been renamed to\n",
            "    --incompatible_strict_action_env and is now on by default. This\n",
            "    means Bazel will no longer use the client's PATH and\n",
            "    LD_LIBRARY_PATH environmental variables in the default action\n",
            "    environment. If the old behavior is desired, pass\n",
            "    --action_env=PATH and --action_env=LD_LIBRARY_PATH.\n",
            "    --noincompatible_strict_action_env will also temporarily restore\n",
            "    the old behavior. However, as --action_env is a more general and\n",
            "    explicit way to pass client environmental variables into actions,\n",
            "    --noincompatible_strict_action_env will eventually be deprecated\n",
            "    and removed. See #6648 for more details.\n",
            "  - XCRUNWRAPPER_LABEL has been removed. If you used this value\n",
            "    before, please use @bazel_tools//tools/objc:xcrunwrapper instead.\n",
            "  - --incompatible_static_name_resolution is no unable by default\n",
            "  - We will phase out --genrule_strategy in favor of\n",
            "    --strategy=Genrule=<value> (for genrules) or\n",
            "    --spawn_strategy=<value> (for all actions).\n",
            "  - --incompatible_package_name_is_a_function is now enabled by\n",
            "    default\n",
            "  - Dynamic execution is now available with\n",
            "    --experimental_spawn_strategy. Dynamic execution allows a build\n",
            "    action to run locally and remotely simultaneously, and Bazel\n",
            "    picks the fastest action. This provides the best of both worlds:\n",
            "    faster clean builds than pure local builds, and faster\n",
            "    incremental builds than pure remote builds.\n",
            "  - --incompatible_package_name_is_a_function is now enabled by\n",
            "    default\n",
            "  - New incompatible flag --incompatible_merge_genfiles_directory\n",
            "  - grpc log now logs updateActionResult\n",
            "  - CppConfiguration doesn't do package loading anymore. That means:\n",
            "    * it's no longer needed to have C++ toolchain available when\n",
            "    building non-C++ projects\n",
            "    * bazel will not analyze C++ toolchain when not needed -> speedup\n",
            "    ~2s on bazel startup when C++ rules using hermetic toolchain are\n",
            "    not loaded\n",
            "  - --incompatible_package_name_is_a_fu...\n",
            "\n",
            "This release contains contributions from many people at Google, as well as andy g scott ?, Attila Ol?h, Benjamin Peterson, Clint Harrison, Dave Lee, Ed Schouten, Greg Estren, Gregor Jasny, Jamie Snape, Jerry Marino, Loo Rong Jie, Or Shachar, Sevki Hasirci, William Chargin.\n",
            "\n",
            "## Build informations\n",
            "   - [Commit](https://github.com/bazelbuild/bazel/commit/defd737)\n",
            "Uncompressing.......\n",
            "\n",
            "Bazel is now installed!\n",
            "\n",
            "Make sure you have \"/root/bin\" in your path. You can also activate bash\n",
            "completion by adding the following line to your ~/.bashrc:\n",
            "  source /root/.bazel/bin/bazel-complete.bash\n",
            "\n",
            "See http://bazel.build/docs/getting-started.html to start a new project!\n",
            "Collecting lz4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/83/fe/66da85ed881031de7cf7de9dd38cc98aec8859824c7bcd3e8a88d255f36d/lz4-2.1.6-cp36-cp36m-manylinux1_x86_64.whl (359kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 2.8MB/s \n",
            "\u001b[?25hInstalling collected packages: lz4\n",
            "Successfully installed lz4-2.1.6\n",
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-o1u_wivd\n",
            "Created temporary directory: /tmp/pip-req-tracker-yv1_hsbl\n",
            "Created requirements tracker '/tmp/pip-req-tracker-yv1_hsbl'\n",
            "Created temporary directory: /tmp/pip-install-iry5rdah\n",
            "Obtaining file:///content/ray-distr/python\n",
            "  Added file:///content/ray-distr/python to build tracker '/tmp/pip-req-tracker-yv1_hsbl'\n",
            "    Running setup.py (path:/content/ray-distr/python/setup.py) egg_info for package from file:///content/ray-distr/python\n",
            "    Running command python setup.py egg_info\n",
            "    running egg_info\n",
            "    creating ray.egg-info\n",
            "    writing ray.egg-info/PKG-INFO\n",
            "    writing dependency_links to ray.egg-info/dependency_links.txt\n",
            "    writing entry points to ray.egg-info/entry_points.txt\n",
            "    writing requirements to ray.egg-info/requires.txt\n",
            "    writing top-level names to ray.egg-info/top_level.txt\n",
            "    writing manifest file 'ray.egg-info/SOURCES.txt'\n",
            "    writing manifest file 'ray.egg-info/SOURCES.txt'\n",
            "  Source in ./ray-distr/python has version 0.7.0, which satisfies requirement ray==0.7.0 from file:///content/ray-distr/python\n",
            "  Removed ray==0.7.0 from file:///content/ray-distr/python from build tracker '/tmp/pip-req-tracker-yv1_hsbl'\n",
            "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.6/dist-packages (from ray==0.7.0) (1.16.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from ray==0.7.0) (3.0.10)\n",
            "Collecting funcsigs (from ray==0.7.0)\n",
            "  1 location(s) to search for versions of funcsigs:\n",
            "  * https://pypi.org/simple/funcsigs/\n",
            "  Getting page https://pypi.org/simple/funcsigs/\n",
            "  Looking up \"https://pypi.org/simple/funcsigs/\" in the cache\n",
            "  Request header has \"max_age\" as 0, cache bypassed\n",
            "  Starting new HTTPS connection (1): pypi.org:443\n",
            "  https://pypi.org:443 \"GET /simple/funcsigs/ HTTP/1.1\" 200 1205\n",
            "  Updating cache with response from \"https://pypi.org/simple/funcsigs/\"\n",
            "  Caching due to etag\n",
            "  Analyzing links from page https://pypi.org/simple/funcsigs/\n",
            "    Found link https://files.pythonhosted.org/packages/78/d2/1c8d781e957a667de45199cc9fa69cc95eedc589ceb2f180d7f40af7625f/funcsigs-0.1.tar.gz#sha256=0e909110e7427ed0abc8b92525281e05aaf116cc2c921a185982edd48c1e0a6a (from https://pypi.org/simple/funcsigs/), version: 0.1\n",
            "    Found link https://files.pythonhosted.org/packages/b7/56/1def30b73d76ef0a6c68c8a14b3fc31d361c53b02ff2ffb1c91d2b465698/funcsigs-0.2.tar.gz#sha256=6896c54379cbaf8a0e14d095bc00fc0969f08f5f7908a86ddde7b15549c93916 (from https://pypi.org/simple/funcsigs/), version: 0.2\n",
            "    Found link https://files.pythonhosted.org/packages/b2/c3/1842bc45f0549d34379e3ea73ce584ba30573e26dd93a0fef03cfed8156c/funcsigs-0.3.tar.gz#sha256=71dcf5c28a97b2a5a5c39a45497d1c86863eb5474589a00bf7ade3cac0fdccaf (from https://pypi.org/simple/funcsigs/), version: 0.3\n",
            "    Found link https://files.pythonhosted.org/packages/5e/9f/025d4c92c6a1a94313cdf0813cd76f5700f8e5434fa15165090a6446ae22/funcsigs-0.4-py2.py3-none-any.whl#sha256=ff5ad9e2f8d9e5d1e8bbfbcf47722ab527cf0d51caeeed9da6d0f40799383fde (from https://pypi.org/simple/funcsigs/), version: 0.4\n",
            "    Found link https://files.pythonhosted.org/packages/87/5e/44bc85c41e5b33b6bf1fcb2f6ccbc4ee74337af079438d2a28c5c45137e1/funcsigs-0.4.tar.gz#sha256=d83ce6df0b0ea6618700fe1db353526391a8a3ada1b7aba52fed7a61da772033 (from https://pypi.org/simple/funcsigs/), version: 0.4\n",
            "    Found link https://files.pythonhosted.org/packages/09/8d/17528625d12ca90651dd1f7958fd0d32b23b15f2197023372669fd683321/funcsigs-1.0.0-py2.py3-none-any.whl#sha256=1c916dfbb4aad250f2a40e937dcff206da165fa29fa909ee1ea02243f7386019 (from https://pypi.org/simple/funcsigs/), version: 1.0.0\n",
            "    Found link https://files.pythonhosted.org/packages/b9/5e/55612c62d35959b5b9767f020f95cb0830f340733f5c2626c7d1e9056729/funcsigs-1.0.0.tar.gz#sha256=2310f9d4a77c284e920ec572dc2525366a107b08d216ff8dbb891d95b6a77563 (from https://pypi.org/simple/funcsigs/), version: 1.0.0\n",
            "    Found link https://files.pythonhosted.org/packages/3c/60/4bb1cbb64a46e98b8063013d271fd3e9e20832827a4d59e343889c6a7a95/funcsigs-1.0.1-py2.py3-none-any.whl#sha256=2edd42db946babc214077be3626e1c496561daeb6e752e482d8d733a0d578f01 (from https://pypi.org/simple/funcsigs/), version: 1.0.1\n",
            "    Found link https://files.pythonhosted.org/packages/ab/5b/a6dff630fe5b68a4d2a049b6d95b51ad1510fb72e9606d656feb2c34efd8/funcsigs-1.0.1.tar.gz#sha256=0726847f1463526794496423f6500cc2ed751361b6c025982ab18bc6c5af35b1 (from https://pypi.org/simple/funcsigs/), version: 1.0.1\n",
            "    Found link https://files.pythonhosted.org/packages/69/cb/f5be453359271714c01b9bd06126eaf2e368f1fddfff30818754b5ac2328/funcsigs-1.0.2-py2.py3-none-any.whl#sha256=330cc27ccbf7f1e992e69fef78261dc7c6569012cf397db8d3de0234e6c937ca (from https://pypi.org/simple/funcsigs/), version: 1.0.2\n",
            "    Found link https://files.pythonhosted.org/packages/94/4a/db842e7a0545de1cdb0439bb80e6e42dfe82aaeaadd4072f2263a4fbed23/funcsigs-1.0.2.tar.gz#sha256=a7bb0f2cf3a3fd1ab2732cb49eba4252c2af4240442415b4abce3b87022a8f50 (from https://pypi.org/simple/funcsigs/), version: 1.0.2\n",
            "  Using version 1.0.2 (newest of versions: 0.1, 0.2, 0.3, 0.4, 1.0.0, 1.0.1, 1.0.2)\n",
            "  Created temporary directory: /tmp/pip-unpack-_hr336ot\n",
            "  Looking up \"https://files.pythonhosted.org/packages/69/cb/f5be453359271714c01b9bd06126eaf2e368f1fddfff30818754b5ac2328/funcsigs-1.0.2-py2.py3-none-any.whl\" in the cache\n",
            "  No cache entry available\n",
            "  Starting new HTTPS connection (1): files.pythonhosted.org:443\n",
            "  https://files.pythonhosted.org:443 \"GET /packages/69/cb/f5be453359271714c01b9bd06126eaf2e368f1fddfff30818754b5ac2328/funcsigs-1.0.2-py2.py3-none-any.whl HTTP/1.1\" 200 17697\n",
            "  Downloading https://files.pythonhosted.org/packages/69/cb/f5be453359271714c01b9bd06126eaf2e368f1fddfff30818754b5ac2328/funcsigs-1.0.2-py2.py3-none-any.whl\n",
            "  Downloading from URL https://files.pythonhosted.org/packages/69/cb/f5be453359271714c01b9bd06126eaf2e368f1fddfff30818754b5ac2328/funcsigs-1.0.2-py2.py3-none-any.whl#sha256=330cc27ccbf7f1e992e69fef78261dc7c6569012cf397db8d3de0234e6c937ca (from https://pypi.org/simple/funcsigs/)\n",
            "  Ignoring unknown cache-control directive: immutable\n",
            "  Updating cache with response from \"https://files.pythonhosted.org/packages/69/cb/f5be453359271714c01b9bd06126eaf2e368f1fddfff30818754b5ac2328/funcsigs-1.0.2-py2.py3-none-any.whl\"\n",
            "  Caching due to etag\n",
            "  Added funcsigs from https://files.pythonhosted.org/packages/69/cb/f5be453359271714c01b9bd06126eaf2e368f1fddfff30818754b5ac2328/funcsigs-1.0.2-py2.py3-none-any.whl#sha256=330cc27ccbf7f1e992e69fef78261dc7c6569012cf397db8d3de0234e6c937ca (from ray==0.7.0) to build tracker '/tmp/pip-req-tracker-yv1_hsbl'\n",
            "  Removed funcsigs from https://files.pythonhosted.org/packages/69/cb/f5be453359271714c01b9bd06126eaf2e368f1fddfff30818754b5ac2328/funcsigs-1.0.2-py2.py3-none-any.whl#sha256=330cc27ccbf7f1e992e69fef78261dc7c6569012cf397db8d3de0234e6c937ca (from ray==0.7.0) from build tracker '/tmp/pip-req-tracker-yv1_hsbl'\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from ray==0.7.0) (7.0)\n",
            "Collecting colorama (from ray==0.7.0)\n",
            "  1 location(s) to search for versions of colorama:\n",
            "  * https://pypi.org/simple/colorama/\n",
            "  Getting page https://pypi.org/simple/colorama/\n",
            "  Looking up \"https://pypi.org/simple/colorama/\" in the cache\n",
            "  Request header has \"max_age\" as 0, cache bypassed\n",
            "  https://pypi.org:443 \"GET /simple/colorama/ HTTP/1.1\" 200 7136\n",
            "  Updating cache with response from \"https://pypi.org/simple/colorama/\"\n",
            "  Caching due to etag\n",
            "  Analyzing links from page https://pypi.org/simple/colorama/\n",
            "    Found link https://files.pythonhosted.org/packages/c4/5f/bd491ccfba0060c785e019ffdeb885fb31c9075573b8414c927b22c7d0f7/colorama-0.1.zip#sha256=dde5204ace2a469f2065d86e1c998e34bf0db8fa390eea7db91e17dd74f1ca9e (from https://pypi.org/simple/colorama/), version: 0.1\n",
            "    Found link https://files.pythonhosted.org/packages/9f/30/5166407fe8e1fb932cf377b0d1c5ec72ec07e372452302875ef1263fec6c/colorama-0.1.1.tar.gz#sha256=4b53b07a72a276642ef0f6aed4a7083480bff6d5dcc44a5972352369c1694309 (from https://pypi.org/simple/colorama/), version: 0.1.1\n",
            "    Found link https://files.pythonhosted.org/packages/99/e6/ef52457b44a915e866ee6439d653cbc76f94163e41fa164056356f011729/colorama-0.1.1.zip#sha256=83f483e4a2efba46c212e054407a6b8ea3b582a7e332b8de927350029271c7c1 (from https://pypi.org/simple/colorama/), version: 0.1.1\n",
            "    Found link https://files.pythonhosted.org/packages/57/cc/50b228f4a10b72e1b535832ccee3f1829e8bf49d9b72db8bf7060fc9e8c4/colorama-0.1.2.tar.gz#sha256=e54911d64d83a05489290232849b4c17b3f1a5b54246cd40ab94fdd9e5b0fcf3 (from https://pypi.org/simple/colorama/), version: 0.1.2\n",
            "    Found link https://files.pythonhosted.org/packages/be/2c/4e6eb6434f5d3974c125e8cb40262bf289518e6aa9d7e4d1b6bd4ce224a8/colorama-0.1.2.zip#sha256=10e40ce2298c412a6b6a96c2a0d87dc652f7d481e830659daf400cbd2946d2d1 (from https://pypi.org/simple/colorama/), version: 0.1.2\n",
            "    Found link https://files.pythonhosted.org/packages/c8/45/422514a0974c0ce307ca92055135ff99825cd7b50e71f496574c965857ab/colorama-0.1.3.tar.gz#sha256=30908bb85f9e5f413b83571f735e3e26ad8d05dcc295a0515dbfb27a01d2efbc (from https://pypi.org/simple/colorama/), version: 0.1.3\n",
            "    Found link https://files.pythonhosted.org/packages/be/d7/76a32e17a58dfcec0b33e206c83752b737ce576928b6a17fd997b72ceb78/colorama-0.1.3.zip#sha256=236badb2f664da9d0ffc9fbd8b09f4f6e138d16ded4d3bd819a1b3bcb696cd75 (from https://pypi.org/simple/colorama/), version: 0.1.3\n",
            "    Found link https://files.pythonhosted.org/packages/fc/ed/606c819f1ac338651d21e314be7537986735142eb58bf6b84780fae536a4/colorama-0.1.4.tar.gz#sha256=8ab93dffae95ff1f8406a4d8fc9a86f496f6faf4ebb1c639d0cbbce988065888 (from https://pypi.org/simple/colorama/), version: 0.1.4\n",
            "    Found link https://files.pythonhosted.org/packages/65/67/8bb9d5fc7e14fecd6d7ee7b6cbb31c8c5e1209d545bbf1cc5d693b252615/colorama-0.1.4.zip#sha256=68d15a25a534b08df195d5b47913c5108e5dead87346fd51939fa8c99b6f4638 (from https://pypi.org/simple/colorama/), version: 0.1.4\n",
            "    Found link https://files.pythonhosted.org/packages/24/10/1a9a1dfbba2e024af127111665636d4e8fddd97518302f69edeea2aa8a88/colorama-0.1.5.tar.gz#sha256=97c429e4b2fa1938d98a8fbb33280fbc7276ffae6ffd49dfff494c703550730e (from https://pypi.org/simple/colorama/), version: 0.1.5\n",
            "    Found link https://files.pythonhosted.org/packages/50/36/4139cebc5102600ee566923f03a01f706ae2ee89e21974721fa0b71e7687/colorama-0.1.5.zip#sha256=c106b14284bf462d945284bb94ded573a6769075166b935589b0582bf4812b9f (from https://pypi.org/simple/colorama/), version: 0.1.5\n",
            "    Found link https://files.pythonhosted.org/packages/ea/18/17d71f153a29763f3a481435d62cd698fc72933b2a053b03922a0187d061/colorama-0.1.6.tar.gz#sha256=61dda1731c73662c151624f093f1d0569de205bf2d11ed85fd68e396f0c189b0 (from https://pypi.org/simple/colorama/), version: 0.1.6\n",
            "    Found link https://files.pythonhosted.org/packages/7f/5c/0ac1be1cb2cf6c1e508d446f29093768f411cb8dfed109ea5ee282c540bd/colorama-0.1.6.zip#sha256=de076ba03273ce1f8f0f3670ecd4e0edb17f584e899005c7edef52b93ebfd822 (from https://pypi.org/simple/colorama/), version: 0.1.6\n",
            "    Found link https://files.pythonhosted.org/packages/fa/1b/620985cb9351b612bb8b849d426c5729be11751955b20a73d51ca07653dc/colorama-0.1.7.tar.gz#sha256=37f9b319303f298aa5231bce4573190c591c731517b9aeefb1b03375df68a51b (from https://pypi.org/simple/colorama/), version: 0.1.7\n",
            "    Found link https://files.pythonhosted.org/packages/4c/2c/24f754ba3d01e48ce2be48b5420b7c4fa58b2dcc2bd9932fe5a18c9d78c2/colorama-0.1.7.zip#sha256=8c688cbaa2d71e8176dcd676f36861132824b8113675c953b31275f42d0a959f (from https://pypi.org/simple/colorama/), version: 0.1.7\n",
            "    Found link https://files.pythonhosted.org/packages/71/35/6917ec507f13a81f3b3111609dce6bf4ba3bca3ef6b3661071f54fa7a494/colorama-0.1.8.tar.gz#sha256=cfaf7cdd26033a2e8d500ffefc65d2b9f66040187e9180a2c0d0fb40aa407a3c (from https://pypi.org/simple/colorama/), version: 0.1.8\n",
            "    Found link https://files.pythonhosted.org/packages/d1/7f/45996d90b613e5041c6927422648638c5df30d840156da567ecc3c5c44c9/colorama-0.1.8.zip#sha256=e1b36afff9365e4fa264b7f984546e5ce67af886dd510a2fdad928c64eb26529 (from https://pypi.org/simple/colorama/), version: 0.1.8\n",
            "    Found link https://files.pythonhosted.org/packages/54/96/e9d16dfcc427d837553a94d504b819874b4f4d440d745bc9e10d5057847b/colorama-0.1.9.tar.gz#sha256=70f4b61fdbff0784988c554071c55b9adf79a6ffbb3b6960e00d8c330ff0db17 (from https://pypi.org/simple/colorama/), version: 0.1.9\n",
            "    Found link https://files.pythonhosted.org/packages/a4/e7/59dc94cad7b61aaff92b3cdba993e320328a8e9e3a88905576db4d239c08/colorama-0.1.9.zip#sha256=ae45945b28f677b249ec30b524a70010a61416368c9ae289b26ef93d697f077d (from https://pypi.org/simple/colorama/), version: 0.1.9\n",
            "    Found link https://files.pythonhosted.org/packages/36/f8/1704d2ccb644c06be7fdca73653d6896e37159e58ffc428cbf919c5d5680/colorama-0.1.10.tar.gz#sha256=d8d0b40c5b66768292576318753270c3cddd2d794986b8f69f32c5f5c8bf02b3 (from https://pypi.org/simple/colorama/), version: 0.1.10\n",
            "    Found link https://files.pythonhosted.org/packages/f8/64/ac1e1ec98b83640d50a7605bfb14740b81ea4f06eeab3119c9da203ed687/colorama-0.1.10.zip#sha256=ecaf291510745cdc5b4fb15831cee410364d74d105ae0c561856c4c953880ada (from https://pypi.org/simple/colorama/), version: 0.1.10\n",
            "    Found link https://files.pythonhosted.org/packages/38/85/8aff6c5de5a8ea71b5b8dceb2ead64cb4ee0432a3367914e90eba7505c35/colorama-0.1.11.tar.gz#sha256=b9449a73936867129ad58ea9ccc24cf5bd5429abcd4c8ab3b5570b515e7d01bf (from https://pypi.org/simple/colorama/), version: 0.1.11\n",
            "    Found link https://files.pythonhosted.org/packages/5b/5e/80a93da9ff4b770c414f32563726040997924b83cd679a94cab738e7f8ff/colorama-0.1.11.zip#sha256=9e7c464abd71a23e203477ca4efc0c784b9f43806d9badbf3758957212dfd39b (from https://pypi.org/simple/colorama/), version: 0.1.11\n",
            "    Found link https://files.pythonhosted.org/packages/2d/0f/ad6109bf90b762004538c44038ec65d2e3e430b62c12ec114fc97afd047b/colorama-0.1.12.tar.gz#sha256=d7bdce9befb286704494ee3c2c7fa06bd79112ae1019171955025a936722a2fa (from https://pypi.org/simple/colorama/), version: 0.1.12\n",
            "    Found link https://files.pythonhosted.org/packages/e7/61/ae5a917ed3534a855132a3ef2b429993ff052fc1b9a594d25c906c9c1a1a/colorama-0.1.12.zip#sha256=e7b519541c95cee3d3268237e9bfd3dac015025fee38075fd50447904750dbcc (from https://pypi.org/simple/colorama/), version: 0.1.12\n",
            "    Found link https://files.pythonhosted.org/packages/40/97/77857f7520dc329736f1569c3b109c5369c7cdbd54fbcc59e317e9707bdf/colorama-0.1.13.tar.gz#sha256=3e1b29490315443351992610fc8ccc92e033e355a9e7771c94fd28ce03657845 (from https://pypi.org/simple/colorama/), version: 0.1.13\n",
            "    Found link https://files.pythonhosted.org/packages/53/d3/0a08085428522d4a21470321fdda8f2c845a863d115e2e97ce47580bb7a5/colorama-0.1.13.zip#sha256=fc9e2899eb4ae1d0f21dbf970240bbf00ead390a815adec05389c5f439da5771 (from https://pypi.org/simple/colorama/), version: 0.1.13\n",
            "    Found link https://files.pythonhosted.org/packages/48/46/4efa86a33c27f42ca35f6d835e660e0a198f321ccf4e7c6271a2a7438454/colorama-0.1.14.tar.gz#sha256=3b8f9c54347138f5d4af332c33dfd7ef3a12cb24a399b4e5de660211ba38cd98 (from https://pypi.org/simple/colorama/), version: 0.1.14\n",
            "    Found link https://files.pythonhosted.org/packages/2d/b3/4a20718f2514eaf0cf40ddc04d795ee5fa247b1e0043c18b0963443ee30b/colorama-0.1.14.zip#sha256=a0e2cb4b7217caa24d52b50cbdeefeb69a76b55e5bd65316f41e898bf44a90fe (from https://pypi.org/simple/colorama/), version: 0.1.14\n",
            "    Found link https://files.pythonhosted.org/packages/59/3c/09d1a085a0886b75c1ef1f73501b8c89dd53f4c6d4c99b677ae7b2858b7c/colorama-0.1.15.tar.gz#sha256=4f57e533873032df40cb19c380d666fed1ea1efc182e5cf6544b460ab1eb0cbd (from https://pypi.org/simple/colorama/), version: 0.1.15\n",
            "    Found link https://files.pythonhosted.org/packages/ca/c2/6910ba3f0de55091bf88e96b94475bf72056d08aa0ce2e45f6a7c5d4e725/colorama-0.1.15.zip#sha256=fb55091e0dd982edcfa99f039f8ae85f7acd538626c15de71fed39a6b7faa3fd (from https://pypi.org/simple/colorama/), version: 0.1.15\n",
            "    Found link https://files.pythonhosted.org/packages/33/07/70a1618f6558fca1be02dba86633e352bf3e1c15a935172b3574e0aad571/colorama-0.1.16.tar.gz#sha256=218648251fa88ddd34fe38e4539c4306d0633bf55dd1fd47b085d92376d3964b (from https://pypi.org/simple/colorama/), version: 0.1.16\n",
            "    Found link https://files.pythonhosted.org/packages/7e/6f/4e74dbe88220aa10d2da2226cb6b863c12f24df94ffab2584a30214a2c7b/colorama-0.1.16.zip#sha256=38843763a2377d72307cc26bc4fc53e7abf207a9f988bd4f7c2f466d017c78c8 (from https://pypi.org/simple/colorama/), version: 0.1.16\n",
            "    Found link https://files.pythonhosted.org/packages/93/8e/0e74bf3f62e1c0a0bcd00862610bab6573be89a5adadb566ff710364db4c/colorama-0.1.17.tar.gz#sha256=8ee8e83f771f31cc208e2603f8a3bf9302324958709e4bd002254ed2013d0d7c (from https://pypi.org/simple/colorama/), version: 0.1.17\n",
            "    Found link https://files.pythonhosted.org/packages/82/42/2e51ae62f1b6d44a67b5f5387cdcbf08a8890186b2bc63cf5f6057b72add/colorama-0.1.17.zip#sha256=dad0db5a7f26ec8500b19c2c8ff50841d774eb299da2c2bba89f4b2df0cb9cec (from https://pypi.org/simple/colorama/), version: 0.1.17\n",
            "    Found link https://files.pythonhosted.org/packages/8a/22/b4e99c35db683631ea352a91d3ba84a712e00f4d910f35f13eda7dfa5591/colorama-0.1.18.tar.gz#sha256=faf09b8eb3253080ed9951af08a7e9d8560ddda46567cc1a88b57e90da63f103 (from https://pypi.org/simple/colorama/), version: 0.1.18\n",
            "    Found link https://files.pythonhosted.org/packages/00/78/61090f52616bdcfa5cd26a29ea5d4b3bf44e00112a59e2516ae5f1db144b/colorama-0.1.18.zip#sha256=b9bd0566714e86ea4c4977e2f6f90a1e530a8bc5a7560e1b6bb2ee2e489433f5 (from https://pypi.org/simple/colorama/), version: 0.1.18\n",
            "    Found link https://files.pythonhosted.org/packages/fe/8e/a8d0ea40a0b5ada3b1d26b65fef3bd08970d6444da239503d06cf97f2ba1/colorama-0.2.0.tar.gz#sha256=e5a10477364714c8e3e11d7cdcfcc011188c936a79f4291c18cff5503dd50c72 (from https://pypi.org/simple/colorama/), version: 0.2.0\n",
            "    Found link https://files.pythonhosted.org/packages/db/3d/a32e3cf2aa1816ec77fdb3354dfc372ef0cc8a4846052442a5752a634da1/colorama-0.2.0.zip#sha256=3be96de7a7f8b34a7fdcca25af1421ade28a5f0d0c3be6af807d6cb8110f493d (from https://pypi.org/simple/colorama/), version: 0.2.0\n",
            "    Found link https://files.pythonhosted.org/packages/fd/bb/b84178418e5da32af96dfe017798455523c8fc87206f63ebe645e3d1a77d/colorama-0.2.1.tar.gz#sha256=f048371a45908c3f77df6f7b9956553faf540ac744326ee1c99890310d5e642f (from https://pypi.org/simple/colorama/), version: 0.2.1\n",
            "    Found link https://files.pythonhosted.org/packages/ef/be/7c5926ccffcadf3217968e7ad700b26bd258b3e501ce9d36a63843de8890/colorama-0.2.1.zip#sha256=c337ac440a2461d54251b25688c351c907acf44210985505aa37da03b66037db (from https://pypi.org/simple/colorama/), version: 0.2.1\n",
            "    Found link https://files.pythonhosted.org/packages/e9/12/d39f82f77e35217dea68b935fb904d3e7dca2a95bd1d60779c808e74b2dd/colorama-0.2.2.tar.gz#sha256=cb68365f4347c621febc8c81762437da9115dce4a63878f0e9c7aa05cad5fff3 (from https://pypi.org/simple/colorama/), version: 0.2.2\n",
            "    Found link https://files.pythonhosted.org/packages/3c/e5/554aaca7cbe67953c785409adb3205c666497306f4607f73eadf9a483c0a/colorama-0.2.2.zip#sha256=a30cd228db907b189707990394225fde00669d37b1daa405d3f1718ac4ae71bf (from https://pypi.org/simple/colorama/), version: 0.2.2\n",
            "    Found link https://files.pythonhosted.org/packages/55/61/ce7a6c859873c27a68cb3b2ac2822f25de4112df42964f9136fa6dab920c/colorama-0.2.3.tar.gz#sha256=04050b9badf460c4e61f9371f5bc8cd880d8ef3a3ea3e6d495a0ee9adc89c21c (from https://pypi.org/simple/colorama/), version: 0.2.3\n",
            "    Found link https://files.pythonhosted.org/packages/19/64/6c4047791014470d75f8ee5018b6fa41eb9d756c8a6ada3e0ae85e456d67/colorama-0.2.3.zip#sha256=d74c464df1bf3ec5d244c7f81eac6caacfb0d5727a19b2d8349a2a3f6afd047d (from https://pypi.org/simple/colorama/), version: 0.2.3\n",
            "    Found link https://files.pythonhosted.org/packages/51/ff/9c6ca40190fa279c3d577689c9252956efd28b0e5a1fd4f447c93926f342/colorama-0.2.4.tar.gz#sha256=ab2a1f39493a7cfe61b919ec3c6c204f593db2bf3818a70f6f0aa6b8b0a52e55 (from https://pypi.org/simple/colorama/), version: 0.2.4\n",
            "    Found link https://files.pythonhosted.org/packages/4f/0f/2fb41f6b8ba83f8d85ce5a8fcb7feca40f76f11f6075ee2c3be746316112/colorama-0.2.4.zip#sha256=bb206dc8d19a84c81e07187adf9f7fd53ca62bd924954bc0c9c5dcef767ec6fb (from https://pypi.org/simple/colorama/), version: 0.2.4\n",
            "    Found link https://files.pythonhosted.org/packages/fc/87/17f7dfcc3632b01972aa64cf97db20498f96ae206c8caa066ca47f304d44/colorama-0.2.5.tar.gz#sha256=06257ff3be96a91cbc6e7121db35935297c1ec444536b361bc9fa4f2ca28a396 (from https://pypi.org/simple/colorama/), version: 0.2.5\n",
            "    Found link https://files.pythonhosted.org/packages/2a/4e/bc9dea2d8fb419a4d097d5bc6e5f3558592942bfe863b91e27430beb1cbe/colorama-0.2.5.zip#sha256=521921faa4f979ba6597e1b10383427403339f8c00a619ce0c563d870b9d8cba (from https://pypi.org/simple/colorama/), version: 0.2.5\n",
            "    Found link https://files.pythonhosted.org/packages/a8/bc/c8fef4eb4f9dc5928270bc2e46109255f051b34e15b61f0f2594c80ce009/colorama-0.2.6.tar.gz#sha256=cf063242f4d5abfcca19c2639ec89855bd9b3914394f9db2f9c6c7007968249f (from https://pypi.org/simple/colorama/), version: 0.2.6\n",
            "    Found link https://files.pythonhosted.org/packages/8f/ce/6387e33fe3a2c0a0579e72ebff098357bb475c9d5459a22176a65a7e54b8/colorama-0.2.6.zip#sha256=4139316b1dda8f8ea5ae00ce8e8a8503775c089f2115ff91039a6bbdeb6794c0 (from https://pypi.org/simple/colorama/), version: 0.2.6\n",
            "    Found link https://files.pythonhosted.org/packages/dc/e8/ffa47bd75f026d716d2297e9b8e93a4d537530318514cdb8b60d50080d54/colorama-0.2.7.tar.gz#sha256=37dc4e718795a6c5d172de35dab1a278625f78c49883519e337834ff40dddde5 (from https://pypi.org/simple/colorama/), version: 0.2.7\n",
            "    Found link https://files.pythonhosted.org/packages/33/cc/3fb8058c58ea5b2d578b7f2a2e5845ae03efe0921fb316c1d570130ddd3e/colorama-0.2.7.zip#sha256=337d9bd3adef4899017cdfffb96f8030bdb27fcd8ede14c1d3f8c7768a8668d0 (from https://pypi.org/simple/colorama/), version: 0.2.7\n",
            "    Found link https://files.pythonhosted.org/packages/53/ef/7be639f6dda67af0a558222c739c5eba4bb54c97e9f57d4241bf1e366fa7/colorama-0.3.0.zip#sha256=ada2463942c960ed18349fe2ac296e724d9f3f3146882af350c8ae2fe26f4169 (from https://pypi.org/simple/colorama/), version: 0.3.0\n",
            "    Found link https://files.pythonhosted.org/packages/a4/1e/73f7cbfb0516942102e9dafdc1dc93c59c110c5927ea7c7440f6039cad54/colorama-0.3.1.tar.gz#sha256=012261ba542a5b18076cac0eaa3892ebe6098e170591e08a8fc0fbf8ab3d5c90 (from https://pypi.org/simple/colorama/), version: 0.3.1\n",
            "    Found link https://files.pythonhosted.org/packages/34/4a/ae411cb1195c6bb1d86b59d941247999a6cee0164dec91a120b6f77168d2/colorama-0.3.1.zip#sha256=0df6c181af416afafa552f8cc2111a88e5f2c8ffc90e10f1a50cdc908d085b0c (from https://pypi.org/simple/colorama/), version: 0.3.1\n",
            "    Found link https://files.pythonhosted.org/packages/29/dc/191dae95b02cb82088b29027ac88d48a3e43f7f12c0543d00c565b3d2f40/colorama-0.3.2.tar.gz#sha256=218862857d74ff781c2caf44629a7d72b88bbb8a2b0aa0f4f1eb8666f8305c11 (from https://pypi.org/simple/colorama/), version: 0.3.2\n",
            "    Found link https://files.pythonhosted.org/packages/13/b4/ccc34a878c59993a36b3f6d967d34eafbcdf07657e54ef1d051570e0c0e9/colorama-0.3.2.zip#sha256=f1ae1669bb4009aeed392a8df008d6926b434ee811b663a30ae673c09263c25b (from https://pypi.org/simple/colorama/), version: 0.3.2\n",
            "    Found link https://files.pythonhosted.org/packages/24/84/29ce4167d1f5c4a320aaad91e1178e5a1baf9cfe1c63f9077c5dade0e3cc/colorama-0.3.3.tar.gz#sha256=eb21f2ba718fbf357afdfdf6f641ab393901c7ca8d9f37edd0bee4806ffa269c (from https://pypi.org/simple/colorama/), version: 0.3.3\n",
            "    Found link https://files.pythonhosted.org/packages/81/79/051335e05573f79cb13cd9ad5b311a54bf31546294969d6b30fb36afebc6/colorama-0.3.4.tar.gz#sha256=ff5c8687f9eea33e6c9586f8bacc43761ac4b7650dd151db8dc7893a0b01e493 (from https://pypi.org/simple/colorama/), version: 0.3.4\n",
            "    Found link https://files.pythonhosted.org/packages/98/ec/9b7db70c01f557681e124e4dc84ba3837a9799352e86452217d46a07a41c/colorama-0.3.4.zip#sha256=81378cbcd8d2fafa019036146c3c5da279a873adf7ecafa63dfb12898a49492e (from https://pypi.org/simple/colorama/), version: 0.3.4\n",
            "    Found link https://files.pythonhosted.org/packages/60/02/5790fb0c1c6ffb803deba163e5d524748bf21316862f18acba8cd4cb2c26/colorama-0.3.5-py2.py3-none-any.whl#sha256=ac378abbd3b335c414a4de4f95905e1050f724cb21fa7c02f95bc2751bfea847 (from https://pypi.org/simple/colorama/), version: 0.3.5\n",
            "    Found link https://files.pythonhosted.org/packages/4b/bf/383aad870435aaaae1cbecb3bcccf029e8b33ae99885c6007ada22b0f6cf/colorama-0.3.5.tar.gz#sha256=0880a751afcb111881b437a846a93e540c7e1346030ba7bd7fda03434371fbc3 (from https://pypi.org/simple/colorama/), version: 0.3.5\n",
            "    Found link https://files.pythonhosted.org/packages/2e/b2/3fa01e0f0e88d453b1b406a559c875abd809f1087f23a6818edbef5e5d28/colorama-0.3.5.zip#sha256=e2a92673e323e1d35050fb597bacbeee9abb0d85ed35c8d91d542a84d9c79a21 (from https://pypi.org/simple/colorama/), version: 0.3.5\n",
            "    Found link https://files.pythonhosted.org/packages/4c/1b/7ea581dff0339aab5cdd3e0c275885a7cfc951984c960a7a1da554032b25/colorama-0.3.6-py2.py3-none-any.whl#sha256=63906b8855da6eb1a1c1f167080b85cc7a13eab6170dbb658650a8b72fac0593 (from https://pypi.org/simple/colorama/), version: 0.3.6\n",
            "    Found link https://files.pythonhosted.org/packages/93/70/68fcfa68d1dfb484a0fcc25b984e22e029051845604f1a3eb8a7c23b0b40/colorama-0.3.6.tar.gz#sha256=ec9efcccb086a1d727876384f94ee6358d2f3f096688c1ba18b0f318f2b453b5 (from https://pypi.org/simple/colorama/), version: 0.3.6\n",
            "    Found link https://files.pythonhosted.org/packages/14/0e/488fd32efe8cf4b2f0b3717b524f375b2391348b47d894f47da775e6f79d/colorama-0.3.6.zip#sha256=c5580586331aeb5b06da34743b1fb9046bec892467947b8c252881393b87880c (from https://pypi.org/simple/colorama/), version: 0.3.6\n",
            "    Found link https://files.pythonhosted.org/packages/b7/8e/ddb32ddaabd431813e180ca224e844bab8ad42fbb47ee07553f0ec44cd86/colorama-0.3.7-py2.py3-none-any.whl#sha256=a4c0f5bc358a62849653471e309dcc991223cf86abafbec17cd8f41327279e89 (from https://pypi.org/simple/colorama/), version: 0.3.7\n",
            "    Found link https://files.pythonhosted.org/packages/f0/d0/21c6449df0ca9da74859edc40208b3a57df9aca7323118c913e58d442030/colorama-0.3.7.tar.gz#sha256=e043c8d32527607223652021ff648fbb394d5e19cba9f1a698670b338c9d782b (from https://pypi.org/simple/colorama/), version: 0.3.7\n",
            "    Found link https://files.pythonhosted.org/packages/cd/ac/228603eb4c2aa4c77e767f3d7165b3c9b3196367fa8e3a9131a87a41de5c/colorama-0.3.7.zip#sha256=f4945bf52ae49da0728fe730a33c18744803752fc948f154f29dc0c4f9f2f9cc (from https://pypi.org/simple/colorama/), version: 0.3.7\n",
            "    Found link https://files.pythonhosted.org/packages/4f/95/b41f846cfae3dc38b2dafa318a7c7143f7dff2ab31ba5e3da956ee8b4ccb/colorama-0.3.8-py2.py3-none-any.whl#sha256=37fed83335fc371eebe48f6f297081962e162c10fc54d47253c6354734eb9625 (from https://pypi.org/simple/colorama/), version: 0.3.8\n",
            "    Found link https://files.pythonhosted.org/packages/9d/86/006d621542b6ab44c1b5df6dbd9be12d7e3b7cb87d5405ea5c68a3cb78e9/colorama-0.3.8.tar.gz#sha256=66c0470b1aab193890761e959103a1d99d609a2158f14ab27fb1afedc99aacc9 (from https://pypi.org/simple/colorama/), version: 0.3.8\n",
            "    Found link https://files.pythonhosted.org/packages/db/c8/7dcf9dbcb22429512708fe3a547f8b6101c0d02137acbd892505aee57adf/colorama-0.3.9-py2.py3-none-any.whl#sha256=463f8483208e921368c9f306094eb6f725c6ca42b0f97e313cb5d5512459feda (from https://pypi.org/simple/colorama/), version: 0.3.9\n",
            "    Found link https://files.pythonhosted.org/packages/e6/76/257b53926889e2835355d74fec73d82662100135293e17d382e2b74d1669/colorama-0.3.9.tar.gz#sha256=48eb22f4f8461b1df5734a074b57042430fb06e1d61bd1e11b078c0fe6d7a1f1 (from https://pypi.org/simple/colorama/), version: 0.3.9\n",
            "    Found link https://files.pythonhosted.org/packages/0a/93/6e8289231675d561d476d656c2ee3a868c1cca207e16c118d4503b25e2bf/colorama-0.4.0-py2.py3-none-any.whl#sha256=a3d89af5db9e9806a779a50296b5fdb466e281147c2c235e8225ecc6dbf7bbf3 (from https://pypi.org/simple/colorama/), version: 0.4.0\n",
            "    Found link https://files.pythonhosted.org/packages/55/d5/c35bd3e63757ac767105f8695b055581d8b8dd8c22fef020ebefa2a3725d/colorama-0.4.0.zip#sha256=c9b54bebe91a6a803e0772c8561d53f2926bfeb17cd141fbabcb08424086595c (from https://pypi.org/simple/colorama/), version: 0.4.0\n",
            "    Found link https://files.pythonhosted.org/packages/4f/a6/728666f39bfff1719fc94c481890b2106837da9318031f71a8424b662e12/colorama-0.4.1-py2.py3-none-any.whl#sha256=f8ac84de7840f5b9c4e3347b3c1eaa50f7e49c2b07596221daec5edaabbd7c48 (from https://pypi.org/simple/colorama/), version: 0.4.1\n",
            "    Found link https://files.pythonhosted.org/packages/76/53/e785891dce0e2f2b9f4b4ff5bc6062a53332ed28833c7afede841f46a5db/colorama-0.4.1.tar.gz#sha256=05eed71e2e327246ad6b38c540c4a3117230b19679b875190486ddd2d721422d (from https://pypi.org/simple/colorama/), version: 0.4.1\n",
            "  Using version 0.4.1 (newest of versions: 0.1, 0.1.1, 0.1.2, 0.1.3, 0.1.4, 0.1.5, 0.1.6, 0.1.7, 0.1.8, 0.1.9, 0.1.10, 0.1.11, 0.1.12, 0.1.13, 0.1.14, 0.1.15, 0.1.16, 0.1.17, 0.1.18, 0.2.0, 0.2.1, 0.2.2, 0.2.3, 0.2.4, 0.2.5, 0.2.6, 0.2.7, 0.3.0, 0.3.1, 0.3.2, 0.3.3, 0.3.4, 0.3.5, 0.3.6, 0.3.7, 0.3.8, 0.3.9, 0.4.0, 0.4.1)\n",
            "  Created temporary directory: /tmp/pip-unpack-n9hz3uiq\n",
            "  Looking up \"https://files.pythonhosted.org/packages/4f/a6/728666f39bfff1719fc94c481890b2106837da9318031f71a8424b662e12/colorama-0.4.1-py2.py3-none-any.whl\" in the cache\n",
            "  No cache entry available\n",
            "  https://files.pythonhosted.org:443 \"GET /packages/4f/a6/728666f39bfff1719fc94c481890b2106837da9318031f71a8424b662e12/colorama-0.4.1-py2.py3-none-any.whl HTTP/1.1\" 200 15471\n",
            "  Downloading https://files.pythonhosted.org/packages/4f/a6/728666f39bfff1719fc94c481890b2106837da9318031f71a8424b662e12/colorama-0.4.1-py2.py3-none-any.whl\n",
            "  Downloading from URL https://files.pythonhosted.org/packages/4f/a6/728666f39bfff1719fc94c481890b2106837da9318031f71a8424b662e12/colorama-0.4.1-py2.py3-none-any.whl#sha256=f8ac84de7840f5b9c4e3347b3c1eaa50f7e49c2b07596221daec5edaabbd7c48 (from https://pypi.org/simple/colorama/)\n",
            "  Ignoring unknown cache-control directive: immutable\n",
            "  Updating cache with response from \"https://files.pythonhosted.org/packages/4f/a6/728666f39bfff1719fc94c481890b2106837da9318031f71a8424b662e12/colorama-0.4.1-py2.py3-none-any.whl\"\n",
            "  Caching due to etag\n",
            "  Added colorama from https://files.pythonhosted.org/packages/4f/a6/728666f39bfff1719fc94c481890b2106837da9318031f71a8424b662e12/colorama-0.4.1-py2.py3-none-any.whl#sha256=f8ac84de7840f5b9c4e3347b3c1eaa50f7e49c2b07596221daec5edaabbd7c48 (from ray==0.7.0) to build tracker '/tmp/pip-req-tracker-yv1_hsbl'\n",
            "  Removed colorama from https://files.pythonhosted.org/packages/4f/a6/728666f39bfff1719fc94c481890b2106837da9318031f71a8424b662e12/colorama-0.4.1-py2.py3-none-any.whl#sha256=f8ac84de7840f5b9c4e3347b3c1eaa50f7e49c2b07596221daec5edaabbd7c48 (from ray==0.7.0) from build tracker '/tmp/pip-req-tracker-yv1_hsbl'\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from ray==0.7.0) (3.6.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from ray==0.7.0) (3.13)\n",
            "Collecting redis (from ray==0.7.0)\n",
            "  1 location(s) to search for versions of redis:\n",
            "  * https://pypi.org/simple/redis/\n",
            "  Getting page https://pypi.org/simple/redis/\n",
            "  Looking up \"https://pypi.org/simple/redis/\" in the cache\n",
            "  Request header has \"max_age\" as 0, cache bypassed\n",
            "  https://pypi.org:443 \"GET /simple/redis/ HTTP/1.1\" 200 5192\n",
            "  Updating cache with response from \"https://pypi.org/simple/redis/\"\n",
            "  Caching due to etag\n",
            "  Analyzing links from page https://pypi.org/simple/redis/\n",
            "    Found link https://files.pythonhosted.org/packages/41/57/c6891ac2904a1984853f26781fe70d58ee3903be71455681906797d27fdd/redis-0.6.0.tar.gz#sha256=fd78a8c3953c1f368ac75355001b8558c1037b1cf0baf9e95bcfa3ffff9826f7 (from https://pypi.org/simple/redis/), version: 0.6.0\n",
            "    Found link https://files.pythonhosted.org/packages/12/a4/bec4b1e2c6a435d0c785acefd9bc7a30b63021279faaa335cd839d3287a8/redis-0.6.1.tar.gz#sha256=71a8fbce7b42593d364fe2c4ffb6b3203753a48186c18996a42e3c86cd3c05cf (from https://pypi.org/simple/redis/), version: 0.6.1\n",
            "    Found link https://files.pythonhosted.org/packages/a8/3e/8817de4983d8b2c64cd92f816800b6329841e2b198b46568c4120ea33154/redis-1.34.tar.gz#sha256=472f982cf540475130fd72212583b1bb26f5d3d511be9da560479d44cd4b319e (from https://pypi.org/simple/redis/), version: 1.34\n",
            "    Found link https://files.pythonhosted.org/packages/5f/09/ab7a27749ce97b3dcbbc4198fac1096bc782afa50d180ef7326505d0ca90/redis-1.34.1.tar.gz#sha256=5bc45eb55d1f62e7104604cad001c24231876dcf14be84eaa246ba4dd3855280 (from https://pypi.org/simple/redis/), version: 1.34.1\n",
            "    Found link https://files.pythonhosted.org/packages/5b/55/3b3e4cf7d61d32cb0b505aa352b3fd4d5895ced3146c50b3faa1dc757207/redis-2.0.0.tar.gz#sha256=81647560cc8d4ffff8c17db207c1410a036a1bc8e9d7cf753b76bc2ac41d0306 (from https://pypi.org/simple/redis/), version: 2.0.0\n",
            "    Found link https://files.pythonhosted.org/packages/97/ae/356be48f4be0c05a0dcac2d90a95a8a4333e7f2b8ed02f1842a0a5ccd2da/redis-2.2.0.tar.gz#sha256=618825c669fa6952d865029d8a3d34697fc8c6330bae032bd6d02118251598a0 (from https://pypi.org/simple/redis/), version: 2.2.0\n",
            "    Found link https://files.pythonhosted.org/packages/0e/dc/b4e51464fa71a451f6533a3aa2d1c868e8ad1cd029a134a079dfdb84909e/redis-2.2.2.tar.gz#sha256=369b487ea1e80790a85d8e6f5b73dd697d26aa2157fde411b1020bf48ea4a770 (from https://pypi.org/simple/redis/), version: 2.2.2\n",
            "    Found link https://files.pythonhosted.org/packages/56/3e/36f920832f0448ac5d2e3fbf05deadb81e8d3aaab8f1ae2d651ae1c71967/redis-2.2.4.tar.gz#sha256=2a3e021e861732ad74ca80160276ac6605dd6b196c4198bc40fc0b9847a61cca (from https://pypi.org/simple/redis/), version: 2.2.4\n",
            "    Found link https://files.pythonhosted.org/packages/29/6b/4caf2b0857ecd4eccf11fb44ebc824ae07bbdc9565a7ed120ba2b14b37ce/redis-2.4.0.tar.gz#sha256=bea01b7a58397f648ecad514599b434e617aedcb8ecd29cd937f3f4819002a05 (from https://pypi.org/simple/redis/), version: 2.4.0\n",
            "    Found link https://files.pythonhosted.org/packages/1c/7a/28efae0a79c87cd148632ea010b7cf327bba5ce9bf1610e2215b15ac4111/redis-2.4.1.tar.gz#sha256=56ab08d7c8914f0452606e4dc232634e13d15b4a2b71365bedddccc5582fdd5e (from https://pypi.org/simple/redis/), version: 2.4.1\n",
            "    Found link https://files.pythonhosted.org/packages/7c/12/e824222ee6212bd2500110f84148368c8975d4c10726c4be5227bae688b9/redis-2.4.2.tar.gz#sha256=5b1b8e4c87872254c4697a6490f5ec3b1a6269b0cfdbc14af9b59b5ceb64b13a (from https://pypi.org/simple/redis/), version: 2.4.2\n",
            "    Found link https://files.pythonhosted.org/packages/7d/b7/f79d85a735f8a7847371fa59ee23c7ff62da517c8517ffb5616fe00b7a9a/redis-2.4.3.tar.gz#sha256=4f389ad6bc0a6c5dd892809216c04e7dd6a2e672796950914ea46c120f33aaeb (from https://pypi.org/simple/redis/), version: 2.4.3\n",
            "    Found link https://files.pythonhosted.org/packages/c9/43/723a5817aecee9f4822b0b2a5c985b9d252091ac3b7f124386e82c9aad45/redis-2.4.4.tar.gz#sha256=a006facb5e5d4c50e290624263497bd1480b27541fb1b40d849b4f87ff692682 (from https://pypi.org/simple/redis/), version: 2.4.4\n",
            "    Found link https://files.pythonhosted.org/packages/b4/ce/c803bf0a9a37f5abc37eb57caaff12d5a75e1b3b0549ead8ae8359171b23/redis-2.4.5.tar.gz#sha256=0086de1e3033322e5b64480ad67caa6ffc6f7fad488153345815b8b502ca626e (from https://pypi.org/simple/redis/), version: 2.4.5\n",
            "    Found link https://files.pythonhosted.org/packages/63/80/2c3fbbe471fd53ad56e597422ae1ae9c09e282c407b84bbbd15c9831fa40/redis-2.4.6.tar.gz#sha256=b018b7454175b683473f1dfed6f3f3d9d530aa8011374bfd59e07311bc2f49d0 (from https://pypi.org/simple/redis/), version: 2.4.6\n",
            "    Found link https://files.pythonhosted.org/packages/4e/d3/dcdb32e9103fe0e0bd7c24de26cdebb70b69a3b5236493225051fcd45017/redis-2.4.7.tar.gz#sha256=58916976d8dcfa3603d49da0c984207e04197c1d60e28c59d40c3192f00b3cfe (from https://pypi.org/simple/redis/), version: 2.4.7\n",
            "    Found link https://files.pythonhosted.org/packages/b5/d8/582d3343e4e87958a8532a883fbae449db8bc4a0e825747f6be11b4fec93/redis-2.4.8.tar.gz#sha256=56a788f3d1102ac1ca1f704af4e1e3f5118da7a7a95cc3b1fc9e9ca0dffa6f7e (from https://pypi.org/simple/redis/), version: 2.4.8\n",
            "    Found link https://files.pythonhosted.org/packages/c4/83/9929c762974a6692528c944522ab6ac9a12b5dfda92a3bdefce9ef3167ec/redis-2.4.9.tar.gz#sha256=f4ea85767e037d1aa471272840db2af512fe86043324621f883de7c9ccebfaf1 (from https://pypi.org/simple/redis/), version: 2.4.9\n",
            "    Found link https://files.pythonhosted.org/packages/8a/61/36979d97ea05607defb660576f9a83ea3dfae77afa73c1f14b0cb10b6cdd/redis-2.4.10.tar.gz#sha256=efdd7e0ea8430d82d6223a20f4ac28860f3bfefd0722037c84ad8085025629a2 (from https://pypi.org/simple/redis/), version: 2.4.10\n",
            "    Found link https://files.pythonhosted.org/packages/52/4d/a89e994c95aece19c8492d2e6ff90fe127408acdfb8376bc3eeebd3ead4d/redis-2.4.11.tar.gz#sha256=8e000a10464e5cbd4814987c130b897fd2a34ff2cef40b2584ea7f8d73473d1c (from https://pypi.org/simple/redis/), version: 2.4.11\n",
            "    Found link https://files.pythonhosted.org/packages/21/83/3a687ea0f9eca54f49a49ec8c19d06f339f61de26b70debf2527f86d5f9c/redis-2.4.12.tar.gz#sha256=98cadb4481671a54b7de867280dc11f11ba16ce007d1e078746ba768d2655486 (from https://pypi.org/simple/redis/), version: 2.4.12\n",
            "    Found link https://files.pythonhosted.org/packages/5e/38/6fa4b282a8033e14ff866cff2ab42dd869fc9d688184c76130898a7ca481/redis-2.4.13.tar.gz#sha256=365285e161395344edc629a2e108f6bb0983e96d9b5012dab1f76cec2379a09a (from https://pypi.org/simple/redis/), version: 2.4.13\n",
            "    Found link https://files.pythonhosted.org/packages/9b/e3/3b356e21f1e6e3ed5cdfbb9d01baeed0894d6acc057dc43ec6dafea95bd9/redis-2.6.0.tar.gz#sha256=95f285c3b326bb26f9d1d35b32bf19f0635a4cb8b0d7ea883a9ff33decc4e867 (from https://pypi.org/simple/redis/), version: 2.6.0\n",
            "    Found link https://files.pythonhosted.org/packages/b0/f8/1904ffda87b945ae4d276aea6ce5f17ea27dfc10f3ceef04173b56601c38/redis-2.6.1.tar.gz#sha256=c9e0e74e92fad8b277ed18af1eeb0129224d7156bad53d2dcd84c6ddb81da8ec (from https://pypi.org/simple/redis/), version: 2.6.1\n",
            "    Found link https://files.pythonhosted.org/packages/47/b4/f42ca3ef6bd981b7b1a572d36b24e5546310a5f19fe6f9f8ad3550309a8d/redis-2.6.2.tar.gz#sha256=2196ff8a6b0ce505d3972a58c49d842f031260af66f2e3960e0ce068ab7598e5 (from https://pypi.org/simple/redis/), version: 2.6.2\n",
            "    Found link https://files.pythonhosted.org/packages/5a/54/5d71d9e12366066680d7da83387c4f83594d1fc8ede00ffac87ff7369d71/redis-2.7.0.tar.gz#sha256=0a6d3ff3d83ade3fb3f2f7392414e43237af61d92ce783cae05b9d1ac40f0e91 (from https://pypi.org/simple/redis/), version: 2.7.0\n",
            "    Found link https://files.pythonhosted.org/packages/bb/6d/3fd5b6a9cd378b643afbf08f80c30ad55efec8c7efeaa2914ba796260d49/redis-2.7.1.tar.gz#sha256=e59c0258d3a831299915ba47640f388107943f3e510a0e89d5ca51e56d2d0474 (from https://pypi.org/simple/redis/), version: 2.7.1\n",
            "    Found link https://files.pythonhosted.org/packages/cd/d0/9b96b359e5c7ff74954f5e55716986d51505f8a6f8a1d4be45138118e820/redis-2.7.2.tar.gz#sha256=c22e7129f21b8bd1690c2cefc07b2caf1088c66a9dd159aed0621dcbaf2dfb09 (from https://pypi.org/simple/redis/), version: 2.7.2\n",
            "    Found link https://files.pythonhosted.org/packages/eb/de/b49b23b4d846893fc2739215cabe01502e47d0827aa50823c8c4e0024234/redis-2.7.3.tar.gz#sha256=3cf41f108f9b0ebd0ae01adc85cf54bafc6825d47b8eda9461235ad68b6fad6f (from https://pypi.org/simple/redis/), version: 2.7.3\n",
            "    Found link https://files.pythonhosted.org/packages/e6/b3/dbccca3a0448355b1dac1f60dbaa8cea9ca8a861e5b373b1d8b67a1a18da/redis-2.7.4.tar.gz#sha256=623c8d437401314f8ec92f03848638c79c757098b316f0ed40ec2deaad57e082 (from https://pypi.org/simple/redis/), version: 2.7.4\n",
            "    Found link https://files.pythonhosted.org/packages/a8/5c/5aa66491fee70ca39d9ba9616a6fe21d786694bcedbbf82e2dd754933c9c/redis-2.7.5.tar.gz#sha256=6c25b05411014ad11feb4869a8c5e5facc900640c597a288bcd3de6a2ab8948a (from https://pypi.org/simple/redis/), version: 2.7.5\n",
            "    Found link https://files.pythonhosted.org/packages/e7/6f/446e6d3cbb6f43d5f73de1be12cd8d033a6f4456ddd8a9dc4cdbd53b389f/redis-2.7.6.tar.gz#sha256=7e8645a5e1a5e36fb6f93d3113eb078e2763db15aafa3dfa5ba2ceace26a01c4 (from https://pypi.org/simple/redis/), version: 2.7.6\n",
            "    Found link https://files.pythonhosted.org/packages/88/5c/c824aa98a1af813332a5e213dbc49cc71c06cef5b5beb8cb237658daf77b/redis-2.8.0.tar.gz#sha256=5a34f92937cacb4082f5834d2ce8b710b791342d17d1769b998327e6479e2b24 (from https://pypi.org/simple/redis/), version: 2.8.0\n",
            "    Found link https://files.pythonhosted.org/packages/94/e5/c6ad0e5b49b40f8e42adbcdfff0f7d3fc16ea7735d225db4f3c60bf542b9/redis-2.9.0.tar.gz#sha256=074660926e3069607abac6da7f39e7511eda2662a0f792140ffff76b2220d7f9 (from https://pypi.org/simple/redis/), version: 2.9.0\n",
            "    Found link https://files.pythonhosted.org/packages/64/6b/75e4176d3b0a427baeaccc958ddfe34308889823cb360cdd8a8b9723d7d6/redis-2.9.1.tar.gz#sha256=af9747ec2727425b1b09252975e21502ee5a3d8d235c7f49869eb13e09ccf4e4 (from https://pypi.org/simple/redis/), version: 2.9.1\n",
            "    Found link https://files.pythonhosted.org/packages/85/84/080ce20bd95010987f25a42ac357fed747be949ca392a604f3efec5956d4/redis-2.10.0.tar.gz#sha256=573a02d457d3eab51d6d849dead1a0fe220cfb129b3bb1579f28c46a6544beb5 (from https://pypi.org/simple/redis/), version: 2.10.0\n",
            "    Found link https://files.pythonhosted.org/packages/1d/f5/408d16f977e7e8b27353923a5f119fe0eea4b20d2909c2ae4e556988d8ed/redis-2.10.1.tar.gz#sha256=644aaf429e666d2254143a6a02f3b1cca2806d0cd52bb130c8f879d3c8259d62 (from https://pypi.org/simple/redis/), version: 2.10.1\n",
            "    Found link https://files.pythonhosted.org/packages/3d/9b/49a944d4d3c350f7cffc86bcc8ec429249fb7f413a2cb28e31bc79cfc813/redis-2.10.2.tar.gz#sha256=4af2f22e511b80cde3b9ff27d6afa6f138a37df7b05cc522953c30473b15c951 (from https://pypi.org/simple/redis/), version: 2.10.2\n",
            "    Found link https://files.pythonhosted.org/packages/37/a8/42e2f2785339cd0a4b4f42316b767ccbf68acf05eb1ba20d737599cccecd/redis-2.10.3.tar.gz#sha256=a4fb37b02860f6b1617f6469487471fd086dd2d38bbce640c2055862b9c4019c (from https://pypi.org/simple/redis/), version: 2.10.3\n",
            "    Found link https://files.pythonhosted.org/packages/08/c1/457428f7507e27ba7144758a7b716ea35766e6d602f4a0c16e443ab3d381/redis-2.10.5-py2.py3-none-any.whl#sha256=97156b37d7cda4e7d8658be1148c983984e1a975090ba458cc7e244025191dbd (from https://pypi.org/simple/redis/), version: 2.10.5\n",
            "    Found link https://files.pythonhosted.org/packages/68/44/5efe9e98ad83ef5b742ce62a15bea609ed5a0d1caf35b79257ddb324031a/redis-2.10.5.tar.gz#sha256=5dfbae6acfc54edf0a7a415b99e0b21c0a3c27a7f787b292eea727b1facc5533 (from https://pypi.org/simple/redis/), version: 2.10.5\n",
            "    Found link https://files.pythonhosted.org/packages/3b/f6/7a76333cf0b9251ecf49efff635015171843d9b977e4ffcf59f9c4428052/redis-2.10.6-py2.py3-none-any.whl#sha256=8a1900a9f2a0a44ecf6e8b5eb3e967a9909dfed219ad66df094f27f7d6f330fb (from https://pypi.org/simple/redis/), version: 2.10.6\n",
            "    Found link https://files.pythonhosted.org/packages/09/8d/6d34b75326bf96d4139a2ddd8e74b80840f800a0a79f9294399e212cb9a7/redis-2.10.6.tar.gz#sha256=a22ca993cea2962dbb588f9f30d0015ac4afcc45bee27d3978c0dbe9e97c6c0f (from https://pypi.org/simple/redis/), version: 2.10.6\n",
            "    Found link https://files.pythonhosted.org/packages/7d/42/a4ae7fa2e0aa41cf1ee6bac741cd8fff03b41b1155bbbdeb597c47a23403/redis-3.0.0-py2.py3-none-any.whl#sha256=909b50e34b9780cf9201f4a11d4572952141a4da9f8740c561b2befd59dfd8de (from https://pypi.org/simple/redis/) (requires-python:>=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*), version: 3.0.0\n",
            "    Found link https://files.pythonhosted.org/packages/dd/8f/2d35634acb3bb7b6546d00c0f34ecbe8a9c52b529e6c5a7b26f9a5273851/redis-3.0.0.tar.gz#sha256=78815017ef63db5f42f3e1207f50ffd07b4b4b98ba7ffe78da59b8543b1e9a27 (from https://pypi.org/simple/redis/) (requires-python:>=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*), version: 3.0.0\n",
            "    Found link https://files.pythonhosted.org/packages/19/cb/b829eb876be33bfe6700a3ef23df4749d758f5da0d337e06576c05e6006f/redis-3.0.0.post1-py2.py3-none-any.whl#sha256=abfbc9a18e9388f3de53d2ae90b174669d50e289fef90850177e63af902ea992 (from https://pypi.org/simple/redis/) (requires-python:>=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*), version: 3.0.0.post1\n",
            "    Found link https://files.pythonhosted.org/packages/da/09/bacdb83e6f8d75ec56049ab302ecdc2d45384da36774ea500c2db62f72b0/redis-3.0.0.post1.tar.gz#sha256=03b1b3d5c360091760666a2865ca60fcfbcfc5b54d0c4df21728e94c96caa7cb (from https://pypi.org/simple/redis/) (requires-python:>=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*), version: 3.0.0.post1\n",
            "    Found link https://files.pythonhosted.org/packages/f5/00/5253aff5e747faf10d8ceb35fb5569b848cde2fdc13685d42fcf63118bbc/redis-3.0.1-py2.py3-none-any.whl#sha256=8e0bdd2de02e829b6225b25646f9fb9daffea99a252610d040409a6738541f0a (from https://pypi.org/simple/redis/) (requires-python:>=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*), version: 3.0.1\n",
            "    Found link https://files.pythonhosted.org/packages/4a/1b/9b40393630954b54a4182ca65a9cf80b41803108fcae435ffd6af57af5ae/redis-3.0.1.tar.gz#sha256=2100750629beff143b6a200a2ea8e719fcf26420adabb81402895e144c5083cf (from https://pypi.org/simple/redis/) (requires-python:>=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*), version: 3.0.1\n",
            "    Found link https://files.pythonhosted.org/packages/f1/19/a0282b77c23f9f9dbcc6480787a60807c78a45947593a02dbf026636c90d/redis-3.1.0-py2.py3-none-any.whl#sha256=74c892041cba46078ae1ef845241548baa3bd3634f9a6f0f952f006eb1619c71 (from https://pypi.org/simple/redis/) (requires-python:>=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*), version: 3.1.0\n",
            "    Found link https://files.pythonhosted.org/packages/91/5c/7d140c6d996680177bb64b9ee5f511de06ebd9b2495588182721cb708549/redis-3.1.0.tar.gz#sha256=7ba8612bbfd966dea8c62322543fed0095da2834dbd5a7c124afbc617a156aa7 (from https://pypi.org/simple/redis/) (requires-python:>=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*), version: 3.1.0\n",
            "    Found link https://files.pythonhosted.org/packages/d0/8b/c43ef27d02382853b22c49bc41a8389e47d60811dd1d72b9a45bc905a5f8/redis-3.2.0-py2.py3-none-any.whl#sha256=9b19425a38fd074eb5795ff2b0d9a55b46a44f91f5347995f27e3ad257a7d775 (from https://pypi.org/simple/redis/) (requires-python:>=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*), version: 3.2.0\n",
            "    Found link https://files.pythonhosted.org/packages/38/75/06ce149efb17817c9ad2428c571372cf2c31b28cee8a4199994ba8fab954/redis-3.2.0.tar.gz#sha256=724932360d48e5407e8f82e405ab3650a36ed02c7e460d1e6fddf0f038422b54 (from https://pypi.org/simple/redis/) (requires-python:>=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*), version: 3.2.0\n",
            "    Found link https://files.pythonhosted.org/packages/ac/a7/cff10cc5f1180834a3ed564d148fb4329c989cbb1f2e196fc9a10fa07072/redis-3.2.1-py2.py3-none-any.whl#sha256=6946b5dca72e86103edc8033019cc3814c031232d339d5f4533b02ea85685175 (from https://pypi.org/simple/redis/) (requires-python:>=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*), version: 3.2.1\n",
            "    Found link https://files.pythonhosted.org/packages/24/d4/06486dee0f66ef8c5080dc576fdfb33131fd2e0be3747f2be4e5634088a2/redis-3.2.1.tar.gz#sha256=8ca418d2ddca1b1a850afa1680a7d2fd1f3322739271de4b704e0d4668449273 (from https://pypi.org/simple/redis/) (requires-python:>=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*), version: 3.2.1\n",
            "  Using version 3.2.1 (newest of versions: 0.6.0, 0.6.1, 1.34, 1.34.1, 2.0.0, 2.2.0, 2.2.2, 2.2.4, 2.4.0, 2.4.1, 2.4.2, 2.4.3, 2.4.4, 2.4.5, 2.4.6, 2.4.7, 2.4.8, 2.4.9, 2.4.10, 2.4.11, 2.4.12, 2.4.13, 2.6.0, 2.6.1, 2.6.2, 2.7.0, 2.7.1, 2.7.2, 2.7.3, 2.7.4, 2.7.5, 2.7.6, 2.8.0, 2.9.0, 2.9.1, 2.10.0, 2.10.1, 2.10.2, 2.10.3, 2.10.5, 2.10.6, 3.0.0, 3.0.0.post1, 3.0.1, 3.1.0, 3.2.0, 3.2.1)\n",
            "  Created temporary directory: /tmp/pip-unpack-2epxd7k0\n",
            "  Looking up \"https://files.pythonhosted.org/packages/ac/a7/cff10cc5f1180834a3ed564d148fb4329c989cbb1f2e196fc9a10fa07072/redis-3.2.1-py2.py3-none-any.whl\" in the cache\n",
            "  No cache entry available\n",
            "  https://files.pythonhosted.org:443 \"GET /packages/ac/a7/cff10cc5f1180834a3ed564d148fb4329c989cbb1f2e196fc9a10fa07072/redis-3.2.1-py2.py3-none-any.whl HTTP/1.1\" 200 65295\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/a7/cff10cc5f1180834a3ed564d148fb4329c989cbb1f2e196fc9a10fa07072/redis-3.2.1-py2.py3-none-any.whl (65kB)\n",
            "  Downloading from URL https://files.pythonhosted.org/packages/ac/a7/cff10cc5f1180834a3ed564d148fb4329c989cbb1f2e196fc9a10fa07072/redis-3.2.1-py2.py3-none-any.whl#sha256=6946b5dca72e86103edc8033019cc3814c031232d339d5f4533b02ea85685175 (from https://pypi.org/simple/redis/) (requires-python:>=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*)\n",
            "\u001b[K     |██████████████████████████████  | 61kB 5.2MB/s eta 0:00:01  Ignoring unknown cache-control directive: immutable\n",
            "  Updating cache with response from \"https://files.pythonhosted.org/packages/ac/a7/cff10cc5f1180834a3ed564d148fb4329c989cbb1f2e196fc9a10fa07072/redis-3.2.1-py2.py3-none-any.whl\"\n",
            "  Caching due to etag\n",
            "\u001b[K     |████████████████████████████████| 71kB 5.3MB/s \n",
            "\u001b[?25h  Added redis from https://files.pythonhosted.org/packages/ac/a7/cff10cc5f1180834a3ed564d148fb4329c989cbb1f2e196fc9a10fa07072/redis-3.2.1-py2.py3-none-any.whl#sha256=6946b5dca72e86103edc8033019cc3814c031232d339d5f4533b02ea85685175 (from ray==0.7.0) to build tracker '/tmp/pip-req-tracker-yv1_hsbl'\n",
            "  Removed redis from https://files.pythonhosted.org/packages/ac/a7/cff10cc5f1180834a3ed564d148fb4329c989cbb1f2e196fc9a10fa07072/redis-3.2.1-py2.py3-none-any.whl#sha256=6946b5dca72e86103edc8033019cc3814c031232d339d5f4533b02ea85685175 (from ray==0.7.0) from build tracker '/tmp/pip-req-tracker-yv1_hsbl'\n",
            "Requirement already satisfied: six>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from ray==0.7.0) (1.12.0)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from ray==0.7.0) (3.6.6)\n",
            "Collecting flatbuffers (from ray==0.7.0)\n",
            "  1 location(s) to search for versions of flatbuffers:\n",
            "  * https://pypi.org/simple/flatbuffers/\n",
            "  Getting page https://pypi.org/simple/flatbuffers/\n",
            "  Looking up \"https://pypi.org/simple/flatbuffers/\" in the cache\n",
            "  Request header has \"max_age\" as 0, cache bypassed\n",
            "  https://pypi.org:443 \"GET /simple/flatbuffers/ HTTP/1.1\" 200 767\n",
            "  Updating cache with response from \"https://pypi.org/simple/flatbuffers/\"\n",
            "  Caching due to etag\n",
            "  Analyzing links from page https://pypi.org/simple/flatbuffers/\n",
            "    Found link https://files.pythonhosted.org/packages/70/fd/d00eb65ec0e89258aec231af3b86539e6e7ba0c553dfeacd018ccee31eba/flatbuffers-1.9-py2.py3-none-any.whl#sha256=b7d616472cccd43097706719cb8aee5063b3f7f134e78fda0a0171b2acef7741 (from https://pypi.org/simple/flatbuffers/), version: 1.9\n",
            "    Found link https://files.pythonhosted.org/packages/13/21/68e38fddb9271ae4f070bdd9315b44efbb37f46c3ec11bcbe56240578865/flatbuffers-1.9.tar.gz#sha256=5f9f88ecac3d44909eada8614920b3765ff4315a1f6f0fec7898eb337902eae2 (from https://pypi.org/simple/flatbuffers/), version: 1.9\n",
            "    Found link https://files.pythonhosted.org/packages/21/9a/b0f3302f994b58bc26ebcc39218c14e33d8fa1bd96b7ba709597aff7507c/flatbuffers-1.10-py2.py3-none-any.whl#sha256=1d367990cbf0ab3b7e9458b81793aa4875082bae2ad497911410f5d1f9234caa (from https://pypi.org/simple/flatbuffers/), version: 1.10\n",
            "    Found link https://files.pythonhosted.org/packages/f9/b8/e1c19502de48f4126151f139b1d311f439fe295530295fce5a30b5784ad4/flatbuffers-1.10.tar.gz#sha256=91800165bedd4efbb4d3a60a7007d2124514faf7f6d85919f7023b74b503445d (from https://pypi.org/simple/flatbuffers/), version: 1.10\n",
            "    Found link https://files.pythonhosted.org/packages/c9/84/adf5837f96c39990bc55afdfddf460b38b4562f50341359afa32e4a98de7/flatbuffers-1.11-py2.py3-none-any.whl#sha256=776a959c5f70b41819fa75de44ed14fd984fa1a79b378f27e6f4fff338cbdca2 (from https://pypi.org/simple/flatbuffers/), version: 1.11\n",
            "    Found link https://files.pythonhosted.org/packages/c6/b6/21478b76aa7ccab58da3beb85746b6844dee2112c0cc25b51ec64b46bdbb/flatbuffers-1.11.tar.gz#sha256=f24185db54193540e3d684dc98aa7c2d89882341641548ceb36fd2589fef6c4e (from https://pypi.org/simple/flatbuffers/), version: 1.11\n",
            "  Using version 1.11 (newest of versions: 1.9, 1.10, 1.11)\n",
            "  Created temporary directory: /tmp/pip-unpack-3tt7n80y\n",
            "  Looking up \"https://files.pythonhosted.org/packages/c9/84/adf5837f96c39990bc55afdfddf460b38b4562f50341359afa32e4a98de7/flatbuffers-1.11-py2.py3-none-any.whl\" in the cache\n",
            "  No cache entry available\n",
            "  https://files.pythonhosted.org:443 \"GET /packages/c9/84/adf5837f96c39990bc55afdfddf460b38b4562f50341359afa32e4a98de7/flatbuffers-1.11-py2.py3-none-any.whl HTTP/1.1\" 200 15665\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/84/adf5837f96c39990bc55afdfddf460b38b4562f50341359afa32e4a98de7/flatbuffers-1.11-py2.py3-none-any.whl\n",
            "  Downloading from URL https://files.pythonhosted.org/packages/c9/84/adf5837f96c39990bc55afdfddf460b38b4562f50341359afa32e4a98de7/flatbuffers-1.11-py2.py3-none-any.whl#sha256=776a959c5f70b41819fa75de44ed14fd984fa1a79b378f27e6f4fff338cbdca2 (from https://pypi.org/simple/flatbuffers/)\n",
            "  Ignoring unknown cache-control directive: immutable\n",
            "  Updating cache with response from \"https://files.pythonhosted.org/packages/c9/84/adf5837f96c39990bc55afdfddf460b38b4562f50341359afa32e4a98de7/flatbuffers-1.11-py2.py3-none-any.whl\"\n",
            "  Caching due to etag\n",
            "  Added flatbuffers from https://files.pythonhosted.org/packages/c9/84/adf5837f96c39990bc55afdfddf460b38b4562f50341359afa32e4a98de7/flatbuffers-1.11-py2.py3-none-any.whl#sha256=776a959c5f70b41819fa75de44ed14fd984fa1a79b378f27e6f4fff338cbdca2 (from ray==0.7.0) to build tracker '/tmp/pip-req-tracker-yv1_hsbl'\n",
            "  Removed flatbuffers from https://files.pythonhosted.org/packages/c9/84/adf5837f96c39990bc55afdfddf460b38b4562f50341359afa32e4a98de7/flatbuffers-1.11-py2.py3-none-any.whl#sha256=776a959c5f70b41819fa75de44ed14fd984fa1a79b378f27e6f4fff338cbdca2 (from ray==0.7.0) from build tracker '/tmp/pip-req-tracker-yv1_hsbl'\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->ray==0.7.0) (41.0.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->ray==0.7.0) (1.3.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->ray==0.7.0) (0.7.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->ray==0.7.0) (19.1.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->ray==0.7.0) (7.0.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->ray==0.7.0) (1.8.0)\n",
            "Installing collected packages: funcsigs, colorama, redis, flatbuffers, ray\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  Running setup.py develop for ray\n",
            "    Running command /usr/bin/python3 -c 'import setuptools, tokenize;__file__='\"'\"'/content/ray-distr/python/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' develop --no-deps\n",
            "    running develop\n",
            "    running egg_info\n",
            "    writing ray.egg-info/PKG-INFO\n",
            "    writing dependency_links to ray.egg-info/dependency_links.txt\n",
            "    writing entry points to ray.egg-info/entry_points.txt\n",
            "    writing requirements to ray.egg-info/requires.txt\n",
            "    writing top-level names to ray.egg-info/top_level.txt\n",
            "    writing manifest file 'ray.egg-info/SOURCES.txt'\n",
            "    running build_ext\n",
            "    + set -e\n",
            "    +++ dirname ../build.sh\n",
            "    ++ cd ..\n",
            "    ++ pwd\n",
            "    + ROOT_DIR=/content/ray-distr\n",
            "    ++ uname\n",
            "    + unamestr=Linux\n",
            "    + [[ Linux == \\L\\i\\n\\u\\x ]]\n",
            "    + PARALLEL=1\n",
            "    + RAY_BUILD_PYTHON=YES\n",
            "    + RAY_BUILD_JAVA=NO\n",
            "    + PYTHON_EXECUTABLE=\n",
            "    + BUILD_DIR=\n",
            "    + [[ 2 -gt 0 ]]\n",
            "    + key=-p\n",
            "    + case $key in\n",
            "    + PYTHON_EXECUTABLE=/usr/bin/python3\n",
            "    + shift\n",
            "    + shift\n",
            "    + [[ 0 -gt 0 ]]\n",
            "    + [[ -z /usr/bin/python3 ]]\n",
            "    + echo 'Using Python executable /usr/bin/python3.'\n",
            "    Using Python executable /usr/bin/python3.\n",
            "    ++ PATH=/usr/local/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin:/root/.bazel/bin\n",
            "    ++ which bazel\n",
            "    + BAZEL_EXECUTABLE=/root/.bazel/bin/bazel\n",
            "    + echo 'Using Bazel executable /root/.bazel/bin/bazel.'\n",
            "    Using Bazel executable /root/.bazel/bin/bazel.\n",
            "    + RAY_BUILD_PYTHON=YES\n",
            "    + RAY_BUILD_JAVA=NO\n",
            "    + bash /content/ray-distr/setup_thirdparty.sh /usr/bin/python3\n",
            "    + set -e\n",
            "    +++ dirname /content/ray-distr/setup_thirdparty.sh\n",
            "    ++ cd /content/ray-distr\n",
            "    ++ pwd\n",
            "    + ROOT_DIR=/content/ray-distr\n",
            "    + [[ -z /usr/bin/python3 ]]\n",
            "    + PYTHON_EXECUTABLE=/usr/bin/python3\n",
            "    + echo 'Using Python executable /usr/bin/python3.'\n",
            "    Using Python executable /usr/bin/python3.\n",
            "    + RAY_BUILD_PYTHON=YES\n",
            "    + RAY_BUILD_JAVA=NO\n",
            "    + /content/ray-distr/thirdparty/scripts/setup.sh /usr/bin/python3\n",
            "    + set -e\n",
            "    +++ dirname /content/ray-distr/thirdparty/scripts/setup.sh\n",
            "    ++ cd /content/ray-distr/thirdparty/scripts\n",
            "    ++ pwd\n",
            "    + TP_SCRIPT_DIR=/content/ray-distr/thirdparty/scripts\n",
            "    + TP_DIR=/content/ray-distr/thirdparty/scripts/..\n",
            "    + mkdir -p /content/ray-distr/thirdparty/scripts/../build\n",
            "    + mkdir -p /content/ray-distr/thirdparty/scripts/../pkg\n",
            "    + [[ -z /usr/bin/python3 ]]\n",
            "    + PYTHON_EXECUTABLE=/usr/bin/python3\n",
            "    + echo 'Using Python executable /usr/bin/python3.'\n",
            "    Using Python executable /usr/bin/python3.\n",
            "    + [[ NO == \\Y\\E\\S ]]\n",
            "    + [[ YES == \\Y\\E\\S ]]\n",
            "    + echo 'Python library will be built.'\n",
            "    Python library will be built.\n",
            "    ++ uname\n",
            "    + unamestr=Linux\n",
            "    + bash /content/ray-distr/thirdparty/scripts/build_redis.sh\n",
            "    + set -e\n",
            "    +++ dirname /content/ray-distr/thirdparty/scripts/build_redis.sh\n",
            "    ++ cd /content/ray-distr/thirdparty/scripts\n",
            "    ++ pwd\n",
            "    + TP_DIR=/content/ray-distr/thirdparty/scripts/../\n",
            "    + '[' '!' -f /content/ray-distr/thirdparty/scripts/..//pkg/redis/src/redis-server ']'\n",
            "    + redis_vname=5.0.3\n",
            "    + '[' '!' -f /content/ray-distr/thirdparty/scripts/..//pkg/redis/utils/whatisdoing.sh ']'\n",
            "    + mkdir -p /content/ray-distr/thirdparty/scripts/..//pkg/redis\n",
            "    + curl -sL https://github.com/antirez/redis/archive/5.0.3.tar.gz\n",
            "    + tar xz --strip-components=1 -C /content/ray-distr/thirdparty/scripts/..//pkg/redis\n",
            "    + pushd /content/ray-distr/thirdparty/scripts/..//pkg/redis\n",
            "    /content/ray-distr/thirdparty/pkg/redis /content/ray-distr/python\n",
            "    + make\n",
            "    cd src && make all\n",
            "    make[1]: Entering directory '/content/ray-distr/thirdparty/pkg/redis/src'\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mMakefile.dep\u001b[0m\n",
            "    rm -rf redis-server redis-sentinel redis-cli redis-benchmark redis-check-rdb redis-check-aof *.o *.gcda *.gcno *.gcov redis.info lcov-html Makefile.dep dict-benchmark\n",
            "    (cd ../deps && make distclean)\n",
            "    make[2]: Entering directory '/content/ray-distr/thirdparty/pkg/redis/deps'\n",
            "    (cd hiredis && make clean) > /dev/null || true\n",
            "    (cd linenoise && make clean) > /dev/null || true\n",
            "    (cd lua && make clean) > /dev/null || true\n",
            "    (cd jemalloc && [ -f Makefile ] && make distclean) > /dev/null || true\n",
            "    (rm -f .make-*)\n",
            "    make[2]: Leaving directory '/content/ray-distr/thirdparty/pkg/redis/deps'\n",
            "    (rm -f .make-*)\n",
            "    echo STD=-std=c99 -pedantic -DREDIS_STATIC='' >> .make-settings\n",
            "    echo WARN=-Wall -W -Wno-missing-field-initializers >> .make-settings\n",
            "    echo OPT=-O2 >> .make-settings\n",
            "    echo MALLOC=jemalloc >> .make-settings\n",
            "    echo CFLAGS= >> .make-settings\n",
            "    echo LDFLAGS= >> .make-settings\n",
            "    echo REDIS_CFLAGS= >> .make-settings\n",
            "    echo REDIS_LDFLAGS= >> .make-settings\n",
            "    echo PREV_FINAL_CFLAGS=-std=c99 -pedantic -DREDIS_STATIC='' -Wall -W -Wno-missing-field-initializers -O2 -g -ggdb   -I../deps/hiredis -I../deps/linenoise -I../deps/lua/src -DUSE_JEMALLOC -I../deps/jemalloc/include >> .make-settings\n",
            "    echo PREV_FINAL_LDFLAGS=  -g -ggdb -rdynamic >> .make-settings\n",
            "    (cd ../deps && make hiredis linenoise lua jemalloc)\n",
            "    make[2]: Entering directory '/content/ray-distr/thirdparty/pkg/redis/deps'\n",
            "    (cd hiredis && make clean) > /dev/null || true\n",
            "    (cd linenoise && make clean) > /dev/null || true\n",
            "    (cd lua && make clean) > /dev/null || true\n",
            "    (cd jemalloc && [ -f Makefile ] && make distclean) > /dev/null || true\n",
            "    (rm -f .make-*)\n",
            "    (echo \"\" > .make-cflags)\n",
            "    (echo \"\" > .make-ldflags)\n",
            "    \u001b[32;1mMAKE\u001b[0m \u001b[37;1mhiredis\u001b[0m\n",
            "    cd hiredis && make static\n",
            "    make[3]: Entering directory '/content/ray-distr/thirdparty/pkg/redis/deps/hiredis'\n",
            "    cc -std=c99 -pedantic -c -O3 -fPIC  -Wall -W -Wstrict-prototypes -Wwrite-strings -g -ggdb  net.c\n",
            "    cc -std=c99 -pedantic -c -O3 -fPIC  -Wall -W -Wstrict-prototypes -Wwrite-strings -g -ggdb  hiredis.c\n",
            "    cc -std=c99 -pedantic -c -O3 -fPIC  -Wall -W -Wstrict-prototypes -Wwrite-strings -g -ggdb  sds.c\n",
            "    cc -std=c99 -pedantic -c -O3 -fPIC  -Wall -W -Wstrict-prototypes -Wwrite-strings -g -ggdb  async.c\n",
            "    cc -std=c99 -pedantic -c -O3 -fPIC  -Wall -W -Wstrict-prototypes -Wwrite-strings -g -ggdb  read.c\n",
            "    ar rcs libhiredis.a net.o hiredis.o sds.o async.o read.o\n",
            "    make[3]: Leaving directory '/content/ray-distr/thirdparty/pkg/redis/deps/hiredis'\n",
            "    \u001b[32;1mMAKE\u001b[0m \u001b[37;1mlinenoise\u001b[0m\n",
            "    cd linenoise && make\n",
            "    make[3]: Entering directory '/content/ray-distr/thirdparty/pkg/redis/deps/linenoise'\n",
            "    cc  -Wall -Os -g  -c linenoise.c\n",
            "    make[3]: Leaving directory '/content/ray-distr/thirdparty/pkg/redis/deps/linenoise'\n",
            "    \u001b[32;1mMAKE\u001b[0m \u001b[37;1mlua\u001b[0m\n",
            "    cd lua/src && make all CFLAGS=\"-O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC='' \" MYLDFLAGS=\"\" AR=\"ar rcu\"\n",
            "    make[3]: Entering directory '/content/ray-distr/thirdparty/pkg/redis/deps/lua/src'\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o lapi.o lapi.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o lcode.o lcode.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o ldebug.o ldebug.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o ldo.o ldo.c\n",
            "    ldo.c: In function ‘f_parser’:\n",
            "    ldo.c:496:7: warning: unused variable ‘c’ [-Wunused-variable]\n",
            "       int c = luaZ_lookahead(p->z);\n",
            "           ^\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o ldump.o ldump.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o lfunc.o lfunc.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o lgc.o lgc.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o llex.o llex.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o lmem.o lmem.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o lobject.o lobject.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o lopcodes.o lopcodes.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o lparser.o lparser.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o lstate.o lstate.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o lstring.o lstring.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o ltable.o ltable.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o ltm.o ltm.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o lundump.o lundump.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o lvm.o lvm.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o lzio.o lzio.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o strbuf.o strbuf.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o fpconv.o fpconv.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o lauxlib.o lauxlib.c\n",
            "    lauxlib.c: In function ‘luaL_loadfile’:\n",
            "    lauxlib.c:577:4: warning: this ‘while’ clause does not guard... [-Wmisleading-indentation]\n",
            "        while ((c = getc(lf.f)) != EOF && c != LUA_SIGNATURE[0]) ;\n",
            "        ^~~~~\n",
            "    lauxlib.c:578:5: note: ...this statement, but the latter is misleadingly indented as if it were guarded by the ‘while’\n",
            "         lf.extraline = 0;\n",
            "         ^~\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o lbaselib.o lbaselib.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o ldblib.o ldblib.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o liolib.o liolib.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o lmathlib.o lmathlib.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o loslib.o loslib.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o ltablib.o ltablib.c\n",
            "    ltablib.c: In function ‘addfield’:\n",
            "    ltablib.c:137:3: warning: this ‘if’ clause does not guard... [-Wmisleading-indentation]\n",
            "       if (!lua_isstring(L, -1))\n",
            "       ^~\n",
            "    ltablib.c:140:5: note: ...this statement, but the latter is misleadingly indented as if it were guarded by the ‘if’\n",
            "         luaL_addvalue(b);\n",
            "         ^~~~~~~~~~~~~\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o lstrlib.o lstrlib.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o loadlib.o loadlib.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o linit.o linit.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o lua_cjson.o lua_cjson.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o lua_struct.o lua_struct.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o lua_cmsgpack.o lua_cmsgpack.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o lua_bit.o lua_bit.c\n",
            "    ar rcu liblua.a lapi.o lcode.o ldebug.o ldo.o ldump.o lfunc.o lgc.o llex.o lmem.o lobject.o lopcodes.o lparser.o lstate.o lstring.o ltable.o ltm.o lundump.o lvm.o lzio.o strbuf.o fpconv.o lauxlib.o lbaselib.o ldblib.o liolib.o lmathlib.o loslib.o ltablib.o lstrlib.o loadlib.o linit.o lua_cjson.o lua_struct.o lua_cmsgpack.o lua_bit.o\t# DLL needs all object files\n",
            "    ar: `u' modifier ignored since `D' is the default (see `U')\n",
            "    ranlib liblua.a\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o lua.o lua.c\n",
            "    cc -o lua  lua.o liblua.a -lm\n",
            "    liblua.a(loslib.o): In function `os_tmpname':\n",
            "    loslib.c:(.text+0x290): warning: the use of `tmpnam' is dangerous, better use `mkstemp'\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o luac.o luac.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o print.o print.c\n",
            "    cc -o luac  luac.o print.o liblua.a -lm\n",
            "    make[3]: Leaving directory '/content/ray-distr/thirdparty/pkg/redis/deps/lua/src'\n",
            "    \u001b[32;1mMAKE\u001b[0m \u001b[37;1mjemalloc\u001b[0m\n",
            "    cd jemalloc && ./configure --with-version=5.1.0-0-g0 --with-lg-quantum=3 --with-jemalloc-prefix=je_ --enable-cc-silence CFLAGS=\"-std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops \" LDFLAGS=\"\"\n",
            "    configure: WARNING: unrecognized options: --enable-cc-silence\n",
            "    checking for xsltproc... false\n",
            "    checking for gcc... gcc\n",
            "    checking whether the C compiler works... yes\n",
            "    checking for C compiler default output file name... a.out\n",
            "    checking for suffix of executables...\n",
            "    checking whether we are cross compiling... no\n",
            "    checking for suffix of object files... o\n",
            "    checking whether we are using the GNU C compiler... yes\n",
            "    checking whether gcc accepts -g... yes\n",
            "    checking for gcc option to accept ISO C89... none needed\n",
            "    checking whether compiler is cray... no\n",
            "    checking whether compiler supports -std=gnu11... yes\n",
            "    checking whether compiler supports -Wall... yes\n",
            "    checking whether compiler supports -Wshorten-64-to-32... no\n",
            "    checking whether compiler supports -Wsign-compare... yes\n",
            "    checking whether compiler supports -Wundef... yes\n",
            "    checking whether compiler supports -Wno-format-zero-length... yes\n",
            "    checking whether compiler supports -pipe... yes\n",
            "    checking whether compiler supports -g3... yes\n",
            "    checking how to run the C preprocessor... gcc -E\n",
            "    checking for g++... g++\n",
            "    checking whether we are using the GNU C++ compiler... yes\n",
            "    checking whether g++ accepts -g... yes\n",
            "    checking whether g++ supports C++14 features by default... yes\n",
            "    checking whether compiler supports -Wall... yes\n",
            "    checking whether compiler supports -g3... yes\n",
            "    checking whether libstdc++ linkage is compilable... yes\n",
            "    checking for grep that handles long lines and -e... /bin/grep\n",
            "    checking for egrep... /bin/grep -E\n",
            "    checking for ANSI C header files... yes\n",
            "    checking for sys/types.h... yes\n",
            "    checking for sys/stat.h... yes\n",
            "    checking for stdlib.h... yes\n",
            "    checking for string.h... yes\n",
            "    checking for memory.h... yes\n",
            "    checking for strings.h... yes\n",
            "    checking for inttypes.h... yes\n",
            "    checking for stdint.h... yes\n",
            "    checking for unistd.h... yes\n",
            "    checking whether byte ordering is bigendian... no\n",
            "    checking size of void *... 8\n",
            "    checking size of int... 4\n",
            "    checking size of long... 8\n",
            "    checking size of long long... 8\n",
            "    checking size of intmax_t... 8\n",
            "    checking build system type... x86_64-pc-linux-gnu\n",
            "    checking host system type... x86_64-pc-linux-gnu\n",
            "    checking whether pause instruction is compilable... yes\n",
            "    checking number of significant virtual address bits... 48\n",
            "    checking for ar... ar\n",
            "    checking for nm... nm\n",
            "    checking for gawk... no\n",
            "    checking for mawk... mawk\n",
            "    checking malloc.h usability... yes\n",
            "    checking malloc.h presence... yes\n",
            "    checking for malloc.h... yes\n",
            "    checking whether malloc_usable_size definition can use const argument... no\n",
            "    checking for library containing log... -lm\n",
            "    checking whether __attribute__ syntax is compilable... yes\n",
            "    checking whether compiler supports -fvisibility=hidden... yes\n",
            "    checking whether compiler supports -fvisibility=hidden... yes\n",
            "    checking whether compiler supports -Werror... yes\n",
            "    checking whether compiler supports -herror_on_warning... no\n",
            "    checking whether tls_model attribute is compilable... yes\n",
            "    checking whether compiler supports -Werror... yes\n",
            "    checking whether compiler supports -herror_on_warning... no\n",
            "    checking whether alloc_size attribute is compilable... yes\n",
            "    checking whether compiler supports -Werror... yes\n",
            "    checking whether compiler supports -herror_on_warning... no\n",
            "    checking whether format(gnu_printf, ...) attribute is compilable... yes\n",
            "    checking whether compiler supports -Werror... yes\n",
            "    checking whether compiler supports -herror_on_warning... no\n",
            "    checking whether format(printf, ...) attribute is compilable... yes\n",
            "    checking for a BSD-compatible install... /usr/bin/install -c\n",
            "    checking for ranlib... ranlib\n",
            "    checking for ld... /usr/bin/ld\n",
            "    checking for autoconf... false\n",
            "    checking for memalign... yes\n",
            "    checking for valloc... yes\n",
            "    checking whether compiler supports -O3... yes\n",
            "    checking whether compiler supports -O3... yes\n",
            "    checking whether compiler supports -funroll-loops... yes\n",
            "    checking configured backtracing method... N/A\n",
            "    checking for sbrk... yes\n",
            "    checking whether utrace(2) is compilable... no\n",
            "    checking whether a program using __builtin_unreachable is compilable... yes\n",
            "    checking whether a program using __builtin_ffsl is compilable... yes\n",
            "    checking LG_PAGE... 12\n",
            "    checking pthread.h usability... yes\n",
            "    checking pthread.h presence... yes\n",
            "    checking for pthread.h... yes\n",
            "    checking for pthread_create in -lpthread... yes\n",
            "    checking dlfcn.h usability... yes\n",
            "    checking dlfcn.h presence... yes\n",
            "    checking for dlfcn.h... yes\n",
            "    checking for dlsym... no\n",
            "    checking for dlsym in -ldl... yes\n",
            "    checking whether pthread_atfork(3) is compilable... yes\n",
            "    checking whether pthread_setname_np(3) is compilable... yes\n",
            "    checking for library containing clock_gettime... none required\n",
            "    checking whether clock_gettime(CLOCK_MONOTONIC_COARSE, ...) is compilable... yes\n",
            "    checking whether clock_gettime(CLOCK_MONOTONIC, ...) is compilable... yes\n",
            "    checking whether mach_absolute_time() is compilable... no\n",
            "    checking whether compiler supports -Werror... yes\n",
            "    checking whether syscall(2) is compilable... yes\n",
            "    checking for secure_getenv... yes\n",
            "    checking for sched_getcpu... yes\n",
            "    checking for sched_setaffinity... yes\n",
            "    checking for issetugid... no\n",
            "    checking for _malloc_thread_cleanup... no\n",
            "    checking for _pthread_mutex_init_calloc_cb... no\n",
            "    checking for TLS... yes\n",
            "    checking whether C11 atomics is compilable... no\n",
            "    checking whether GCC __atomic atomics is compilable... yes\n",
            "    checking whether GCC __sync atomics is compilable... yes\n",
            "    checking whether Darwin OSAtomic*() is compilable... no\n",
            "    checking whether madvise(2) is compilable... yes\n",
            "    checking whether madvise(..., MADV_FREE) is compilable... yes\n",
            "    checking whether madvise(..., MADV_DONTNEED) is compilable... yes\n",
            "    checking whether madvise(..., MADV_DO[NT]DUMP) is compilable... yes\n",
            "    checking whether madvise(..., MADV_[NO]HUGEPAGE) is compilable... yes\n",
            "    checking whether to force 32-bit __sync_{add,sub}_and_fetch()... no\n",
            "    checking whether to force 64-bit __sync_{add,sub}_and_fetch()... no\n",
            "    checking for __builtin_clz... yes\n",
            "    checking whether Darwin os_unfair_lock_*() is compilable... no\n",
            "    checking whether Darwin OSSpin*() is compilable... no\n",
            "    checking whether glibc malloc hook is compilable... yes\n",
            "    checking whether glibc memalign hook is compilable... yes\n",
            "    checking whether pthreads adaptive mutexes is compilable... yes\n",
            "    checking whether compiler supports -D_GNU_SOURCE... yes\n",
            "    checking whether compiler supports -Werror... yes\n",
            "    checking whether compiler supports -herror_on_warning... no\n",
            "    checking whether strerror_r returns char with gnu source is compilable... yes\n",
            "    checking for stdbool.h that conforms to C99... yes\n",
            "    checking for _Bool... yes\n",
            "    configure: creating ./config.status\n",
            "    config.status: creating Makefile\n",
            "    config.status: creating jemalloc.pc\n",
            "    config.status: creating doc/html.xsl\n",
            "    config.status: creating doc/manpages.xsl\n",
            "    config.status: creating doc/jemalloc.xml\n",
            "    config.status: creating include/jemalloc/jemalloc_macros.h\n",
            "    config.status: creating include/jemalloc/jemalloc_protos.h\n",
            "    config.status: creating include/jemalloc/jemalloc_typedefs.h\n",
            "    config.status: creating include/jemalloc/internal/jemalloc_preamble.h\n",
            "    config.status: creating test/test.sh\n",
            "    config.status: creating test/include/test/jemalloc_test.h\n",
            "    config.status: creating config.stamp\n",
            "    config.status: creating bin/jemalloc-config\n",
            "    config.status: creating bin/jemalloc.sh\n",
            "    config.status: creating bin/jeprof\n",
            "    config.status: creating include/jemalloc/jemalloc_defs.h\n",
            "    config.status: creating include/jemalloc/internal/jemalloc_internal_defs.h\n",
            "    config.status: creating test/include/test/jemalloc_test_defs.h\n",
            "    config.status: executing include/jemalloc/internal/public_symbols.txt commands\n",
            "    config.status: executing include/jemalloc/internal/private_symbols.awk commands\n",
            "    config.status: executing include/jemalloc/internal/private_symbols_jet.awk commands\n",
            "    config.status: executing include/jemalloc/internal/public_namespace.h commands\n",
            "    config.status: executing include/jemalloc/internal/public_unnamespace.h commands\n",
            "    config.status: executing include/jemalloc/internal/size_classes.h commands\n",
            "    config.status: executing include/jemalloc/jemalloc_protos_jet.h commands\n",
            "    config.status: executing include/jemalloc/jemalloc_rename.h commands\n",
            "    config.status: executing include/jemalloc/jemalloc_mangle.h commands\n",
            "    config.status: executing include/jemalloc/jemalloc_mangle_jet.h commands\n",
            "    config.status: executing include/jemalloc/jemalloc.h commands\n",
            "    configure: WARNING: unrecognized options: --enable-cc-silence\n",
            "    ===============================================================================\n",
            "    jemalloc version   : 5.1.0-0-g0\n",
            "    library revision   : 2\n",
            "\n",
            "    CONFIG             : --with-version=5.1.0-0-g0 --with-lg-quantum=3 --with-jemalloc-prefix=je_ --enable-cc-silence 'CFLAGS=-std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops ' LDFLAGS=\n",
            "    CC                 : gcc\n",
            "    CONFIGURE_CFLAGS   : -std=gnu11 -Wall -Wsign-compare -Wundef -Wno-format-zero-length -pipe -g3 -fvisibility=hidden -O3 -funroll-loops\n",
            "    SPECIFIED_CFLAGS   : -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops\n",
            "    EXTRA_CFLAGS       :\n",
            "    CPPFLAGS           : -D_GNU_SOURCE -D_REENTRANT\n",
            "    CXX                : g++\n",
            "    CONFIGURE_CXXFLAGS : -Wall -g3 -fvisibility=hidden -O3\n",
            "    SPECIFIED_CXXFLAGS :\n",
            "    EXTRA_CXXFLAGS     :\n",
            "    LDFLAGS            :\n",
            "    EXTRA_LDFLAGS      :\n",
            "    DSO_LDFLAGS        : -shared -Wl,-soname,$(@F)\n",
            "    LIBS               : -lm -lstdc++ -lpthread -ldl\n",
            "    RPATH_EXTRA        :\n",
            "\n",
            "    XSLTPROC           : false\n",
            "    XSLROOT            :\n",
            "\n",
            "    PREFIX             : /usr/local\n",
            "    BINDIR             : /usr/local/bin\n",
            "    DATADIR            : /usr/local/share\n",
            "    INCLUDEDIR         : /usr/local/include\n",
            "    LIBDIR             : /usr/local/lib\n",
            "    MANDIR             : /usr/local/share/man\n",
            "\n",
            "    srcroot            :\n",
            "    abs_srcroot        : /content/ray-distr/thirdparty/pkg/redis/deps/jemalloc/\n",
            "    objroot            :\n",
            "    abs_objroot        : /content/ray-distr/thirdparty/pkg/redis/deps/jemalloc/\n",
            "\n",
            "    JEMALLOC_PREFIX    : je_\n",
            "    JEMALLOC_PRIVATE_NAMESPACE\n",
            "                       : je_\n",
            "    install_suffix     :\n",
            "    malloc_conf        :\n",
            "    autogen            : 0\n",
            "    debug              : 0\n",
            "    stats              : 1\n",
            "    prof               : 0\n",
            "    prof-libunwind     : 0\n",
            "    prof-libgcc        : 0\n",
            "    prof-gcc           : 0\n",
            "    fill               : 1\n",
            "    utrace             : 0\n",
            "    xmalloc            : 0\n",
            "    log                : 0\n",
            "    lazy_lock          : 0\n",
            "    cache-oblivious    : 1\n",
            "    cxx                : 1\n",
            "    ===============================================================================\n",
            "    cd jemalloc && make CFLAGS=\"-std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops \" LDFLAGS=\"\" lib/libjemalloc.a\n",
            "    make[3]: Entering directory '/content/ray-distr/thirdparty/pkg/redis/deps/jemalloc'\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/jemalloc.sym.o src/jemalloc.c\n",
            "    nm -a src/jemalloc.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/jemalloc.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/arena.sym.o src/arena.c\n",
            "    nm -a src/arena.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/arena.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/background_thread.sym.o src/background_thread.c\n",
            "    nm -a src/background_thread.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/background_thread.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/base.sym.o src/base.c\n",
            "    nm -a src/base.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/base.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/bin.sym.o src/bin.c\n",
            "    nm -a src/bin.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/bin.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/bitmap.sym.o src/bitmap.c\n",
            "    nm -a src/bitmap.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/bitmap.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/ckh.sym.o src/ckh.c\n",
            "    nm -a src/ckh.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/ckh.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/ctl.sym.o src/ctl.c\n",
            "    nm -a src/ctl.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/ctl.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/div.sym.o src/div.c\n",
            "    nm -a src/div.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/div.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/extent.sym.o src/extent.c\n",
            "    nm -a src/extent.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/extent.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/extent_dss.sym.o src/extent_dss.c\n",
            "    nm -a src/extent_dss.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/extent_dss.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/extent_mmap.sym.o src/extent_mmap.c\n",
            "    nm -a src/extent_mmap.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/extent_mmap.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/hash.sym.o src/hash.c\n",
            "    nm -a src/hash.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/hash.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/hooks.sym.o src/hooks.c\n",
            "    nm -a src/hooks.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/hooks.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/large.sym.o src/large.c\n",
            "    nm -a src/large.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/large.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/log.sym.o src/log.c\n",
            "    nm -a src/log.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/log.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/malloc_io.sym.o src/malloc_io.c\n",
            "    nm -a src/malloc_io.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/malloc_io.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/mutex.sym.o src/mutex.c\n",
            "    nm -a src/mutex.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/mutex.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/mutex_pool.sym.o src/mutex_pool.c\n",
            "    nm -a src/mutex_pool.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/mutex_pool.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/nstime.sym.o src/nstime.c\n",
            "    nm -a src/nstime.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/nstime.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/pages.sym.o src/pages.c\n",
            "    nm -a src/pages.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/pages.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/prng.sym.o src/prng.c\n",
            "    nm -a src/prng.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/prng.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/prof.sym.o src/prof.c\n",
            "    nm -a src/prof.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/prof.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/rtree.sym.o src/rtree.c\n",
            "    nm -a src/rtree.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/rtree.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/stats.sym.o src/stats.c\n",
            "    nm -a src/stats.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/stats.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/sz.sym.o src/sz.c\n",
            "    nm -a src/sz.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/sz.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/tcache.sym.o src/tcache.c\n",
            "    nm -a src/tcache.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/tcache.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/ticker.sym.o src/ticker.c\n",
            "    nm -a src/ticker.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/ticker.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/tsd.sym.o src/tsd.c\n",
            "    nm -a src/tsd.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/tsd.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/witness.sym.o src/witness.c\n",
            "    nm -a src/witness.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/witness.sym\n",
            "    /bin/sh include/jemalloc/internal/private_namespace.sh src/jemalloc.sym src/arena.sym src/background_thread.sym src/base.sym src/bin.sym src/bitmap.sym src/ckh.sym src/ctl.sym src/div.sym src/extent.sym src/extent_dss.sym src/extent_mmap.sym src/hash.sym src/hooks.sym src/large.sym src/log.sym src/malloc_io.sym src/mutex.sym src/mutex_pool.sym src/nstime.sym src/pages.sym src/prng.sym src/prof.sym src/rtree.sym src/stats.sym src/sz.sym src/tcache.sym src/ticker.sym src/tsd.sym src/witness.sym > include/jemalloc/internal/private_namespace.gen.h\n",
            "    cp include/jemalloc/internal/private_namespace.gen.h include/jemalloc/internal/private_namespace.gen.h\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/jemalloc.o src/jemalloc.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/arena.o src/arena.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/background_thread.o src/background_thread.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/base.o src/base.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/bin.o src/bin.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/bitmap.o src/bitmap.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/ckh.o src/ckh.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/ctl.o src/ctl.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/div.o src/div.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/extent.o src/extent.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/extent_dss.o src/extent_dss.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/extent_mmap.o src/extent_mmap.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/hash.o src/hash.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/hooks.o src/hooks.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/large.o src/large.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/log.o src/log.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/malloc_io.o src/malloc_io.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/mutex.o src/mutex.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/mutex_pool.o src/mutex_pool.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/nstime.o src/nstime.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/pages.o src/pages.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/prng.o src/prng.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/prof.o src/prof.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/rtree.o src/rtree.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/stats.o src/stats.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/sz.o src/sz.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/tcache.o src/tcache.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/ticker.o src/ticker.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/tsd.o src/tsd.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/witness.o src/witness.c\n",
            "    g++ -Wall -g3 -fvisibility=hidden -O3 -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/jemalloc_cpp.o src/jemalloc_cpp.cpp\n",
            "    ar crus lib/libjemalloc.a src/jemalloc.o src/arena.o src/background_thread.o src/base.o src/bin.o src/bitmap.o src/ckh.o src/ctl.o src/div.o src/extent.o src/extent_dss.o src/extent_mmap.o src/hash.o src/hooks.o src/large.o src/log.o src/malloc_io.o src/mutex.o src/mutex_pool.o src/nstime.o src/pages.o src/prng.o src/prof.o src/rtree.o src/stats.o src/sz.o src/tcache.o src/ticker.o src/tsd.o src/witness.o src/jemalloc_cpp.o\n",
            "    ar: `u' modifier ignored since `D' is the default (see `U')\n",
            "    make[3]: Leaving directory '/content/ray-distr/thirdparty/pkg/redis/deps/jemalloc'\n",
            "    make[2]: Leaving directory '/content/ray-distr/thirdparty/pkg/redis/deps'\n",
            "        \u001b[34mCC\u001b[0m \u001b[33madlist.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mquicklist.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mae.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33manet.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mdict.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mserver.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33msds.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mzmalloc.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mlzf_c.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mlzf_d.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mpqsort.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mzipmap.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33msha1.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mziplist.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mrelease.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mnetworking.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mutil.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mobject.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mdb.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mreplication.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mrdb.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mt_string.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mt_list.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mt_set.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mt_zset.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mt_hash.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mconfig.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33maof.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mpubsub.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mmulti.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mdebug.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33msort.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mintset.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33msyncio.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mcluster.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mcrc16.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mendianconv.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mslowlog.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mscripting.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mbio.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mrio.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mrand.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mmemtest.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mcrc64.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mbitops.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33msentinel.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mnotify.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33msetproctitle.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mblocked.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mhyperloglog.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mlatency.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33msparkline.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mredis-check-rdb.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mredis-check-aof.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mgeo.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mlazyfree.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mmodule.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mevict.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mexpire.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mgeohash.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mgeohash_helper.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mchildinfo.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mdefrag.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33msiphash.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mrax.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mt_stream.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mlistpack.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mlocaltime.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mlolwut.o\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mlolwut5.o\u001b[0m\n",
            "        \u001b[34;1mLINK\u001b[0m \u001b[37;1mredis-server\u001b[0m\n",
            "        \u001b[34;1mINSTALL\u001b[0m \u001b[37;1mredis-sentinel\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mredis-cli.o\u001b[0m\n",
            "        \u001b[34;1mLINK\u001b[0m \u001b[37;1mredis-cli\u001b[0m\n",
            "        \u001b[34mCC\u001b[0m \u001b[33mredis-benchmark.o\u001b[0m\n",
            "        \u001b[34;1mLINK\u001b[0m \u001b[37;1mredis-benchmark\u001b[0m\n",
            "        \u001b[34;1mINSTALL\u001b[0m \u001b[37;1mredis-check-rdb\u001b[0m\n",
            "        \u001b[34;1mINSTALL\u001b[0m \u001b[37;1mredis-check-aof\u001b[0m\n",
            "\n",
            "    Hint: It's a good idea to run 'make test' ;)\n",
            "\n",
            "    make[1]: Leaving directory '/content/ray-distr/thirdparty/pkg/redis/src'\n",
            "    + popd\n",
            "    /content/ray-distr/python\n",
            "    + bash /content/ray-distr/thirdparty/scripts/build_credis.sh\n",
            "    + set -e\n",
            "    +++ dirname /content/ray-distr/thirdparty/scripts/build_credis.sh\n",
            "    ++ cd /content/ray-distr/thirdparty/scripts\n",
            "    ++ pwd\n",
            "    + TP_DIR=/content/ray-distr/thirdparty/scripts/../\n",
            "    + ROOT_DIR=/content/ray-distr/thirdparty/scripts/..//..\n",
            "    ++ uname\n",
            "    + '[' Linux == Darwin ']'\n",
            "    + BUILD_LEVELDB_CONFIG=-DBUILD_SHARED_LIBS=on\n",
            "    + [[ '' = \\o\\n ]]\n",
            "    + bash /content/ray-distr/thirdparty/scripts/build_modin.sh /usr/bin/python3\n",
            "    + set -e\n",
            "    + [[ -z /usr/bin/python3 ]]\n",
            "    + PYTHON_EXECUTABLE=/usr/bin/python3\n",
            "    ++ /usr/bin/python3 -c 'import sys; print(sys.version_info[0])'\n",
            "    + PYTHON_VERSION=3\n",
            "    +++ dirname /content/ray-distr/thirdparty/scripts/build_modin.sh\n",
            "    ++ cd /content/ray-distr/thirdparty/scripts\n",
            "    ++ pwd\n",
            "    + TP_DIR=/content/ray-distr/thirdparty/scripts/../\n",
            "    + MODIN_VERSION=0.5.0\n",
            "    + MODIN_WHEELS_FNAME=modin-0.5.0-py3-none-any.whl\n",
            "    + MODIN_WHEELS_URL=https://github.com/modin-project/modin/releases/download/v0.5.0/\n",
            "    + pushd /content/ray-distr/thirdparty/scripts/..//../python/ray/\n",
            "    /content/ray-distr/python/ray /content/ray-distr/python\n",
            "    + rm -rf modin\n",
            "    + mkdir modin\n",
            "    + pushd modin\n",
            "    /content/ray-distr/python/ray/modin /content/ray-distr/python/ray /content/ray-distr/python\n",
            "    + curl -kL https://github.com/modin-project/modin/releases/download/v0.5.0/modin-0.5.0-py3-none-any.whl -o modin-0.5.0-py3-none-any.whl\n",
            "      % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                     Dload  Upload   Total   Spent    Left  Speed\n",
            "    100   619    0   619    0     0   3458      0 --:--:-- --:--:-- --:--:--  3477\n",
            "    100  208k  100  208k    0     0   518k      0 --:--:-- --:--:-- --:--:--  518k\n",
            "    + unzip modin-0.5.0-py3-none-any.whl\n",
            "    Archive:  modin-0.5.0-py3-none-any.whl\n",
            "      inflating: modin/__init__.py\n",
            "      inflating: modin/error_message.py\n",
            "      inflating: modin/backends/__init__.py\n",
            "      inflating: modin/backends/base/__init__.py\n",
            "      inflating: modin/backends/base/query_compiler.py\n",
            "      inflating: modin/backends/pandas/__init__.py\n",
            "      inflating: modin/backends/pandas/query_compiler.py\n",
            "      inflating: modin/backends/pyarrow/__init__.py\n",
            "      inflating: modin/backends/pyarrow/query_compiler.py\n",
            "      inflating: modin/data_management/__init__.py\n",
            "      inflating: modin/data_management/factories.py\n",
            "      inflating: modin/data_management/utils.py\n",
            "      inflating: modin/engines/__init__.py\n",
            "      inflating: modin/engines/base/__init__.py\n",
            "      inflating: modin/engines/base/io.py\n",
            "      inflating: modin/engines/base/frame/__init__.py\n",
            "      inflating: modin/engines/base/frame/axis_partition.py\n",
            "      inflating: modin/engines/base/frame/partition.py\n",
            "      inflating: modin/engines/base/frame/partition_manager.py\n",
            "      inflating: modin/engines/base/series/__init__.py\n",
            "      inflating: modin/engines/dask/__init__.py\n",
            "      inflating: modin/engines/dask/pandas_on_dask_delayed/__init__.py\n",
            "      inflating: modin/engines/dask/pandas_on_dask_delayed/io.py\n",
            "      inflating: modin/engines/dask/pandas_on_dask_delayed/frame/__init__.py\n",
            "      inflating: modin/engines/dask/pandas_on_dask_delayed/frame/axis_partition.py\n",
            "      inflating: modin/engines/dask/pandas_on_dask_delayed/frame/partition.py\n",
            "      inflating: modin/engines/dask/pandas_on_dask_delayed/frame/partition_manager.py\n",
            "      inflating: modin/engines/dask/pandas_on_dask_delayed/series/__init__.py\n",
            "      inflating: modin/engines/python/__init__.py\n",
            "      inflating: modin/engines/python/pandas_on_python/__init__.py\n",
            "      inflating: modin/engines/python/pandas_on_python/io.py\n",
            "      inflating: modin/engines/python/pandas_on_python/frame/__init__.py\n",
            "      inflating: modin/engines/python/pandas_on_python/frame/axis_partition.py\n",
            "      inflating: modin/engines/python/pandas_on_python/frame/partition.py\n",
            "      inflating: modin/engines/python/pandas_on_python/frame/partition_manager.py\n",
            "      inflating: modin/engines/python/pandas_on_python/series/__init__.py\n",
            "      inflating: modin/engines/ray/__init__.py\n",
            "      inflating: modin/engines/ray/utils.py\n",
            "      inflating: modin/engines/ray/generic/__init__.py\n",
            "      inflating: modin/engines/ray/generic/io.py\n",
            "      inflating: modin/engines/ray/generic/frame/__init__.py\n",
            "      inflating: modin/engines/ray/generic/frame/partition_manager.py\n",
            "      inflating: modin/engines/ray/generic/series/__init__.py\n",
            "      inflating: modin/engines/ray/pandas_on_ray/__init__.py\n",
            "      inflating: modin/engines/ray/pandas_on_ray/io.py\n",
            "      inflating: modin/engines/ray/pandas_on_ray/frame/__init__.py\n",
            "      inflating: modin/engines/ray/pandas_on_ray/frame/axis_partition.py\n",
            "      inflating: modin/engines/ray/pandas_on_ray/frame/partition.py\n",
            "      inflating: modin/engines/ray/pandas_on_ray/frame/partition_manager.py\n",
            "      inflating: modin/engines/ray/pandas_on_ray/series/__init__.py\n",
            "      inflating: modin/experimental/__init__.py\n",
            "      inflating: modin/experimental/engines/__init__.py\n",
            "      inflating: modin/experimental/engines/pandas_on_ray/__init__.py\n",
            "      inflating: modin/experimental/engines/pandas_on_ray/io_exp.py\n",
            "      inflating: modin/experimental/engines/pandas_on_ray/sql.py\n",
            "      inflating: modin/experimental/engines/pyarrow_on_ray/__init__.py\n",
            "      inflating: modin/experimental/engines/pyarrow_on_ray/io.py\n",
            "      inflating: modin/experimental/engines/pyarrow_on_ray/frame/__init__.py\n",
            "      inflating: modin/experimental/engines/pyarrow_on_ray/frame/axis_partition.py\n",
            "      inflating: modin/experimental/engines/pyarrow_on_ray/frame/partition.py\n",
            "      inflating: modin/experimental/engines/pyarrow_on_ray/frame/partition_manager.py\n",
            "      inflating: modin/experimental/engines/pyarrow_on_ray/series/__init__.py\n",
            "      inflating: modin/experimental/pandas/__init__.py\n",
            "      inflating: modin/experimental/pandas/io_exp.py\n",
            "      inflating: modin/pandas/__init__.py\n",
            "      inflating: modin/pandas/base.py\n",
            "      inflating: modin/pandas/concat.py\n",
            "      inflating: modin/pandas/dataframe.py\n",
            "      inflating: modin/pandas/datetimes.py\n",
            "      inflating: modin/pandas/general.py\n",
            "      inflating: modin/pandas/groupby.py\n",
            "      inflating: modin/pandas/indexing.py\n",
            "      inflating: modin/pandas/io.py\n",
            "      inflating: modin/pandas/iterator.py\n",
            "      inflating: modin/pandas/plotting.py\n",
            "      inflating: modin/pandas/reshape.py\n",
            "      inflating: modin/pandas/series.py\n",
            "      inflating: modin/pandas/utils.py\n",
            "      inflating: modin/pandas/index/__init__.py\n",
            "      inflating: modin/pandas/index/partitioned_index.py\n",
            "      inflating: modin/pandas/test/__init__.py\n",
            "      inflating: modin/pandas/test/test_api.py\n",
            "      inflating: modin/pandas/test/test_concat.py\n",
            "      inflating: modin/pandas/test/test_dataframe.py\n",
            "      inflating: modin/pandas/test/test_general.py\n",
            "      inflating: modin/pandas/test/test_groupby.py\n",
            "      inflating: modin/pandas/test/test_io.py\n",
            "      inflating: modin/pandas/test/test_reshape.py\n",
            "      inflating: modin/pandas/test/test_series.py\n",
            "      inflating: modin/pandas/test/utils.py\n",
            "      inflating: modin/sql/__init__.py\n",
            "      inflating: modin/sql/connection.py\n",
            "      inflating: modin-0.5.0.dist-info/LICENSE\n",
            "      inflating: modin-0.5.0.dist-info/METADATA\n",
            "      inflating: modin-0.5.0.dist-info/WHEEL\n",
            "      inflating: modin-0.5.0.dist-info/top_level.txt\n",
            "      inflating: modin-0.5.0.dist-info/RECORD\n",
            "    + rm modin-0.5.0-py3-none-any.whl\n",
            "    + popd\n",
            "    /content/ray-distr/python/ray /content/ray-distr/python\n",
            "    + popd\n",
            "    /content/ray-distr/python\n",
            "    + BUILD_DIR=/content/ray-distr/build/\n",
            "    + '[' '!' -d /content/ray-distr/build/ ']'\n",
            "    + mkdir -p /content/ray-distr/build/\n",
            "    + pushd /content/ray-distr/build/\n",
            "    /content/ray-distr/build /content/ray-distr/python\n",
            "    + /usr/bin/python3 -m pip install --target=/content/ray-distr/python/ray/pyarrow_files pyarrow==0.12.0.RAY --find-links https://s3-us-west-2.amazonaws.com/arrow-wheels/ca1fa51f0901f5a4298f0e4faea00f24e5dd7bb7/index.html\n",
            "    Looking in links: https://s3-us-west-2.amazonaws.com/arrow-wheels/ca1fa51f0901f5a4298f0e4faea00f24e5dd7bb7/index.html\n",
            "    Collecting pyarrow==0.12.0.RAY\n",
            "      Downloading https://s3-us-west-2.amazonaws.com/arrow-wheels/ca1fa51f0901f5a4298f0e4faea00f24e5dd7bb7/pyarrow-0.12.0.RAY-cp36-cp36m-manylinux1_x86_64.whl (48.2MB)\n",
            "    Collecting numpy>=1.14 (from pyarrow==0.12.0.RAY)\n",
            "      Downloading https://files.pythonhosted.org/packages/c1/e2/4db8df8f6cddc98e7d7c537245ef2f4e41a1ed17bf0c3177ab3cc6beac7f/numpy-1.16.3-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
            "    Collecting six>=1.0.0 (from pyarrow==0.12.0.RAY)\n",
            "      Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n",
            "    ERROR: jupyter-console 6.0.0 has requirement prompt-toolkit<2.1.0,>=2.0.0, but you'll have prompt-toolkit 1.0.16 which is incompatible.\n",
            "    ERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\n",
            "    ERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\n",
            "    Installing collected packages: numpy, six, pyarrow\n",
            "    Successfully installed numpy-1.16.3 pyarrow-0.12.0.RAY six-1.12.0\n",
            "    + export PYTHON_BIN_PATH=/usr/bin/python3\n",
            "    + PYTHON_BIN_PATH=/usr/bin/python3\n",
            "    + '[' NO == YES ']'\n",
            "    + '[' YES == YES ']'\n",
            "    + /root/.bazel/bin/bazel build //:ray_pkg --verbose_failures\n",
            "    Extracting Bazel installation...\n",
            "    WARNING: ignoring LD_PRELOAD in environment.\n",
            "    Starting local Bazel server and connecting to it...\n",
            "    INFO: Invocation ID: 96b6750b-a0d5-4348-ae80-98c976a4c996\n",
            "    Loading:\n",
            "    Loading: 0 packages loaded\n",
            "    Loading: 0 packages loaded\n",
            "    INFO: Rule 'com_github_checkstyle_java' modified arguments {\"shallow_since\": \"1552542575 +0800\"}\n",
            "    INFO: Rule 'com_github_nelhage_rules_boost' modified arguments {\"shallow_since\": \"1556014830 +0800\"}\n",
            "    INFO: SHA256 (https://github.com/jovany-wang/prometheus-cpp/archive/master.zip) = d0c773da8af3db99c543dd0413f4427d835170eddfd517bfeba104236a8d2c07\n",
            "    Loading: 0 packages loaded\n",
            "    INFO: SHA256 (https://github.com/google/bazel-common/archive/f1115e0f777f08c3cdb115526c4e663005bec69b.zip) = 1e05a4791cc3470d3ecf7edb556f796b1d340359f1c4d293f175d4d0946cf84c\n",
            "    INFO: SHA256 (https://github.com/bazelbuild/bazel-skylib/archive/0.6.0.tar.gz) = eb5c57e4c12e68c0c20bc774bfbc60a568e800d025557bc4ea022c6479acc867\n",
            "    Loading: 0 packages loaded\n",
            "        currently loading:\n",
            "    Loading: 0 packages loaded\n",
            "        currently loading:\n",
            "    INFO: Rule 'com_github_google_flatbuffers' modified arguments {\"shallow_since\": \"1547755012 -0800\"}\n",
            "    Analyzing: target //:ray_pkg (1 packages loaded, 0 targets configured)\n",
            "    Analyzing: target //:ray_pkg (3 packages loaded, 16 targets configured)\n",
            "    Analyzing: target //:ray_pkg (3 packages loaded, 16 targets configured)\n",
            "    INFO: Rule 'plasma' modified arguments {\"shallow_since\": \"1553452258 +0100\"}\n",
            "    Analyzing: target //:ray_pkg (11 packages loaded, 121 targets configured)\n",
            "    INFO: SHA256 (https://github.com/census-instrumentation/opencensus-cpp/archive/v0.3.0.zip) = e95cadb1941e1a0a698bf5c539a660ef57bc6a1ee2c0f3f76b23707a8dd6d229\n",
            "    Analyzing: target //:ray_pkg (12 packages loaded, 121 targets configured)\n",
            "    INFO: Rule 'com_google_absl' modified arguments {\"shallow_since\": \"1552083078 -0500\"}\n",
            "    Analyzing: target //:ray_pkg (15 packages loaded, 121 targets configured)\n",
            "    INFO: Rule 'com_google_googletest' modified arguments {\"shallow_since\": \"1534270723 -0700\"}\n",
            "    Analyzing: target //:ray_pkg (20 packages loaded, 123 targets configured)\n",
            "    Analyzing: target //:ray_pkg (20 packages loaded, 123 targets configured)\n",
            "    INFO: Rule 'cython' modified arguments {\"shallow_since\": \"1547888711 +0100\"}\n",
            "    INFO: Rule 'com_github_gflags_gflags' modified arguments {\"commit\": \"e171aa2d15ed9eb17054558e0b3a6a413bb01067\", \"shallow_since\": \"1541971260 +0000\"} and dropped [\"tag\"]\n",
            "    Analyzing: target //:ray_pkg (28 packages loaded, 582 targets configured)\n",
            "    INFO: Rule 'com_github_google_glog' modified arguments {\"shallow_since\": \"1550458164 +0900\"}\n",
            "    INFO: Analysed target //:ray_pkg (46 packages loaded, 5095 targets configured).\n",
            "    INFO: Found 1 target...\n",
            "    [0 / 5] [-----] BazelWorkspaceStatusAction stable-status.txt\n",
            "    [7 / 15] Compiling external/com_github_google_flatbuffers/src/idl_gen_rust.cpp [for host]; 1s processwrapper-sandbox ... (2 actions, 1 running)\n",
            "    [11 / 16] Compiling external/com_github_google_flatbuffers/src/idl_gen_text.cpp [for host]; 2s processwrapper-sandbox\n",
            "    [15 / 20] Compiling external/com_github_google_flatbuffers/src/idl_parser.cpp [for host]; 9s processwrapper-sandbox\n",
            "    [19 / 24] Compiling external/com_github_google_flatbuffers/src/reflection.cpp [for host]; 2s processwrapper-sandbox\n",
            "    [82 / 117] Compiling external/io_opencensus_cpp/opencensus/stats/internal/stats_manager.cc; 1s processwrapper-sandbox\n",
            "    [113 / 159] Compiling external/com_google_googletest/googletest/src/gtest.cc; 1s processwrapper-sandbox\n",
            "    [136 / 186] Compiling external/boost/libs/regex/src/posix_api.cpp; 1s processwrapper-sandbox\n",
            "    [173 / 233] Compiling external/boost/libs/regex/src/wide_posix_api.cpp; 4s processwrapper-sandbox\n",
            "    [210 / 277] Compiling external/boost/libs/date_time/src/gregorian/date_generators.cpp; 0s processwrapper-sandbox\n",
            "    [255 / 335] Compiling external/boost/libs/regex/src/cregex.cpp; 3s processwrapper-sandbox\n",
            "    INFO: From Compiling src/ray/thirdparty/hiredis/dict.c:\n",
            "    src/ray/thirdparty/hiredis/dict.c:288:13: warning: 'dictReleaseIterator' defined but not used [-Wunused-function]\n",
            "     static void dictReleaseIterator(dictIterator *iter) {\n",
            "                 ^~~~~~~~~~~~~~~~~~~\n",
            "    src/ray/thirdparty/hiredis/dict.c:268:19: warning: 'dictNext' defined but not used [-Wunused-function]\n",
            "     static dictEntry *dictNext(dictIterator *iter) {\n",
            "                       ^~~~~~~~\n",
            "    src/ray/thirdparty/hiredis/dict.c:258:22: warning: 'dictGetIterator' defined but not used [-Wunused-function]\n",
            "     static dictIterator *dictGetIterator(dict *ht) {\n",
            "                          ^~~~~~~~~~~~~~~\n",
            "    src/ray/thirdparty/hiredis/dict.c:238:13: warning: 'dictRelease' defined but not used [-Wunused-function]\n",
            "     static void dictRelease(dict *ht) {\n",
            "                 ^~~~~~~~~~~\n",
            "    src/ray/thirdparty/hiredis/dict.c:182:12: warning: 'dictDelete' defined but not used [-Wunused-function]\n",
            "     static int dictDelete(dict *ht, const void *key) {\n",
            "                ^~~~~~~~~~\n",
            "    src/ray/thirdparty/hiredis/dict.c:160:12: warning: 'dictReplace' defined but not used [-Wunused-function]\n",
            "     static int dictReplace(dict *ht, void *key, void *val) {\n",
            "                ^~~~~~~~~~~\n",
            "    src/ray/thirdparty/hiredis/dict.c:73:14: warning: 'dictCreate' defined but not used [-Wunused-function]\n",
            "     static dict *dictCreate(dictType *type, void *privDataPtr) {\n",
            "                  ^~~~~~~~~~\n",
            "    src/ray/thirdparty/hiredis/dict.c:53:21: warning: 'dictGenHashFunction' defined but not used [-Wunused-function]\n",
            "     static unsigned int dictGenHashFunction(const unsigned char *buf, int len) {\n",
            "                         ^~~~~~~~~~~~~~~~~~~\n",
            "    [303 / 395] Compiling external/boost/libs/regex/src/cregex.cpp; 5s processwrapper-sandbox\n",
            "    [359 / 462] Compiling external/io_opencensus_cpp/opencensus/stats/internal/stats_exporter.cc; 1s processwrapper-sandbox\n",
            "    INFO: From Compiling src/ray/thirdparty/hiredis/dict.c:\n",
            "    src/ray/thirdparty/hiredis/dict.c:288:13: warning: 'dictReleaseIterator' defined but not used [-Wunused-function]\n",
            "     static void dictReleaseIterator(dictIterator *iter) {\n",
            "                 ^~~~~~~~~~~~~~~~~~~\n",
            "    src/ray/thirdparty/hiredis/dict.c:268:19: warning: 'dictNext' defined but not used [-Wunused-function]\n",
            "     static dictEntry *dictNext(dictIterator *iter) {\n",
            "                       ^~~~~~~~\n",
            "    src/ray/thirdparty/hiredis/dict.c:258:22: warning: 'dictGetIterator' defined but not used [-Wunused-function]\n",
            "     static dictIterator *dictGetIterator(dict *ht) {\n",
            "                          ^~~~~~~~~~~~~~~\n",
            "    src/ray/thirdparty/hiredis/dict.c:238:13: warning: 'dictRelease' defined but not used [-Wunused-function]\n",
            "     static void dictRelease(dict *ht) {\n",
            "                 ^~~~~~~~~~~\n",
            "    src/ray/thirdparty/hiredis/dict.c:182:12: warning: 'dictDelete' defined but not used [-Wunused-function]\n",
            "     static int dictDelete(dict *ht, const void *key) {\n",
            "                ^~~~~~~~~~\n",
            "    src/ray/thirdparty/hiredis/dict.c:160:12: warning: 'dictReplace' defined but not used [-Wunused-function]\n",
            "     static int dictReplace(dict *ht, void *key, void *val) {\n",
            "                ^~~~~~~~~~~\n",
            "    src/ray/thirdparty/hiredis/dict.c:73:14: warning: 'dictCreate' defined but not used [-Wunused-function]\n",
            "     static dict *dictCreate(dictType *type, void *privDataPtr) {\n",
            "                  ^~~~~~~~~~\n",
            "    src/ray/thirdparty/hiredis/dict.c:53:21: warning: 'dictGenHashFunction' defined but not used [-Wunused-function]\n",
            "     static unsigned int dictGenHashFunction(const unsigned char *buf, int len) {\n",
            "                         ^~~~~~~~~~~~~~~~~~~\n",
            "    [440 / 567] Compiling external/boost/libs/regex/src/winstances.cpp; 1s processwrapper-sandbox ... (2 actions running)\n",
            "    [523 / 648] Compiling external/plasma/cpp/src/plasma/client.cc; 3s processwrapper-sandbox ... (2 actions running)\n",
            "    [557 / 648] Executing genrule //:redis; 45s processwrapper-sandbox ... (2 actions running)\n",
            "    [567 / 648] Executing genrule //:redis; 101s processwrapper-sandbox ... (2 actions running)\n",
            "    INFO: From Executing genrule //:redis:\n",
            "    + tar xz --strip-components=1 -C .\n",
            "    + curl -sL https://github.com/antirez/redis/archive/5.0.3.tar.gz\n",
            "    + make\n",
            "        CC Makefile.dep\n",
            "    ldo.c: In function 'f_parser':\n",
            "    ldo.c:496:7: warning: unused variable 'c' [-Wunused-variable]\n",
            "       int c = luaZ_lookahead(p->z);\n",
            "           ^\n",
            "    lauxlib.c: In function 'luaL_loadfile':\n",
            "    lauxlib.c:577:4: warning: this 'while' clause does not guard... [-Wmisleading-indentation]\n",
            "        while ((c = getc(lf.f)) != EOF && c != LUA_SIGNATURE[0]) ;\n",
            "        ^~~~~\n",
            "    lauxlib.c:578:5: note: ...this statement, but the latter is misleadingly indented as if it were guarded by the 'while'\n",
            "         lf.extraline = 0;\n",
            "         ^~\n",
            "    ltablib.c: In function 'addfield':\n",
            "    ltablib.c:137:3: warning: this 'if' clause does not guard... [-Wmisleading-indentation]\n",
            "       if (!lua_isstring(L, -1))\n",
            "       ^~\n",
            "    ltablib.c:140:5: note: ...this statement, but the latter is misleadingly indented as if it were guarded by the 'if'\n",
            "         luaL_addvalue(b);\n",
            "         ^~~~~~~~~~~~~\n",
            "    ar: `u' modifier ignored since `D' is the default (see `U')\n",
            "    liblua.a(loslib.o): In function `os_tmpname':\n",
            "    loslib.c:(.text+0x290): warning: the use of `tmpnam' is dangerous, better use `mkstemp'\n",
            "    configure: WARNING: unrecognized options: --enable-cc-silence\n",
            "    configure: WARNING: unrecognized options: --enable-cc-silence\n",
            "    ar: `u' modifier ignored since `D' is the default (see `U')\n",
            "        CC adlist.o\n",
            "        CC quicklist.o\n",
            "        CC ae.o\n",
            "        CC anet.o\n",
            "        CC dict.o\n",
            "        CC server.o\n",
            "        CC sds.o\n",
            "        CC zmalloc.o\n",
            "        CC lzf_c.o\n",
            "        CC lzf_d.o\n",
            "        CC pqsort.o\n",
            "        CC zipmap.o\n",
            "        CC sha1.o\n",
            "        CC ziplist.o\n",
            "        CC release.o\n",
            "        CC networking.o\n",
            "        CC util.o\n",
            "        CC object.o\n",
            "        CC db.o\n",
            "        CC replication.o\n",
            "        CC rdb.o\n",
            "        CC t_string.o\n",
            "        CC t_list.o\n",
            "        CC t_set.o\n",
            "        CC t_zset.o\n",
            "        CC t_hash.o\n",
            "        CC config.o\n",
            "        CC aof.o\n",
            "        CC pubsub.o\n",
            "        CC multi.o\n",
            "        CC debug.o\n",
            "        CC sort.o\n",
            "        CC intset.o\n",
            "        CC syncio.o\n",
            "        CC cluster.o\n",
            "        CC crc16.o\n",
            "        CC endianconv.o\n",
            "        CC slowlog.o\n",
            "        CC scripting.o\n",
            "        CC bio.o\n",
            "        CC rio.o\n",
            "        CC rand.o\n",
            "        CC memtest.o\n",
            "        CC crc64.o\n",
            "        CC bitops.o\n",
            "        CC sentinel.o\n",
            "        CC notify.o\n",
            "        CC setproctitle.o\n",
            "        CC blocked.o\n",
            "        CC hyperloglog.o\n",
            "        CC latency.o\n",
            "        CC sparkline.o\n",
            "        CC redis-check-rdb.o\n",
            "        CC redis-check-aof.o\n",
            "        CC geo.o\n",
            "        CC lazyfree.o\n",
            "        CC module.o\n",
            "        CC evict.o\n",
            "        CC expire.o\n",
            "        CC geohash.o\n",
            "        CC geohash_helper.o\n",
            "        CC childinfo.o\n",
            "        CC defrag.o\n",
            "        CC siphash.o\n",
            "        CC rax.o\n",
            "        CC t_stream.o\n",
            "        CC listpack.o\n",
            "        CC localtime.o\n",
            "        CC lolwut.o\n",
            "        CC lolwut5.o\n",
            "        LINK redis-server\n",
            "        INSTALL redis-sentinel\n",
            "        CC redis-cli.o\n",
            "        LINK redis-cli\n",
            "        CC redis-benchmark.o\n",
            "        LINK redis-benchmark\n",
            "        INSTALL redis-check-rdb\n",
            "        INSTALL redis-check-aof\n",
            "    + mv ./src/redis-server bazel-out/k8-opt/genfiles/redis-server\n",
            "    + chmod +x bazel-out/k8-opt/genfiles/redis-server\n",
            "    + mv ./src/redis-cli bazel-out/k8-opt/genfiles/redis-cli\n",
            "    + chmod +x bazel-out/k8-opt/genfiles/redis-cli\n",
            "    cd src && make all\n",
            "    make[1]: Entering directory '/root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/sandbox/processwrapper-sandbox/470/execroot/com_github_ray_project_ray/src'\n",
            "    rm -rf redis-server redis-sentinel redis-cli redis-benchmark redis-check-rdb redis-check-aof *.o *.gcda *.gcno *.gcov redis.info lcov-html Makefile.dep dict-benchmark\n",
            "    (cd ../deps && make distclean)\n",
            "    make[2]: Entering directory '/root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/sandbox/processwrapper-sandbox/470/execroot/com_github_ray_project_ray/deps'\n",
            "    (cd hiredis && make clean) > /dev/null || true\n",
            "    (cd linenoise && make clean) > /dev/null || true\n",
            "    (cd lua && make clean) > /dev/null || true\n",
            "    (cd jemalloc && [ -f Makefile ] && make distclean) > /dev/null || true\n",
            "    (rm -f .make-*)\n",
            "    make[2]: Leaving directory '/root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/sandbox/processwrapper-sandbox/470/execroot/com_github_ray_project_ray/deps'\n",
            "    (rm -f .make-*)\n",
            "    echo STD=-std=c99 -pedantic -DREDIS_STATIC='' >> .make-settings\n",
            "    echo WARN=-Wall -W -Wno-missing-field-initializers >> .make-settings\n",
            "    echo OPT=-O2 >> .make-settings\n",
            "    echo MALLOC=jemalloc >> .make-settings\n",
            "    echo CFLAGS= >> .make-settings\n",
            "    echo LDFLAGS= >> .make-settings\n",
            "    echo REDIS_CFLAGS= >> .make-settings\n",
            "    echo REDIS_LDFLAGS= >> .make-settings\n",
            "    echo PREV_FINAL_CFLAGS=-std=c99 -pedantic -DREDIS_STATIC='' -Wall -W -Wno-missing-field-initializers -O2 -g -ggdb   -I../deps/hiredis -I../deps/linenoise -I../deps/lua/src -DUSE_JEMALLOC -I../deps/jemalloc/include >> .make-settings\n",
            "    echo PREV_FINAL_LDFLAGS=  -g -ggdb -rdynamic >> .make-settings\n",
            "    (cd ../deps && make hiredis linenoise lua jemalloc)\n",
            "    make[2]: Entering directory '/root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/sandbox/processwrapper-sandbox/470/execroot/com_github_ray_project_ray/deps'\n",
            "    (cd hiredis && make clean) > /dev/null || true\n",
            "    (cd linenoise && make clean) > /dev/null || true\n",
            "    (cd lua && make clean) > /dev/null || true\n",
            "    (cd jemalloc && [ -f Makefile ] && make distclean) > /dev/null || true\n",
            "    (rm -f .make-*)\n",
            "    (echo \"\" > .make-cflags)\n",
            "    (echo \"\" > .make-ldflags)\n",
            "    MAKE hiredis\n",
            "    cd hiredis && make static\n",
            "    make[3]: Entering directory '/root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/sandbox/processwrapper-sandbox/470/execroot/com_github_ray_project_ray/deps/hiredis'\n",
            "    cc -std=c99 -pedantic -c -O3 -fPIC  -Wall -W -Wstrict-prototypes -Wwrite-strings -g -ggdb  net.c\n",
            "    cc -std=c99 -pedantic -c -O3 -fPIC  -Wall -W -Wstrict-prototypes -Wwrite-strings -g -ggdb  hiredis.c\n",
            "    cc -std=c99 -pedantic -c -O3 -fPIC  -Wall -W -Wstrict-prototypes -Wwrite-strings -g -ggdb  sds.c\n",
            "    cc -std=c99 -pedantic -c -O3 -fPIC  -Wall -W -Wstrict-prototypes -Wwrite-strings -g -ggdb  async.c\n",
            "    cc -std=c99 -pedantic -c -O3 -fPIC  -Wall -W -Wstrict-prototypes -Wwrite-strings -g -ggdb  read.c\n",
            "    ar rcs libhiredis.a net.o hiredis.o sds.o async.o read.o\n",
            "    make[3]: Leaving directory '/root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/sandbox/processwrapper-sandbox/470/execroot/com_github_ray_project_ray/deps/hiredis'\n",
            "    MAKE linenoise\n",
            "    cd linenoise && make\n",
            "    make[3]: Entering directory '/root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/sandbox/processwrapper-sandbox/470/execroot/com_github_ray_project_ray/deps/linenoise'\n",
            "    cc  -Wall -Os -g  -c linenoise.c\n",
            "    make[3]: Leaving directory '/root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/sandbox/processwrapper-sandbox/470/execroot/com_github_ray_project_ray/deps/linenoise'\n",
            "    MAKE lua\n",
            "    cd lua/src && make all CFLAGS=\"-O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC='' \" MYLDFLAGS=\"\" AR=\"ar rcu\"\n",
            "    make[3]: Entering directory '/root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/sandbox/processwrapper-sandbox/470/execroot/com_github_ray_project_ray/deps/lua/src'\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o lapi.o lapi.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o lcode.o lcode.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o ldebug.o ldebug.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o ldo.o ldo.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o ldump.o ldump.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o lfunc.o lfunc.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o lgc.o lgc.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o llex.o llex.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o lmem.o lmem.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o lobject.o lobject.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o lopcodes.o lopcodes.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o lparser.o lparser.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o lstate.o lstate.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o lstring.o lstring.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o ltable.o ltable.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o ltm.o ltm.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o lundump.o lundump.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o lvm.o lvm.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o lzio.o lzio.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o strbuf.o strbuf.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o fpconv.o fpconv.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o lauxlib.o lauxlib.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o lbaselib.o lbaselib.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o ldblib.o ldblib.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o liolib.o liolib.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o lmathlib.o lmathlib.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o loslib.o loslib.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o ltablib.o ltablib.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o lstrlib.o lstrlib.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o loadlib.o loadlib.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o linit.o linit.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o lua_cjson.o lua_cjson.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o lua_struct.o lua_struct.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o lua_cmsgpack.o lua_cmsgpack.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o lua_bit.o lua_bit.c\n",
            "    ar rcu liblua.a lapi.o lcode.o ldebug.o ldo.o ldump.o lfunc.o lgc.o llex.o lmem.o lobject.o lopcodes.o lparser.o lstate.o lstring.o ltable.o ltm.o lundump.o lvm.o lzio.o strbuf.o fpconv.o lauxlib.o lbaselib.o ldblib.o liolib.o lmathlib.o loslib.o ltablib.o lstrlib.o loadlib.o linit.o lua_cjson.o lua_struct.o lua_cmsgpack.o lua_bit.o\t# DLL needs all object files\n",
            "    ranlib liblua.a\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o lua.o lua.c\n",
            "    cc -o lua  lua.o liblua.a -lm\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o luac.o luac.c\n",
            "    cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL -DREDIS_STATIC=''    -c -o print.o print.c\n",
            "    cc -o luac  luac.o print.o liblua.a -lm\n",
            "    make[3]: Leaving directory '/root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/sandbox/processwrapper-sandbox/470/execroot/com_github_ray_project_ray/deps/lua/src'\n",
            "    MAKE jemalloc\n",
            "    cd jemalloc && ./configure --with-version=5.1.0-0-g0 --with-lg-quantum=3 --with-jemalloc-prefix=je_ --enable-cc-silence CFLAGS=\"-std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops \" LDFLAGS=\"\"\n",
            "    checking for xsltproc... false\n",
            "    checking for gcc... gcc\n",
            "    checking whether the C compiler works... yes\n",
            "    checking for C compiler default output file name... a.out\n",
            "    checking for suffix of executables...\n",
            "    checking whether we are cross compiling... no\n",
            "    checking for suffix of object files... o\n",
            "    checking whether we are using the GNU C compiler... yes\n",
            "    checking whether gcc accepts -g... yes\n",
            "    checking for gcc option to accept ISO C89... none needed\n",
            "    checking whether compiler is cray... no\n",
            "    checking whether compiler supports -std=gnu11... yes\n",
            "    checking whether compiler supports -Wall... yes\n",
            "    checking whether compiler supports -Wshorten-64-to-32... no\n",
            "    checking whether compiler supports -Wsign-compare... yes\n",
            "    checking whether compiler supports -Wundef... yes\n",
            "    checking whether compiler supports -Wno-format-zero-length... yes\n",
            "    checking whether compiler supports -pipe... yes\n",
            "    checking whether compiler supports -g3... yes\n",
            "    checking how to run the C preprocessor... gcc -E\n",
            "    checking for g++... g++\n",
            "    checking whether we are using the GNU C++ compiler... yes\n",
            "    checking whether g++ accepts -g... yes\n",
            "    checking whether g++ supports C++14 features by default... yes\n",
            "    checking whether compiler supports -Wall... yes\n",
            "    checking whether compiler supports -g3... yes\n",
            "    checking whether libstdc++ linkage is compilable... yes\n",
            "    checking for grep that handles long lines and -e... /bin/grep\n",
            "    checking for egrep... /bin/grep -E\n",
            "    checking for ANSI C header files... yes\n",
            "    checking for sys/types.h... yes\n",
            "    checking for sys/stat.h... yes\n",
            "    checking for stdlib.h... yes\n",
            "    checking for string.h... yes\n",
            "    checking for memory.h... yes\n",
            "    checking for strings.h... yes\n",
            "    checking for inttypes.h... yes\n",
            "    checking for stdint.h... yes\n",
            "    checking for unistd.h... yes\n",
            "    checking whether byte ordering is bigendian... no\n",
            "    checking size of void *... 8\n",
            "    checking size of int... 4\n",
            "    checking size of long... 8\n",
            "    checking size of long long... 8\n",
            "    checking size of intmax_t... 8\n",
            "    checking build system type... x86_64-pc-linux-gnu\n",
            "    checking host system type... x86_64-pc-linux-gnu\n",
            "    checking whether pause instruction is compilable... yes\n",
            "    checking number of significant virtual address bits... 48\n",
            "    checking for ar... ar\n",
            "    checking for nm... nm\n",
            "    checking for gawk... no\n",
            "    checking for mawk... mawk\n",
            "    checking malloc.h usability... yes\n",
            "    checking malloc.h presence... yes\n",
            "    checking for malloc.h... yes\n",
            "    checking whether malloc_usable_size definition can use const argument... no\n",
            "    checking for library containing log... -lm\n",
            "    checking whether __attribute__ syntax is compilable... yes\n",
            "    checking whether compiler supports -fvisibility=hidden... yes\n",
            "    checking whether compiler supports -fvisibility=hidden... yes\n",
            "    checking whether compiler supports -Werror... yes\n",
            "    checking whether compiler supports -herror_on_warning... no\n",
            "    checking whether tls_model attribute is compilable... yes\n",
            "    checking whether compiler supports -Werror... yes\n",
            "    checking whether compiler supports -herror_on_warning... no\n",
            "    checking whether alloc_size attribute is compilable... yes\n",
            "    checking whether compiler supports -Werror... yes\n",
            "    checking whether compiler supports -herror_on_warning... no\n",
            "    checking whether format(gnu_printf, ...) attribute is compilable... yes\n",
            "    checking whether compiler supports -Werror... yes\n",
            "    checking whether compiler supports -herror_on_warning... no\n",
            "    checking whether format(printf, ...) attribute is compilable... yes\n",
            "    checking for a BSD-compatible install... /usr/bin/install -c\n",
            "    checking for ranlib... ranlib\n",
            "    checking for ld... /usr/bin/ld\n",
            "    checking for autoconf... false\n",
            "    checking for memalign... yes\n",
            "    checking for valloc... yes\n",
            "    checking whether compiler supports -O3... yes\n",
            "    checking whether compiler supports -O3... yes\n",
            "    checking whether compiler supports -funroll-loops... yes\n",
            "    checking configured backtracing method... N/A\n",
            "    checking for sbrk... yes\n",
            "    checking whether utrace(2) is compilable... no\n",
            "    checking whether a program using __builtin_unreachable is compilable... yes\n",
            "    checking whether a program using __builtin_ffsl is compilable... yes\n",
            "    checking LG_PAGE... 12\n",
            "    checking pthread.h usability... yes\n",
            "    checking pthread.h presence... yes\n",
            "    checking for pthread.h... yes\n",
            "    checking for pthread_create in -lpthread... yes\n",
            "    checking dlfcn.h usability... yes\n",
            "    checking dlfcn.h presence... yes\n",
            "    checking for dlfcn.h... yes\n",
            "    checking for dlsym... no\n",
            "    checking for dlsym in -ldl... yes\n",
            "    checking whether pthread_atfork(3) is compilable... yes\n",
            "    checking whether pthread_setname_np(3) is compilable... yes\n",
            "    checking for library containing clock_gettime... none required\n",
            "    checking whether clock_gettime(CLOCK_MONOTONIC_COARSE, ...) is compilable... yes\n",
            "    checking whether clock_gettime(CLOCK_MONOTONIC, ...) is compilable... yes\n",
            "    checking whether mach_absolute_time() is compilable... no\n",
            "    checking whether compiler supports -Werror... yes\n",
            "    checking whether syscall(2) is compilable... yes\n",
            "    checking for secure_getenv... yes\n",
            "    checking for sched_getcpu... yes\n",
            "    checking for sched_setaffinity... yes\n",
            "    checking for issetugid... no\n",
            "    checking for _malloc_thread_cleanup... no\n",
            "    checking for _pthread_mutex_init_calloc_cb... no\n",
            "    checking for TLS... yes\n",
            "    checking whether C11 atomics is compilable... no\n",
            "    checking whether GCC __atomic atomics is compilable... yes\n",
            "    checking whether GCC __sync atomics is compilable... yes\n",
            "    checking whether Darwin OSAtomic*() is compilable... no\n",
            "    checking whether madvise(2) is compilable... yes\n",
            "    checking whether madvise(..., MADV_FREE) is compilable... yes\n",
            "    checking whether madvise(..., MADV_DONTNEED) is compilable... yes\n",
            "    checking whether madvise(..., MADV_DO[NT]DUMP) is compilable... yes\n",
            "    checking whether madvise(..., MADV_[NO]HUGEPAGE) is compilable... yes\n",
            "    checking whether to force 32-bit __sync_{add,sub}_and_fetch()... no\n",
            "    checking whether to force 64-bit __sync_{add,sub}_and_fetch()... no\n",
            "    checking for __builtin_clz... yes\n",
            "    checking whether Darwin os_unfair_lock_*() is compilable... no\n",
            "    checking whether Darwin OSSpin*() is compilable... no\n",
            "    checking whether glibc malloc hook is compilable... yes\n",
            "    checking whether glibc memalign hook is compilable... yes\n",
            "    checking whether pthreads adaptive mutexes is compilable... yes\n",
            "    checking whether compiler supports -D_GNU_SOURCE... yes\n",
            "    checking whether compiler supports -Werror... yes\n",
            "    checking whether compiler supports -herror_on_warning... no\n",
            "    checking whether strerror_r returns char with gnu source is compilable... yes\n",
            "    checking for stdbool.h that conforms to C99... yes\n",
            "    checking for _Bool... yes\n",
            "    configure: creating ./config.status\n",
            "    config.status: creating Makefile\n",
            "    config.status: creating jemalloc.pc\n",
            "    config.status: creating doc/html.xsl\n",
            "    config.status: creating doc/manpages.xsl\n",
            "    config.status: creating doc/jemalloc.xml\n",
            "    config.status: creating include/jemalloc/jemalloc_macros.h\n",
            "    config.status: creating include/jemalloc/jemalloc_protos.h\n",
            "    config.status: creating include/jemalloc/jemalloc_typedefs.h\n",
            "    config.status: creating include/jemalloc/internal/jemalloc_preamble.h\n",
            "    config.status: creating test/test.sh\n",
            "    config.status: creating test/include/test/jemalloc_test.h\n",
            "    config.status: creating config.stamp\n",
            "    config.status: creating bin/jemalloc-config\n",
            "    config.status: creating bin/jemalloc.sh\n",
            "    config.status: creating bin/jeprof\n",
            "    config.status: creating include/jemalloc/jemalloc_defs.h\n",
            "    config.status: creating include/jemalloc/internal/jemalloc_internal_defs.h\n",
            "    config.status: creating test/include/test/jemalloc_test_defs.h\n",
            "    config.status: executing include/jemalloc/internal/public_symbols.txt commands\n",
            "    config.status: executing include/jemalloc/internal/private_symbols.awk commands\n",
            "    config.status: executing include/jemalloc/internal/private_symbols_jet.awk commands\n",
            "    config.status: executing include/jemalloc/internal/public_namespace.h commands\n",
            "    config.status: executing include/jemalloc/internal/public_unnamespace.h commands\n",
            "    config.status: executing include/jemalloc/internal/size_classes.h commands\n",
            "    config.status: executing include/jemalloc/jemalloc_protos_jet.h commands\n",
            "    config.status: executing include/jemalloc/jemalloc_rename.h commands\n",
            "    config.status: executing include/jemalloc/jemalloc_mangle.h commands\n",
            "    config.status: executing include/jemalloc/jemalloc_mangle_jet.h commands\n",
            "    config.status: executing include/jemalloc/jemalloc.h commands\n",
            "    ===============================================================================\n",
            "    jemalloc version   : 5.1.0-0-g0\n",
            "    library revision   : 2\n",
            "\n",
            "    CONFIG             : --with-version=5.1.0-0-g0 --with-lg-quantum=3 --with-jemalloc-prefix=je_ --enable-cc-silence 'CFLAGS=-std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops ' LDFLAGS=\n",
            "    CC                 : gcc\n",
            "    CONFIGURE_CFLAGS   : -std=gnu11 -Wall -Wsign-compare -Wundef -Wno-format-zero-length -pipe -g3 -fvisibility=hidden -O3 -funroll-loops\n",
            "    SPECIFIED_CFLAGS   : -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops\n",
            "    EXTRA_CFLAGS       :\n",
            "    CPPFLAGS           : -D_GNU_SOURCE -D_REENTRANT\n",
            "    CXX                : g++\n",
            "    CONFIGURE_CXXFLAGS : -Wall -g3 -fvisibility=hidden -O3\n",
            "    SPECIFIED_CXXFLAGS :\n",
            "    EXTRA_CXXFLAGS     :\n",
            "    LDFLAGS            :\n",
            "    EXTRA_LDFLAGS      :\n",
            "    DSO_LDFLAGS        : -shared -Wl,-soname,$(@F)\n",
            "    LIBS               : -lm -lstdc++ -lpthread -ldl\n",
            "    RPATH_EXTRA        :\n",
            "\n",
            "    XSLTPROC           : false\n",
            "    XSLROOT            :\n",
            "\n",
            "    PREFIX             : /usr/local\n",
            "    BINDIR             : /usr/local/bin\n",
            "    DATADIR            : /usr/local/share\n",
            "    INCLUDEDIR         : /usr/local/include\n",
            "    LIBDIR             : /usr/local/lib\n",
            "    MANDIR             : /usr/local/share/man\n",
            "\n",
            "    srcroot            :\n",
            "    abs_srcroot        : /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/sandbox/processwrapper-sandbox/470/execroot/com_github_ray_project_ray/deps/jemalloc/\n",
            "    objroot            :\n",
            "    abs_objroot        : /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/sandbox/processwrapper-sandbox/470/execroot/com_github_ray_project_ray/deps/jemalloc/\n",
            "\n",
            "    JEMALLOC_PREFIX    : je_\n",
            "    JEMALLOC_PRIVATE_NAMESPACE\n",
            "                       : je_\n",
            "    install_suffix     :\n",
            "    malloc_conf        :\n",
            "    autogen            : 0\n",
            "    debug              : 0\n",
            "    stats              : 1\n",
            "    prof               : 0\n",
            "    prof-libunwind     : 0\n",
            "    prof-libgcc        : 0\n",
            "    prof-gcc           : 0\n",
            "    fill               : 1\n",
            "    utrace             : 0\n",
            "    xmalloc            : 0\n",
            "    log                : 0\n",
            "    lazy_lock          : 0\n",
            "    cache-oblivious    : 1\n",
            "    cxx                : 1\n",
            "    ===============================================================================\n",
            "    cd jemalloc && make CFLAGS=\"-std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops \" LDFLAGS=\"\" lib/libjemalloc.a\n",
            "    make[3]: Entering directory '/root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/sandbox/processwrapper-sandbox/470/execroot/com_github_ray_project_ray/deps/jemalloc'\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/jemalloc.sym.o src/jemalloc.c\n",
            "    nm -a src/jemalloc.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/jemalloc.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/arena.sym.o src/arena.c\n",
            "    nm -a src/arena.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/arena.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/background_thread.sym.o src/background_thread.c\n",
            "    nm -a src/background_thread.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/background_thread.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/base.sym.o src/base.c\n",
            "    nm -a src/base.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/base.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/bin.sym.o src/bin.c\n",
            "    nm -a src/bin.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/bin.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/bitmap.sym.o src/bitmap.c\n",
            "    nm -a src/bitmap.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/bitmap.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/ckh.sym.o src/ckh.c\n",
            "    nm -a src/ckh.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/ckh.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/ctl.sym.o src/ctl.c\n",
            "    nm -a src/ctl.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/ctl.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/div.sym.o src/div.c\n",
            "    nm -a src/div.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/div.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/extent.sym.o src/extent.c\n",
            "    nm -a src/extent.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/extent.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/extent_dss.sym.o src/extent_dss.c\n",
            "    nm -a src/extent_dss.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/extent_dss.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/extent_mmap.sym.o src/extent_mmap.c\n",
            "    nm -a src/extent_mmap.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/extent_mmap.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/hash.sym.o src/hash.c\n",
            "    nm -a src/hash.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/hash.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/hooks.sym.o src/hooks.c\n",
            "    nm -a src/hooks.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/hooks.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/large.sym.o src/large.c\n",
            "    nm -a src/large.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/large.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/log.sym.o src/log.c\n",
            "    nm -a src/log.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/log.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/malloc_io.sym.o src/malloc_io.c\n",
            "    nm -a src/malloc_io.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/malloc_io.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/mutex.sym.o src/mutex.c\n",
            "    nm -a src/mutex.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/mutex.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/mutex_pool.sym.o src/mutex_pool.c\n",
            "    nm -a src/mutex_pool.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/mutex_pool.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/nstime.sym.o src/nstime.c\n",
            "    nm -a src/nstime.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/nstime.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/pages.sym.o src/pages.c\n",
            "    nm -a src/pages.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/pages.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/prng.sym.o src/prng.c\n",
            "    nm -a src/prng.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/prng.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/prof.sym.o src/prof.c\n",
            "    nm -a src/prof.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/prof.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/rtree.sym.o src/rtree.c\n",
            "    nm -a src/rtree.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/rtree.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/stats.sym.o src/stats.c\n",
            "    nm -a src/stats.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/stats.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/sz.sym.o src/sz.c\n",
            "    nm -a src/sz.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/sz.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/tcache.sym.o src/tcache.c\n",
            "    nm -a src/tcache.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/tcache.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/ticker.sym.o src/ticker.c\n",
            "    nm -a src/ticker.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/ticker.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/tsd.sym.o src/tsd.c\n",
            "    nm -a src/tsd.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/tsd.sym\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -DJEMALLOC_NO_PRIVATE_NAMESPACE -o src/witness.sym.o src/witness.c\n",
            "    nm -a src/witness.sym.o | mawk -f include/jemalloc/internal/private_symbols.awk > src/witness.sym\n",
            "    /bin/sh include/jemalloc/internal/private_namespace.sh src/jemalloc.sym src/arena.sym src/background_thread.sym src/base.sym src/bin.sym src/bitmap.sym src/ckh.sym src/ctl.sym src/div.sym src/extent.sym src/extent_dss.sym src/extent_mmap.sym src/hash.sym src/hooks.sym src/large.sym src/log.sym src/malloc_io.sym src/mutex.sym src/mutex_pool.sym src/nstime.sym src/pages.sym src/prng.sym src/prof.sym src/rtree.sym src/stats.sym src/sz.sym src/tcache.sym src/ticker.sym src/tsd.sym src/witness.sym > include/jemalloc/internal/private_namespace.gen.h\n",
            "    cp include/jemalloc/internal/private_namespace.gen.h include/jemalloc/internal/private_namespace.gen.h\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/jemalloc.o src/jemalloc.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/arena.o src/arena.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/background_thread.o src/background_thread.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/base.o src/base.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/bin.o src/bin.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/bitmap.o src/bitmap.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/ckh.o src/ckh.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/ctl.o src/ctl.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/div.o src/div.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/extent.o src/extent.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/extent_dss.o src/extent_dss.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/extent_mmap.o src/extent_mmap.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/hash.o src/hash.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/hooks.o src/hooks.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/large.o src/large.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/log.o src/log.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/malloc_io.o src/malloc_io.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/mutex.o src/mutex.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/mutex_pool.o src/mutex_pool.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/nstime.o src/nstime.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/pages.o src/pages.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/prng.o src/prng.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/prof.o src/prof.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/rtree.o src/rtree.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/stats.o src/stats.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/sz.o src/sz.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/tcache.o src/tcache.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/ticker.o src/ticker.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/tsd.o src/tsd.c\n",
            "    gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/witness.o src/witness.c\n",
            "    g++ -Wall -g3 -fvisibility=hidden -O3 -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/jemalloc_cpp.o src/jemalloc_cpp.cpp\n",
            "    ar crus lib/libjemalloc.a src/jemalloc.o src/arena.o src/background_thread.o src/base.o src/bin.o src/bitmap.o src/ckh.o src/ctl.o src/div.o src/extent.o src/extent_dss.o src/extent_mmap.o src/hash.o src/hooks.o src/large.o src/log.o src/malloc_io.o src/mutex.o src/mutex_pool.o src/nstime.o src/pages.o src/prng.o src/prof.o src/rtree.o src/stats.o src/sz.o src/tcache.o src/ticker.o src/tsd.o src/witness.o src/jemalloc_cpp.o\n",
            "    make[3]: Leaving directory '/root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/sandbox/processwrapper-sandbox/470/execroot/com_github_ray_project_ray/deps/jemalloc'\n",
            "    make[2]: Leaving directory '/root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/sandbox/processwrapper-sandbox/470/execroot/com_github_ray_project_ray/deps'\n",
            "\n",
            "    Hint: It's a good idea to run 'make test' ;)\n",
            "\n",
            "    make[1]: Leaving directory '/root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/sandbox/processwrapper-sandbox/470/execroot/com_github_ray_project_ray/src'\n",
            "    [581 / 648] Compiling src/ray/raylet/node_manager.cc; 16s processwrapper-sandbox ... (2 actions running)\n",
            "    [609 / 648] Compiling src/ray/gcs/tables.cc; 13s processwrapper-sandbox ... (2 actions running)\n",
            "    INFO: From Executing genrule //:ray_pkg:\n",
            "    ++ pwd\n",
            "    + WORK_DIR=/root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray\n",
            "    + cp -f bazel-out/k8-opt/bin/python/ray/_raylet.so /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray\n",
            "    + mkdir -p /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/src/ray/thirdparty/redis/src/\n",
            "    + cp -f bazel-out/k8-opt/genfiles/redis-server /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/src/ray/thirdparty/redis/src/\n",
            "    + cp -f bazel-out/k8-opt/genfiles/redis-cli /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/src/ray/thirdparty/redis/src/\n",
            "    + mkdir -p /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/src/ray/gcs/redis_module/\n",
            "    + cp -f bazel-out/k8-opt/bin/libray_redis_module.so /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/src/ray/gcs/redis_module/\n",
            "    + cp -f bazel-out/k8-opt/bin/raylet_monitor /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/src/ray/raylet/\n",
            "    + cp -f bazel-out/k8-opt/bin/external/plasma/plasma_store_server /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/src/plasma/\n",
            "    + cp -f bazel-out/k8-opt/bin/raylet /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/src/ray/raylet/\n",
            "    + for f in bazel-out/k8-opt/genfiles/ActorCheckpointIdData.py bazel-out/k8-opt/genfiles/ActorState.py bazel-out/k8-opt/genfiles/ActorTableData.py bazel-out/k8-opt/genfiles/Arg.py bazel-out/k8-opt/genfiles/ClassTableData.py bazel-out/k8-opt/genfiles/ClientTableData.py bazel-out/k8-opt/genfiles/ConfigTableData.py bazel-out/k8-opt/genfiles/CustomSerializerData.py bazel-out/k8-opt/genfiles/DriverTableData.py bazel-out/k8-opt/genfiles/EntryType.py bazel-out/k8-opt/genfiles/ErrorTableData.py bazel-out/k8-opt/genfiles/ErrorType.py bazel-out/k8-opt/genfiles/FunctionTableData.py bazel-out/k8-opt/genfiles/GcsTableEntry.py bazel-out/k8-opt/genfiles/HeartbeatBatchTableData.py bazel-out/k8-opt/genfiles/HeartbeatTableData.py bazel-out/k8-opt/genfiles/Language.py bazel-out/k8-opt/genfiles/ObjectTableData.py bazel-out/k8-opt/genfiles/ProfileEvent.py bazel-out/k8-opt/genfiles/ProfileTableData.py bazel-out/k8-opt/genfiles/RayResource.py bazel-out/k8-opt/genfiles/ResourcePair.py bazel-out/k8-opt/genfiles/SchedulingState.py bazel-out/k8-opt/genfiles/TablePrefix.py bazel-out/k8-opt/genfiles/TablePubsub.py bazel-out/k8-opt/genfiles/TaskInfo.py bazel-out/k8-opt/genfiles/TaskLeaseData.py bazel-out/k8-opt/genfiles/TaskReconstructionData.py bazel-out/k8-opt/genfiles/TaskTableData.py bazel-out/k8-opt/genfiles/TaskTableTestAndUpdate.py\n",
            "    + cp -f bazel-out/k8-opt/genfiles/ActorCheckpointIdData.py /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/\n",
            "    + for f in bazel-out/k8-opt/genfiles/ActorCheckpointIdData.py bazel-out/k8-opt/genfiles/ActorState.py bazel-out/k8-opt/genfiles/ActorTableData.py bazel-out/k8-opt/genfiles/Arg.py bazel-out/k8-opt/genfiles/ClassTableData.py bazel-out/k8-opt/genfiles/ClientTableData.py bazel-out/k8-opt/genfiles/ConfigTableData.py bazel-out/k8-opt/genfiles/CustomSerializerData.py bazel-out/k8-opt/genfiles/DriverTableData.py bazel-out/k8-opt/genfiles/EntryType.py bazel-out/k8-opt/genfiles/ErrorTableData.py bazel-out/k8-opt/genfiles/ErrorType.py bazel-out/k8-opt/genfiles/FunctionTableData.py bazel-out/k8-opt/genfiles/GcsTableEntry.py bazel-out/k8-opt/genfiles/HeartbeatBatchTableData.py bazel-out/k8-opt/genfiles/HeartbeatTableData.py bazel-out/k8-opt/genfiles/Language.py bazel-out/k8-opt/genfiles/ObjectTableData.py bazel-out/k8-opt/genfiles/ProfileEvent.py bazel-out/k8-opt/genfiles/ProfileTableData.py bazel-out/k8-opt/genfiles/RayResource.py bazel-out/k8-opt/genfiles/ResourcePair.py bazel-out/k8-opt/genfiles/SchedulingState.py bazel-out/k8-opt/genfiles/TablePrefix.py bazel-out/k8-opt/genfiles/TablePubsub.py bazel-out/k8-opt/genfiles/TaskInfo.py bazel-out/k8-opt/genfiles/TaskLeaseData.py bazel-out/k8-opt/genfiles/TaskReconstructionData.py bazel-out/k8-opt/genfiles/TaskTableData.py bazel-out/k8-opt/genfiles/TaskTableTestAndUpdate.py\n",
            "    + cp -f bazel-out/k8-opt/genfiles/ActorState.py /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/\n",
            "    + for f in bazel-out/k8-opt/genfiles/ActorCheckpointIdData.py bazel-out/k8-opt/genfiles/ActorState.py bazel-out/k8-opt/genfiles/ActorTableData.py bazel-out/k8-opt/genfiles/Arg.py bazel-out/k8-opt/genfiles/ClassTableData.py bazel-out/k8-opt/genfiles/ClientTableData.py bazel-out/k8-opt/genfiles/ConfigTableData.py bazel-out/k8-opt/genfiles/CustomSerializerData.py bazel-out/k8-opt/genfiles/DriverTableData.py bazel-out/k8-opt/genfiles/EntryType.py bazel-out/k8-opt/genfiles/ErrorTableData.py bazel-out/k8-opt/genfiles/ErrorType.py bazel-out/k8-opt/genfiles/FunctionTableData.py bazel-out/k8-opt/genfiles/GcsTableEntry.py bazel-out/k8-opt/genfiles/HeartbeatBatchTableData.py bazel-out/k8-opt/genfiles/HeartbeatTableData.py bazel-out/k8-opt/genfiles/Language.py bazel-out/k8-opt/genfiles/ObjectTableData.py bazel-out/k8-opt/genfiles/ProfileEvent.py bazel-out/k8-opt/genfiles/ProfileTableData.py bazel-out/k8-opt/genfiles/RayResource.py bazel-out/k8-opt/genfiles/ResourcePair.py bazel-out/k8-opt/genfiles/SchedulingState.py bazel-out/k8-opt/genfiles/TablePrefix.py bazel-out/k8-opt/genfiles/TablePubsub.py bazel-out/k8-opt/genfiles/TaskInfo.py bazel-out/k8-opt/genfiles/TaskLeaseData.py bazel-out/k8-opt/genfiles/TaskReconstructionData.py bazel-out/k8-opt/genfiles/TaskTableData.py bazel-out/k8-opt/genfiles/TaskTableTestAndUpdate.py\n",
            "    + cp -f bazel-out/k8-opt/genfiles/ActorTableData.py /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/\n",
            "    + for f in bazel-out/k8-opt/genfiles/ActorCheckpointIdData.py bazel-out/k8-opt/genfiles/ActorState.py bazel-out/k8-opt/genfiles/ActorTableData.py bazel-out/k8-opt/genfiles/Arg.py bazel-out/k8-opt/genfiles/ClassTableData.py bazel-out/k8-opt/genfiles/ClientTableData.py bazel-out/k8-opt/genfiles/ConfigTableData.py bazel-out/k8-opt/genfiles/CustomSerializerData.py bazel-out/k8-opt/genfiles/DriverTableData.py bazel-out/k8-opt/genfiles/EntryType.py bazel-out/k8-opt/genfiles/ErrorTableData.py bazel-out/k8-opt/genfiles/ErrorType.py bazel-out/k8-opt/genfiles/FunctionTableData.py bazel-out/k8-opt/genfiles/GcsTableEntry.py bazel-out/k8-opt/genfiles/HeartbeatBatchTableData.py bazel-out/k8-opt/genfiles/HeartbeatTableData.py bazel-out/k8-opt/genfiles/Language.py bazel-out/k8-opt/genfiles/ObjectTableData.py bazel-out/k8-opt/genfiles/ProfileEvent.py bazel-out/k8-opt/genfiles/ProfileTableData.py bazel-out/k8-opt/genfiles/RayResource.py bazel-out/k8-opt/genfiles/ResourcePair.py bazel-out/k8-opt/genfiles/SchedulingState.py bazel-out/k8-opt/genfiles/TablePrefix.py bazel-out/k8-opt/genfiles/TablePubsub.py bazel-out/k8-opt/genfiles/TaskInfo.py bazel-out/k8-opt/genfiles/TaskLeaseData.py bazel-out/k8-opt/genfiles/TaskReconstructionData.py bazel-out/k8-opt/genfiles/TaskTableData.py bazel-out/k8-opt/genfiles/TaskTableTestAndUpdate.py\n",
            "    + cp -f bazel-out/k8-opt/genfiles/Arg.py /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/\n",
            "    + for f in bazel-out/k8-opt/genfiles/ActorCheckpointIdData.py bazel-out/k8-opt/genfiles/ActorState.py bazel-out/k8-opt/genfiles/ActorTableData.py bazel-out/k8-opt/genfiles/Arg.py bazel-out/k8-opt/genfiles/ClassTableData.py bazel-out/k8-opt/genfiles/ClientTableData.py bazel-out/k8-opt/genfiles/ConfigTableData.py bazel-out/k8-opt/genfiles/CustomSerializerData.py bazel-out/k8-opt/genfiles/DriverTableData.py bazel-out/k8-opt/genfiles/EntryType.py bazel-out/k8-opt/genfiles/ErrorTableData.py bazel-out/k8-opt/genfiles/ErrorType.py bazel-out/k8-opt/genfiles/FunctionTableData.py bazel-out/k8-opt/genfiles/GcsTableEntry.py bazel-out/k8-opt/genfiles/HeartbeatBatchTableData.py bazel-out/k8-opt/genfiles/HeartbeatTableData.py bazel-out/k8-opt/genfiles/Language.py bazel-out/k8-opt/genfiles/ObjectTableData.py bazel-out/k8-opt/genfiles/ProfileEvent.py bazel-out/k8-opt/genfiles/ProfileTableData.py bazel-out/k8-opt/genfiles/RayResource.py bazel-out/k8-opt/genfiles/ResourcePair.py bazel-out/k8-opt/genfiles/SchedulingState.py bazel-out/k8-opt/genfiles/TablePrefix.py bazel-out/k8-opt/genfiles/TablePubsub.py bazel-out/k8-opt/genfiles/TaskInfo.py bazel-out/k8-opt/genfiles/TaskLeaseData.py bazel-out/k8-opt/genfiles/TaskReconstructionData.py bazel-out/k8-opt/genfiles/TaskTableData.py bazel-out/k8-opt/genfiles/TaskTableTestAndUpdate.py\n",
            "    + cp -f bazel-out/k8-opt/genfiles/ClassTableData.py /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/\n",
            "    + for f in bazel-out/k8-opt/genfiles/ActorCheckpointIdData.py bazel-out/k8-opt/genfiles/ActorState.py bazel-out/k8-opt/genfiles/ActorTableData.py bazel-out/k8-opt/genfiles/Arg.py bazel-out/k8-opt/genfiles/ClassTableData.py bazel-out/k8-opt/genfiles/ClientTableData.py bazel-out/k8-opt/genfiles/ConfigTableData.py bazel-out/k8-opt/genfiles/CustomSerializerData.py bazel-out/k8-opt/genfiles/DriverTableData.py bazel-out/k8-opt/genfiles/EntryType.py bazel-out/k8-opt/genfiles/ErrorTableData.py bazel-out/k8-opt/genfiles/ErrorType.py bazel-out/k8-opt/genfiles/FunctionTableData.py bazel-out/k8-opt/genfiles/GcsTableEntry.py bazel-out/k8-opt/genfiles/HeartbeatBatchTableData.py bazel-out/k8-opt/genfiles/HeartbeatTableData.py bazel-out/k8-opt/genfiles/Language.py bazel-out/k8-opt/genfiles/ObjectTableData.py bazel-out/k8-opt/genfiles/ProfileEvent.py bazel-out/k8-opt/genfiles/ProfileTableData.py bazel-out/k8-opt/genfiles/RayResource.py bazel-out/k8-opt/genfiles/ResourcePair.py bazel-out/k8-opt/genfiles/SchedulingState.py bazel-out/k8-opt/genfiles/TablePrefix.py bazel-out/k8-opt/genfiles/TablePubsub.py bazel-out/k8-opt/genfiles/TaskInfo.py bazel-out/k8-opt/genfiles/TaskLeaseData.py bazel-out/k8-opt/genfiles/TaskReconstructionData.py bazel-out/k8-opt/genfiles/TaskTableData.py bazel-out/k8-opt/genfiles/TaskTableTestAndUpdate.py\n",
            "    + cp -f bazel-out/k8-opt/genfiles/ClientTableData.py /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/\n",
            "    + for f in bazel-out/k8-opt/genfiles/ActorCheckpointIdData.py bazel-out/k8-opt/genfiles/ActorState.py bazel-out/k8-opt/genfiles/ActorTableData.py bazel-out/k8-opt/genfiles/Arg.py bazel-out/k8-opt/genfiles/ClassTableData.py bazel-out/k8-opt/genfiles/ClientTableData.py bazel-out/k8-opt/genfiles/ConfigTableData.py bazel-out/k8-opt/genfiles/CustomSerializerData.py bazel-out/k8-opt/genfiles/DriverTableData.py bazel-out/k8-opt/genfiles/EntryType.py bazel-out/k8-opt/genfiles/ErrorTableData.py bazel-out/k8-opt/genfiles/ErrorType.py bazel-out/k8-opt/genfiles/FunctionTableData.py bazel-out/k8-opt/genfiles/GcsTableEntry.py bazel-out/k8-opt/genfiles/HeartbeatBatchTableData.py bazel-out/k8-opt/genfiles/HeartbeatTableData.py bazel-out/k8-opt/genfiles/Language.py bazel-out/k8-opt/genfiles/ObjectTableData.py bazel-out/k8-opt/genfiles/ProfileEvent.py bazel-out/k8-opt/genfiles/ProfileTableData.py bazel-out/k8-opt/genfiles/RayResource.py bazel-out/k8-opt/genfiles/ResourcePair.py bazel-out/k8-opt/genfiles/SchedulingState.py bazel-out/k8-opt/genfiles/TablePrefix.py bazel-out/k8-opt/genfiles/TablePubsub.py bazel-out/k8-opt/genfiles/TaskInfo.py bazel-out/k8-opt/genfiles/TaskLeaseData.py bazel-out/k8-opt/genfiles/TaskReconstructionData.py bazel-out/k8-opt/genfiles/TaskTableData.py bazel-out/k8-opt/genfiles/TaskTableTestAndUpdate.py\n",
            "    + cp -f bazel-out/k8-opt/genfiles/ConfigTableData.py /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/\n",
            "    + for f in bazel-out/k8-opt/genfiles/ActorCheckpointIdData.py bazel-out/k8-opt/genfiles/ActorState.py bazel-out/k8-opt/genfiles/ActorTableData.py bazel-out/k8-opt/genfiles/Arg.py bazel-out/k8-opt/genfiles/ClassTableData.py bazel-out/k8-opt/genfiles/ClientTableData.py bazel-out/k8-opt/genfiles/ConfigTableData.py bazel-out/k8-opt/genfiles/CustomSerializerData.py bazel-out/k8-opt/genfiles/DriverTableData.py bazel-out/k8-opt/genfiles/EntryType.py bazel-out/k8-opt/genfiles/ErrorTableData.py bazel-out/k8-opt/genfiles/ErrorType.py bazel-out/k8-opt/genfiles/FunctionTableData.py bazel-out/k8-opt/genfiles/GcsTableEntry.py bazel-out/k8-opt/genfiles/HeartbeatBatchTableData.py bazel-out/k8-opt/genfiles/HeartbeatTableData.py bazel-out/k8-opt/genfiles/Language.py bazel-out/k8-opt/genfiles/ObjectTableData.py bazel-out/k8-opt/genfiles/ProfileEvent.py bazel-out/k8-opt/genfiles/ProfileTableData.py bazel-out/k8-opt/genfiles/RayResource.py bazel-out/k8-opt/genfiles/ResourcePair.py bazel-out/k8-opt/genfiles/SchedulingState.py bazel-out/k8-opt/genfiles/TablePrefix.py bazel-out/k8-opt/genfiles/TablePubsub.py bazel-out/k8-opt/genfiles/TaskInfo.py bazel-out/k8-opt/genfiles/TaskLeaseData.py bazel-out/k8-opt/genfiles/TaskReconstructionData.py bazel-out/k8-opt/genfiles/TaskTableData.py bazel-out/k8-opt/genfiles/TaskTableTestAndUpdate.py\n",
            "    + cp -f bazel-out/k8-opt/genfiles/CustomSerializerData.py /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/\n",
            "    + for f in bazel-out/k8-opt/genfiles/ActorCheckpointIdData.py bazel-out/k8-opt/genfiles/ActorState.py bazel-out/k8-opt/genfiles/ActorTableData.py bazel-out/k8-opt/genfiles/Arg.py bazel-out/k8-opt/genfiles/ClassTableData.py bazel-out/k8-opt/genfiles/ClientTableData.py bazel-out/k8-opt/genfiles/ConfigTableData.py bazel-out/k8-opt/genfiles/CustomSerializerData.py bazel-out/k8-opt/genfiles/DriverTableData.py bazel-out/k8-opt/genfiles/EntryType.py bazel-out/k8-opt/genfiles/ErrorTableData.py bazel-out/k8-opt/genfiles/ErrorType.py bazel-out/k8-opt/genfiles/FunctionTableData.py bazel-out/k8-opt/genfiles/GcsTableEntry.py bazel-out/k8-opt/genfiles/HeartbeatBatchTableData.py bazel-out/k8-opt/genfiles/HeartbeatTableData.py bazel-out/k8-opt/genfiles/Language.py bazel-out/k8-opt/genfiles/ObjectTableData.py bazel-out/k8-opt/genfiles/ProfileEvent.py bazel-out/k8-opt/genfiles/ProfileTableData.py bazel-out/k8-opt/genfiles/RayResource.py bazel-out/k8-opt/genfiles/ResourcePair.py bazel-out/k8-opt/genfiles/SchedulingState.py bazel-out/k8-opt/genfiles/TablePrefix.py bazel-out/k8-opt/genfiles/TablePubsub.py bazel-out/k8-opt/genfiles/TaskInfo.py bazel-out/k8-opt/genfiles/TaskLeaseData.py bazel-out/k8-opt/genfiles/TaskReconstructionData.py bazel-out/k8-opt/genfiles/TaskTableData.py bazel-out/k8-opt/genfiles/TaskTableTestAndUpdate.py\n",
            "    + cp -f bazel-out/k8-opt/genfiles/DriverTableData.py /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/\n",
            "    + for f in bazel-out/k8-opt/genfiles/ActorCheckpointIdData.py bazel-out/k8-opt/genfiles/ActorState.py bazel-out/k8-opt/genfiles/ActorTableData.py bazel-out/k8-opt/genfiles/Arg.py bazel-out/k8-opt/genfiles/ClassTableData.py bazel-out/k8-opt/genfiles/ClientTableData.py bazel-out/k8-opt/genfiles/ConfigTableData.py bazel-out/k8-opt/genfiles/CustomSerializerData.py bazel-out/k8-opt/genfiles/DriverTableData.py bazel-out/k8-opt/genfiles/EntryType.py bazel-out/k8-opt/genfiles/ErrorTableData.py bazel-out/k8-opt/genfiles/ErrorType.py bazel-out/k8-opt/genfiles/FunctionTableData.py bazel-out/k8-opt/genfiles/GcsTableEntry.py bazel-out/k8-opt/genfiles/HeartbeatBatchTableData.py bazel-out/k8-opt/genfiles/HeartbeatTableData.py bazel-out/k8-opt/genfiles/Language.py bazel-out/k8-opt/genfiles/ObjectTableData.py bazel-out/k8-opt/genfiles/ProfileEvent.py bazel-out/k8-opt/genfiles/ProfileTableData.py bazel-out/k8-opt/genfiles/RayResource.py bazel-out/k8-opt/genfiles/ResourcePair.py bazel-out/k8-opt/genfiles/SchedulingState.py bazel-out/k8-opt/genfiles/TablePrefix.py bazel-out/k8-opt/genfiles/TablePubsub.py bazel-out/k8-opt/genfiles/TaskInfo.py bazel-out/k8-opt/genfiles/TaskLeaseData.py bazel-out/k8-opt/genfiles/TaskReconstructionData.py bazel-out/k8-opt/genfiles/TaskTableData.py bazel-out/k8-opt/genfiles/TaskTableTestAndUpdate.py\n",
            "    + cp -f bazel-out/k8-opt/genfiles/EntryType.py /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/\n",
            "    + for f in bazel-out/k8-opt/genfiles/ActorCheckpointIdData.py bazel-out/k8-opt/genfiles/ActorState.py bazel-out/k8-opt/genfiles/ActorTableData.py bazel-out/k8-opt/genfiles/Arg.py bazel-out/k8-opt/genfiles/ClassTableData.py bazel-out/k8-opt/genfiles/ClientTableData.py bazel-out/k8-opt/genfiles/ConfigTableData.py bazel-out/k8-opt/genfiles/CustomSerializerData.py bazel-out/k8-opt/genfiles/DriverTableData.py bazel-out/k8-opt/genfiles/EntryType.py bazel-out/k8-opt/genfiles/ErrorTableData.py bazel-out/k8-opt/genfiles/ErrorType.py bazel-out/k8-opt/genfiles/FunctionTableData.py bazel-out/k8-opt/genfiles/GcsTableEntry.py bazel-out/k8-opt/genfiles/HeartbeatBatchTableData.py bazel-out/k8-opt/genfiles/HeartbeatTableData.py bazel-out/k8-opt/genfiles/Language.py bazel-out/k8-opt/genfiles/ObjectTableData.py bazel-out/k8-opt/genfiles/ProfileEvent.py bazel-out/k8-opt/genfiles/ProfileTableData.py bazel-out/k8-opt/genfiles/RayResource.py bazel-out/k8-opt/genfiles/ResourcePair.py bazel-out/k8-opt/genfiles/SchedulingState.py bazel-out/k8-opt/genfiles/TablePrefix.py bazel-out/k8-opt/genfiles/TablePubsub.py bazel-out/k8-opt/genfiles/TaskInfo.py bazel-out/k8-opt/genfiles/TaskLeaseData.py bazel-out/k8-opt/genfiles/TaskReconstructionData.py bazel-out/k8-opt/genfiles/TaskTableData.py bazel-out/k8-opt/genfiles/TaskTableTestAndUpdate.py\n",
            "    + cp -f bazel-out/k8-opt/genfiles/ErrorTableData.py /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/\n",
            "    + for f in bazel-out/k8-opt/genfiles/ActorCheckpointIdData.py bazel-out/k8-opt/genfiles/ActorState.py bazel-out/k8-opt/genfiles/ActorTableData.py bazel-out/k8-opt/genfiles/Arg.py bazel-out/k8-opt/genfiles/ClassTableData.py bazel-out/k8-opt/genfiles/ClientTableData.py bazel-out/k8-opt/genfiles/ConfigTableData.py bazel-out/k8-opt/genfiles/CustomSerializerData.py bazel-out/k8-opt/genfiles/DriverTableData.py bazel-out/k8-opt/genfiles/EntryType.py bazel-out/k8-opt/genfiles/ErrorTableData.py bazel-out/k8-opt/genfiles/ErrorType.py bazel-out/k8-opt/genfiles/FunctionTableData.py bazel-out/k8-opt/genfiles/GcsTableEntry.py bazel-out/k8-opt/genfiles/HeartbeatBatchTableData.py bazel-out/k8-opt/genfiles/HeartbeatTableData.py bazel-out/k8-opt/genfiles/Language.py bazel-out/k8-opt/genfiles/ObjectTableData.py bazel-out/k8-opt/genfiles/ProfileEvent.py bazel-out/k8-opt/genfiles/ProfileTableData.py bazel-out/k8-opt/genfiles/RayResource.py bazel-out/k8-opt/genfiles/ResourcePair.py bazel-out/k8-opt/genfiles/SchedulingState.py bazel-out/k8-opt/genfiles/TablePrefix.py bazel-out/k8-opt/genfiles/TablePubsub.py bazel-out/k8-opt/genfiles/TaskInfo.py bazel-out/k8-opt/genfiles/TaskLeaseData.py bazel-out/k8-opt/genfiles/TaskReconstructionData.py bazel-out/k8-opt/genfiles/TaskTableData.py bazel-out/k8-opt/genfiles/TaskTableTestAndUpdate.py\n",
            "    + cp -f bazel-out/k8-opt/genfiles/ErrorType.py /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/\n",
            "    + for f in bazel-out/k8-opt/genfiles/ActorCheckpointIdData.py bazel-out/k8-opt/genfiles/ActorState.py bazel-out/k8-opt/genfiles/ActorTableData.py bazel-out/k8-opt/genfiles/Arg.py bazel-out/k8-opt/genfiles/ClassTableData.py bazel-out/k8-opt/genfiles/ClientTableData.py bazel-out/k8-opt/genfiles/ConfigTableData.py bazel-out/k8-opt/genfiles/CustomSerializerData.py bazel-out/k8-opt/genfiles/DriverTableData.py bazel-out/k8-opt/genfiles/EntryType.py bazel-out/k8-opt/genfiles/ErrorTableData.py bazel-out/k8-opt/genfiles/ErrorType.py bazel-out/k8-opt/genfiles/FunctionTableData.py bazel-out/k8-opt/genfiles/GcsTableEntry.py bazel-out/k8-opt/genfiles/HeartbeatBatchTableData.py bazel-out/k8-opt/genfiles/HeartbeatTableData.py bazel-out/k8-opt/genfiles/Language.py bazel-out/k8-opt/genfiles/ObjectTableData.py bazel-out/k8-opt/genfiles/ProfileEvent.py bazel-out/k8-opt/genfiles/ProfileTableData.py bazel-out/k8-opt/genfiles/RayResource.py bazel-out/k8-opt/genfiles/ResourcePair.py bazel-out/k8-opt/genfiles/SchedulingState.py bazel-out/k8-opt/genfiles/TablePrefix.py bazel-out/k8-opt/genfiles/TablePubsub.py bazel-out/k8-opt/genfiles/TaskInfo.py bazel-out/k8-opt/genfiles/TaskLeaseData.py bazel-out/k8-opt/genfiles/TaskReconstructionData.py bazel-out/k8-opt/genfiles/TaskTableData.py bazel-out/k8-opt/genfiles/TaskTableTestAndUpdate.py\n",
            "    + cp -f bazel-out/k8-opt/genfiles/FunctionTableData.py /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/\n",
            "    + for f in bazel-out/k8-opt/genfiles/ActorCheckpointIdData.py bazel-out/k8-opt/genfiles/ActorState.py bazel-out/k8-opt/genfiles/ActorTableData.py bazel-out/k8-opt/genfiles/Arg.py bazel-out/k8-opt/genfiles/ClassTableData.py bazel-out/k8-opt/genfiles/ClientTableData.py bazel-out/k8-opt/genfiles/ConfigTableData.py bazel-out/k8-opt/genfiles/CustomSerializerData.py bazel-out/k8-opt/genfiles/DriverTableData.py bazel-out/k8-opt/genfiles/EntryType.py bazel-out/k8-opt/genfiles/ErrorTableData.py bazel-out/k8-opt/genfiles/ErrorType.py bazel-out/k8-opt/genfiles/FunctionTableData.py bazel-out/k8-opt/genfiles/GcsTableEntry.py bazel-out/k8-opt/genfiles/HeartbeatBatchTableData.py bazel-out/k8-opt/genfiles/HeartbeatTableData.py bazel-out/k8-opt/genfiles/Language.py bazel-out/k8-opt/genfiles/ObjectTableData.py bazel-out/k8-opt/genfiles/ProfileEvent.py bazel-out/k8-opt/genfiles/ProfileTableData.py bazel-out/k8-opt/genfiles/RayResource.py bazel-out/k8-opt/genfiles/ResourcePair.py bazel-out/k8-opt/genfiles/SchedulingState.py bazel-out/k8-opt/genfiles/TablePrefix.py bazel-out/k8-opt/genfiles/TablePubsub.py bazel-out/k8-opt/genfiles/TaskInfo.py bazel-out/k8-opt/genfiles/TaskLeaseData.py bazel-out/k8-opt/genfiles/TaskReconstructionData.py bazel-out/k8-opt/genfiles/TaskTableData.py bazel-out/k8-opt/genfiles/TaskTableTestAndUpdate.py\n",
            "    + cp -f bazel-out/k8-opt/genfiles/GcsTableEntry.py /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/\n",
            "    + for f in bazel-out/k8-opt/genfiles/ActorCheckpointIdData.py bazel-out/k8-opt/genfiles/ActorState.py bazel-out/k8-opt/genfiles/ActorTableData.py bazel-out/k8-opt/genfiles/Arg.py bazel-out/k8-opt/genfiles/ClassTableData.py bazel-out/k8-opt/genfiles/ClientTableData.py bazel-out/k8-opt/genfiles/ConfigTableData.py bazel-out/k8-opt/genfiles/CustomSerializerData.py bazel-out/k8-opt/genfiles/DriverTableData.py bazel-out/k8-opt/genfiles/EntryType.py bazel-out/k8-opt/genfiles/ErrorTableData.py bazel-out/k8-opt/genfiles/ErrorType.py bazel-out/k8-opt/genfiles/FunctionTableData.py bazel-out/k8-opt/genfiles/GcsTableEntry.py bazel-out/k8-opt/genfiles/HeartbeatBatchTableData.py bazel-out/k8-opt/genfiles/HeartbeatTableData.py bazel-out/k8-opt/genfiles/Language.py bazel-out/k8-opt/genfiles/ObjectTableData.py bazel-out/k8-opt/genfiles/ProfileEvent.py bazel-out/k8-opt/genfiles/ProfileTableData.py bazel-out/k8-opt/genfiles/RayResource.py bazel-out/k8-opt/genfiles/ResourcePair.py bazel-out/k8-opt/genfiles/SchedulingState.py bazel-out/k8-opt/genfiles/TablePrefix.py bazel-out/k8-opt/genfiles/TablePubsub.py bazel-out/k8-opt/genfiles/TaskInfo.py bazel-out/k8-opt/genfiles/TaskLeaseData.py bazel-out/k8-opt/genfiles/TaskReconstructionData.py bazel-out/k8-opt/genfiles/TaskTableData.py bazel-out/k8-opt/genfiles/TaskTableTestAndUpdate.py\n",
            "    + cp -f bazel-out/k8-opt/genfiles/HeartbeatBatchTableData.py /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/\n",
            "    + for f in bazel-out/k8-opt/genfiles/ActorCheckpointIdData.py bazel-out/k8-opt/genfiles/ActorState.py bazel-out/k8-opt/genfiles/ActorTableData.py bazel-out/k8-opt/genfiles/Arg.py bazel-out/k8-opt/genfiles/ClassTableData.py bazel-out/k8-opt/genfiles/ClientTableData.py bazel-out/k8-opt/genfiles/ConfigTableData.py bazel-out/k8-opt/genfiles/CustomSerializerData.py bazel-out/k8-opt/genfiles/DriverTableData.py bazel-out/k8-opt/genfiles/EntryType.py bazel-out/k8-opt/genfiles/ErrorTableData.py bazel-out/k8-opt/genfiles/ErrorType.py bazel-out/k8-opt/genfiles/FunctionTableData.py bazel-out/k8-opt/genfiles/GcsTableEntry.py bazel-out/k8-opt/genfiles/HeartbeatBatchTableData.py bazel-out/k8-opt/genfiles/HeartbeatTableData.py bazel-out/k8-opt/genfiles/Language.py bazel-out/k8-opt/genfiles/ObjectTableData.py bazel-out/k8-opt/genfiles/ProfileEvent.py bazel-out/k8-opt/genfiles/ProfileTableData.py bazel-out/k8-opt/genfiles/RayResource.py bazel-out/k8-opt/genfiles/ResourcePair.py bazel-out/k8-opt/genfiles/SchedulingState.py bazel-out/k8-opt/genfiles/TablePrefix.py bazel-out/k8-opt/genfiles/TablePubsub.py bazel-out/k8-opt/genfiles/TaskInfo.py bazel-out/k8-opt/genfiles/TaskLeaseData.py bazel-out/k8-opt/genfiles/TaskReconstructionData.py bazel-out/k8-opt/genfiles/TaskTableData.py bazel-out/k8-opt/genfiles/TaskTableTestAndUpdate.py\n",
            "    + cp -f bazel-out/k8-opt/genfiles/HeartbeatTableData.py /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/\n",
            "    + for f in bazel-out/k8-opt/genfiles/ActorCheckpointIdData.py bazel-out/k8-opt/genfiles/ActorState.py bazel-out/k8-opt/genfiles/ActorTableData.py bazel-out/k8-opt/genfiles/Arg.py bazel-out/k8-opt/genfiles/ClassTableData.py bazel-out/k8-opt/genfiles/ClientTableData.py bazel-out/k8-opt/genfiles/ConfigTableData.py bazel-out/k8-opt/genfiles/CustomSerializerData.py bazel-out/k8-opt/genfiles/DriverTableData.py bazel-out/k8-opt/genfiles/EntryType.py bazel-out/k8-opt/genfiles/ErrorTableData.py bazel-out/k8-opt/genfiles/ErrorType.py bazel-out/k8-opt/genfiles/FunctionTableData.py bazel-out/k8-opt/genfiles/GcsTableEntry.py bazel-out/k8-opt/genfiles/HeartbeatBatchTableData.py bazel-out/k8-opt/genfiles/HeartbeatTableData.py bazel-out/k8-opt/genfiles/Language.py bazel-out/k8-opt/genfiles/ObjectTableData.py bazel-out/k8-opt/genfiles/ProfileEvent.py bazel-out/k8-opt/genfiles/ProfileTableData.py bazel-out/k8-opt/genfiles/RayResource.py bazel-out/k8-opt/genfiles/ResourcePair.py bazel-out/k8-opt/genfiles/SchedulingState.py bazel-out/k8-opt/genfiles/TablePrefix.py bazel-out/k8-opt/genfiles/TablePubsub.py bazel-out/k8-opt/genfiles/TaskInfo.py bazel-out/k8-opt/genfiles/TaskLeaseData.py bazel-out/k8-opt/genfiles/TaskReconstructionData.py bazel-out/k8-opt/genfiles/TaskTableData.py bazel-out/k8-opt/genfiles/TaskTableTestAndUpdate.py\n",
            "    + cp -f bazel-out/k8-opt/genfiles/Language.py /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/\n",
            "    + for f in bazel-out/k8-opt/genfiles/ActorCheckpointIdData.py bazel-out/k8-opt/genfiles/ActorState.py bazel-out/k8-opt/genfiles/ActorTableData.py bazel-out/k8-opt/genfiles/Arg.py bazel-out/k8-opt/genfiles/ClassTableData.py bazel-out/k8-opt/genfiles/ClientTableData.py bazel-out/k8-opt/genfiles/ConfigTableData.py bazel-out/k8-opt/genfiles/CustomSerializerData.py bazel-out/k8-opt/genfiles/DriverTableData.py bazel-out/k8-opt/genfiles/EntryType.py bazel-out/k8-opt/genfiles/ErrorTableData.py bazel-out/k8-opt/genfiles/ErrorType.py bazel-out/k8-opt/genfiles/FunctionTableData.py bazel-out/k8-opt/genfiles/GcsTableEntry.py bazel-out/k8-opt/genfiles/HeartbeatBatchTableData.py bazel-out/k8-opt/genfiles/HeartbeatTableData.py bazel-out/k8-opt/genfiles/Language.py bazel-out/k8-opt/genfiles/ObjectTableData.py bazel-out/k8-opt/genfiles/ProfileEvent.py bazel-out/k8-opt/genfiles/ProfileTableData.py bazel-out/k8-opt/genfiles/RayResource.py bazel-out/k8-opt/genfiles/ResourcePair.py bazel-out/k8-opt/genfiles/SchedulingState.py bazel-out/k8-opt/genfiles/TablePrefix.py bazel-out/k8-opt/genfiles/TablePubsub.py bazel-out/k8-opt/genfiles/TaskInfo.py bazel-out/k8-opt/genfiles/TaskLeaseData.py bazel-out/k8-opt/genfiles/TaskReconstructionData.py bazel-out/k8-opt/genfiles/TaskTableData.py bazel-out/k8-opt/genfiles/TaskTableTestAndUpdate.py\n",
            "    + cp -f bazel-out/k8-opt/genfiles/ObjectTableData.py /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/\n",
            "    + for f in bazel-out/k8-opt/genfiles/ActorCheckpointIdData.py bazel-out/k8-opt/genfiles/ActorState.py bazel-out/k8-opt/genfiles/ActorTableData.py bazel-out/k8-opt/genfiles/Arg.py bazel-out/k8-opt/genfiles/ClassTableData.py bazel-out/k8-opt/genfiles/ClientTableData.py bazel-out/k8-opt/genfiles/ConfigTableData.py bazel-out/k8-opt/genfiles/CustomSerializerData.py bazel-out/k8-opt/genfiles/DriverTableData.py bazel-out/k8-opt/genfiles/EntryType.py bazel-out/k8-opt/genfiles/ErrorTableData.py bazel-out/k8-opt/genfiles/ErrorType.py bazel-out/k8-opt/genfiles/FunctionTableData.py bazel-out/k8-opt/genfiles/GcsTableEntry.py bazel-out/k8-opt/genfiles/HeartbeatBatchTableData.py bazel-out/k8-opt/genfiles/HeartbeatTableData.py bazel-out/k8-opt/genfiles/Language.py bazel-out/k8-opt/genfiles/ObjectTableData.py bazel-out/k8-opt/genfiles/ProfileEvent.py bazel-out/k8-opt/genfiles/ProfileTableData.py bazel-out/k8-opt/genfiles/RayResource.py bazel-out/k8-opt/genfiles/ResourcePair.py bazel-out/k8-opt/genfiles/SchedulingState.py bazel-out/k8-opt/genfiles/TablePrefix.py bazel-out/k8-opt/genfiles/TablePubsub.py bazel-out/k8-opt/genfiles/TaskInfo.py bazel-out/k8-opt/genfiles/TaskLeaseData.py bazel-out/k8-opt/genfiles/TaskReconstructionData.py bazel-out/k8-opt/genfiles/TaskTableData.py bazel-out/k8-opt/genfiles/TaskTableTestAndUpdate.py\n",
            "    + cp -f bazel-out/k8-opt/genfiles/ProfileEvent.py /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/\n",
            "    + for f in bazel-out/k8-opt/genfiles/ActorCheckpointIdData.py bazel-out/k8-opt/genfiles/ActorState.py bazel-out/k8-opt/genfiles/ActorTableData.py bazel-out/k8-opt/genfiles/Arg.py bazel-out/k8-opt/genfiles/ClassTableData.py bazel-out/k8-opt/genfiles/ClientTableData.py bazel-out/k8-opt/genfiles/ConfigTableData.py bazel-out/k8-opt/genfiles/CustomSerializerData.py bazel-out/k8-opt/genfiles/DriverTableData.py bazel-out/k8-opt/genfiles/EntryType.py bazel-out/k8-opt/genfiles/ErrorTableData.py bazel-out/k8-opt/genfiles/ErrorType.py bazel-out/k8-opt/genfiles/FunctionTableData.py bazel-out/k8-opt/genfiles/GcsTableEntry.py bazel-out/k8-opt/genfiles/HeartbeatBatchTableData.py bazel-out/k8-opt/genfiles/HeartbeatTableData.py bazel-out/k8-opt/genfiles/Language.py bazel-out/k8-opt/genfiles/ObjectTableData.py bazel-out/k8-opt/genfiles/ProfileEvent.py bazel-out/k8-opt/genfiles/ProfileTableData.py bazel-out/k8-opt/genfiles/RayResource.py bazel-out/k8-opt/genfiles/ResourcePair.py bazel-out/k8-opt/genfiles/SchedulingState.py bazel-out/k8-opt/genfiles/TablePrefix.py bazel-out/k8-opt/genfiles/TablePubsub.py bazel-out/k8-opt/genfiles/TaskInfo.py bazel-out/k8-opt/genfiles/TaskLeaseData.py bazel-out/k8-opt/genfiles/TaskReconstructionData.py bazel-out/k8-opt/genfiles/TaskTableData.py bazel-out/k8-opt/genfiles/TaskTableTestAndUpdate.py\n",
            "    + cp -f bazel-out/k8-opt/genfiles/ProfileTableData.py /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/\n",
            "    + for f in bazel-out/k8-opt/genfiles/ActorCheckpointIdData.py bazel-out/k8-opt/genfiles/ActorState.py bazel-out/k8-opt/genfiles/ActorTableData.py bazel-out/k8-opt/genfiles/Arg.py bazel-out/k8-opt/genfiles/ClassTableData.py bazel-out/k8-opt/genfiles/ClientTableData.py bazel-out/k8-opt/genfiles/ConfigTableData.py bazel-out/k8-opt/genfiles/CustomSerializerData.py bazel-out/k8-opt/genfiles/DriverTableData.py bazel-out/k8-opt/genfiles/EntryType.py bazel-out/k8-opt/genfiles/ErrorTableData.py bazel-out/k8-opt/genfiles/ErrorType.py bazel-out/k8-opt/genfiles/FunctionTableData.py bazel-out/k8-opt/genfiles/GcsTableEntry.py bazel-out/k8-opt/genfiles/HeartbeatBatchTableData.py bazel-out/k8-opt/genfiles/HeartbeatTableData.py bazel-out/k8-opt/genfiles/Language.py bazel-out/k8-opt/genfiles/ObjectTableData.py bazel-out/k8-opt/genfiles/ProfileEvent.py bazel-out/k8-opt/genfiles/ProfileTableData.py bazel-out/k8-opt/genfiles/RayResource.py bazel-out/k8-opt/genfiles/ResourcePair.py bazel-out/k8-opt/genfiles/SchedulingState.py bazel-out/k8-opt/genfiles/TablePrefix.py bazel-out/k8-opt/genfiles/TablePubsub.py bazel-out/k8-opt/genfiles/TaskInfo.py bazel-out/k8-opt/genfiles/TaskLeaseData.py bazel-out/k8-opt/genfiles/TaskReconstructionData.py bazel-out/k8-opt/genfiles/TaskTableData.py bazel-out/k8-opt/genfiles/TaskTableTestAndUpdate.py\n",
            "    + cp -f bazel-out/k8-opt/genfiles/RayResource.py /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/\n",
            "    + for f in bazel-out/k8-opt/genfiles/ActorCheckpointIdData.py bazel-out/k8-opt/genfiles/ActorState.py bazel-out/k8-opt/genfiles/ActorTableData.py bazel-out/k8-opt/genfiles/Arg.py bazel-out/k8-opt/genfiles/ClassTableData.py bazel-out/k8-opt/genfiles/ClientTableData.py bazel-out/k8-opt/genfiles/ConfigTableData.py bazel-out/k8-opt/genfiles/CustomSerializerData.py bazel-out/k8-opt/genfiles/DriverTableData.py bazel-out/k8-opt/genfiles/EntryType.py bazel-out/k8-opt/genfiles/ErrorTableData.py bazel-out/k8-opt/genfiles/ErrorType.py bazel-out/k8-opt/genfiles/FunctionTableData.py bazel-out/k8-opt/genfiles/GcsTableEntry.py bazel-out/k8-opt/genfiles/HeartbeatBatchTableData.py bazel-out/k8-opt/genfiles/HeartbeatTableData.py bazel-out/k8-opt/genfiles/Language.py bazel-out/k8-opt/genfiles/ObjectTableData.py bazel-out/k8-opt/genfiles/ProfileEvent.py bazel-out/k8-opt/genfiles/ProfileTableData.py bazel-out/k8-opt/genfiles/RayResource.py bazel-out/k8-opt/genfiles/ResourcePair.py bazel-out/k8-opt/genfiles/SchedulingState.py bazel-out/k8-opt/genfiles/TablePrefix.py bazel-out/k8-opt/genfiles/TablePubsub.py bazel-out/k8-opt/genfiles/TaskInfo.py bazel-out/k8-opt/genfiles/TaskLeaseData.py bazel-out/k8-opt/genfiles/TaskReconstructionData.py bazel-out/k8-opt/genfiles/TaskTableData.py bazel-out/k8-opt/genfiles/TaskTableTestAndUpdate.py\n",
            "    + cp -f bazel-out/k8-opt/genfiles/ResourcePair.py /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/\n",
            "    + for f in bazel-out/k8-opt/genfiles/ActorCheckpointIdData.py bazel-out/k8-opt/genfiles/ActorState.py bazel-out/k8-opt/genfiles/ActorTableData.py bazel-out/k8-opt/genfiles/Arg.py bazel-out/k8-opt/genfiles/ClassTableData.py bazel-out/k8-opt/genfiles/ClientTableData.py bazel-out/k8-opt/genfiles/ConfigTableData.py bazel-out/k8-opt/genfiles/CustomSerializerData.py bazel-out/k8-opt/genfiles/DriverTableData.py bazel-out/k8-opt/genfiles/EntryType.py bazel-out/k8-opt/genfiles/ErrorTableData.py bazel-out/k8-opt/genfiles/ErrorType.py bazel-out/k8-opt/genfiles/FunctionTableData.py bazel-out/k8-opt/genfiles/GcsTableEntry.py bazel-out/k8-opt/genfiles/HeartbeatBatchTableData.py bazel-out/k8-opt/genfiles/HeartbeatTableData.py bazel-out/k8-opt/genfiles/Language.py bazel-out/k8-opt/genfiles/ObjectTableData.py bazel-out/k8-opt/genfiles/ProfileEvent.py bazel-out/k8-opt/genfiles/ProfileTableData.py bazel-out/k8-opt/genfiles/RayResource.py bazel-out/k8-opt/genfiles/ResourcePair.py bazel-out/k8-opt/genfiles/SchedulingState.py bazel-out/k8-opt/genfiles/TablePrefix.py bazel-out/k8-opt/genfiles/TablePubsub.py bazel-out/k8-opt/genfiles/TaskInfo.py bazel-out/k8-opt/genfiles/TaskLeaseData.py bazel-out/k8-opt/genfiles/TaskReconstructionData.py bazel-out/k8-opt/genfiles/TaskTableData.py bazel-out/k8-opt/genfiles/TaskTableTestAndUpdate.py\n",
            "    + cp -f bazel-out/k8-opt/genfiles/SchedulingState.py /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/\n",
            "    + for f in bazel-out/k8-opt/genfiles/ActorCheckpointIdData.py bazel-out/k8-opt/genfiles/ActorState.py bazel-out/k8-opt/genfiles/ActorTableData.py bazel-out/k8-opt/genfiles/Arg.py bazel-out/k8-opt/genfiles/ClassTableData.py bazel-out/k8-opt/genfiles/ClientTableData.py bazel-out/k8-opt/genfiles/ConfigTableData.py bazel-out/k8-opt/genfiles/CustomSerializerData.py bazel-out/k8-opt/genfiles/DriverTableData.py bazel-out/k8-opt/genfiles/EntryType.py bazel-out/k8-opt/genfiles/ErrorTableData.py bazel-out/k8-opt/genfiles/ErrorType.py bazel-out/k8-opt/genfiles/FunctionTableData.py bazel-out/k8-opt/genfiles/GcsTableEntry.py bazel-out/k8-opt/genfiles/HeartbeatBatchTableData.py bazel-out/k8-opt/genfiles/HeartbeatTableData.py bazel-out/k8-opt/genfiles/Language.py bazel-out/k8-opt/genfiles/ObjectTableData.py bazel-out/k8-opt/genfiles/ProfileEvent.py bazel-out/k8-opt/genfiles/ProfileTableData.py bazel-out/k8-opt/genfiles/RayResource.py bazel-out/k8-opt/genfiles/ResourcePair.py bazel-out/k8-opt/genfiles/SchedulingState.py bazel-out/k8-opt/genfiles/TablePrefix.py bazel-out/k8-opt/genfiles/TablePubsub.py bazel-out/k8-opt/genfiles/TaskInfo.py bazel-out/k8-opt/genfiles/TaskLeaseData.py bazel-out/k8-opt/genfiles/TaskReconstructionData.py bazel-out/k8-opt/genfiles/TaskTableData.py bazel-out/k8-opt/genfiles/TaskTableTestAndUpdate.py\n",
            "    + cp -f bazel-out/k8-opt/genfiles/TablePrefix.py /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/\n",
            "    + for f in bazel-out/k8-opt/genfiles/ActorCheckpointIdData.py bazel-out/k8-opt/genfiles/ActorState.py bazel-out/k8-opt/genfiles/ActorTableData.py bazel-out/k8-opt/genfiles/Arg.py bazel-out/k8-opt/genfiles/ClassTableData.py bazel-out/k8-opt/genfiles/ClientTableData.py bazel-out/k8-opt/genfiles/ConfigTableData.py bazel-out/k8-opt/genfiles/CustomSerializerData.py bazel-out/k8-opt/genfiles/DriverTableData.py bazel-out/k8-opt/genfiles/EntryType.py bazel-out/k8-opt/genfiles/ErrorTableData.py bazel-out/k8-opt/genfiles/ErrorType.py bazel-out/k8-opt/genfiles/FunctionTableData.py bazel-out/k8-opt/genfiles/GcsTableEntry.py bazel-out/k8-opt/genfiles/HeartbeatBatchTableData.py bazel-out/k8-opt/genfiles/HeartbeatTableData.py bazel-out/k8-opt/genfiles/Language.py bazel-out/k8-opt/genfiles/ObjectTableData.py bazel-out/k8-opt/genfiles/ProfileEvent.py bazel-out/k8-opt/genfiles/ProfileTableData.py bazel-out/k8-opt/genfiles/RayResource.py bazel-out/k8-opt/genfiles/ResourcePair.py bazel-out/k8-opt/genfiles/SchedulingState.py bazel-out/k8-opt/genfiles/TablePrefix.py bazel-out/k8-opt/genfiles/TablePubsub.py bazel-out/k8-opt/genfiles/TaskInfo.py bazel-out/k8-opt/genfiles/TaskLeaseData.py bazel-out/k8-opt/genfiles/TaskReconstructionData.py bazel-out/k8-opt/genfiles/TaskTableData.py bazel-out/k8-opt/genfiles/TaskTableTestAndUpdate.py\n",
            "    + cp -f bazel-out/k8-opt/genfiles/TablePubsub.py /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/\n",
            "    + for f in bazel-out/k8-opt/genfiles/ActorCheckpointIdData.py bazel-out/k8-opt/genfiles/ActorState.py bazel-out/k8-opt/genfiles/ActorTableData.py bazel-out/k8-opt/genfiles/Arg.py bazel-out/k8-opt/genfiles/ClassTableData.py bazel-out/k8-opt/genfiles/ClientTableData.py bazel-out/k8-opt/genfiles/ConfigTableData.py bazel-out/k8-opt/genfiles/CustomSerializerData.py bazel-out/k8-opt/genfiles/DriverTableData.py bazel-out/k8-opt/genfiles/EntryType.py bazel-out/k8-opt/genfiles/ErrorTableData.py bazel-out/k8-opt/genfiles/ErrorType.py bazel-out/k8-opt/genfiles/FunctionTableData.py bazel-out/k8-opt/genfiles/GcsTableEntry.py bazel-out/k8-opt/genfiles/HeartbeatBatchTableData.py bazel-out/k8-opt/genfiles/HeartbeatTableData.py bazel-out/k8-opt/genfiles/Language.py bazel-out/k8-opt/genfiles/ObjectTableData.py bazel-out/k8-opt/genfiles/ProfileEvent.py bazel-out/k8-opt/genfiles/ProfileTableData.py bazel-out/k8-opt/genfiles/RayResource.py bazel-out/k8-opt/genfiles/ResourcePair.py bazel-out/k8-opt/genfiles/SchedulingState.py bazel-out/k8-opt/genfiles/TablePrefix.py bazel-out/k8-opt/genfiles/TablePubsub.py bazel-out/k8-opt/genfiles/TaskInfo.py bazel-out/k8-opt/genfiles/TaskLeaseData.py bazel-out/k8-opt/genfiles/TaskReconstructionData.py bazel-out/k8-opt/genfiles/TaskTableData.py bazel-out/k8-opt/genfiles/TaskTableTestAndUpdate.py\n",
            "    + cp -f bazel-out/k8-opt/genfiles/TaskInfo.py /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/\n",
            "    + for f in bazel-out/k8-opt/genfiles/ActorCheckpointIdData.py bazel-out/k8-opt/genfiles/ActorState.py bazel-out/k8-opt/genfiles/ActorTableData.py bazel-out/k8-opt/genfiles/Arg.py bazel-out/k8-opt/genfiles/ClassTableData.py bazel-out/k8-opt/genfiles/ClientTableData.py bazel-out/k8-opt/genfiles/ConfigTableData.py bazel-out/k8-opt/genfiles/CustomSerializerData.py bazel-out/k8-opt/genfiles/DriverTableData.py bazel-out/k8-opt/genfiles/EntryType.py bazel-out/k8-opt/genfiles/ErrorTableData.py bazel-out/k8-opt/genfiles/ErrorType.py bazel-out/k8-opt/genfiles/FunctionTableData.py bazel-out/k8-opt/genfiles/GcsTableEntry.py bazel-out/k8-opt/genfiles/HeartbeatBatchTableData.py bazel-out/k8-opt/genfiles/HeartbeatTableData.py bazel-out/k8-opt/genfiles/Language.py bazel-out/k8-opt/genfiles/ObjectTableData.py bazel-out/k8-opt/genfiles/ProfileEvent.py bazel-out/k8-opt/genfiles/ProfileTableData.py bazel-out/k8-opt/genfiles/RayResource.py bazel-out/k8-opt/genfiles/ResourcePair.py bazel-out/k8-opt/genfiles/SchedulingState.py bazel-out/k8-opt/genfiles/TablePrefix.py bazel-out/k8-opt/genfiles/TablePubsub.py bazel-out/k8-opt/genfiles/TaskInfo.py bazel-out/k8-opt/genfiles/TaskLeaseData.py bazel-out/k8-opt/genfiles/TaskReconstructionData.py bazel-out/k8-opt/genfiles/TaskTableData.py bazel-out/k8-opt/genfiles/TaskTableTestAndUpdate.py\n",
            "    + cp -f bazel-out/k8-opt/genfiles/TaskLeaseData.py /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/\n",
            "    + for f in bazel-out/k8-opt/genfiles/ActorCheckpointIdData.py bazel-out/k8-opt/genfiles/ActorState.py bazel-out/k8-opt/genfiles/ActorTableData.py bazel-out/k8-opt/genfiles/Arg.py bazel-out/k8-opt/genfiles/ClassTableData.py bazel-out/k8-opt/genfiles/ClientTableData.py bazel-out/k8-opt/genfiles/ConfigTableData.py bazel-out/k8-opt/genfiles/CustomSerializerData.py bazel-out/k8-opt/genfiles/DriverTableData.py bazel-out/k8-opt/genfiles/EntryType.py bazel-out/k8-opt/genfiles/ErrorTableData.py bazel-out/k8-opt/genfiles/ErrorType.py bazel-out/k8-opt/genfiles/FunctionTableData.py bazel-out/k8-opt/genfiles/GcsTableEntry.py bazel-out/k8-opt/genfiles/HeartbeatBatchTableData.py bazel-out/k8-opt/genfiles/HeartbeatTableData.py bazel-out/k8-opt/genfiles/Language.py bazel-out/k8-opt/genfiles/ObjectTableData.py bazel-out/k8-opt/genfiles/ProfileEvent.py bazel-out/k8-opt/genfiles/ProfileTableData.py bazel-out/k8-opt/genfiles/RayResource.py bazel-out/k8-opt/genfiles/ResourcePair.py bazel-out/k8-opt/genfiles/SchedulingState.py bazel-out/k8-opt/genfiles/TablePrefix.py bazel-out/k8-opt/genfiles/TablePubsub.py bazel-out/k8-opt/genfiles/TaskInfo.py bazel-out/k8-opt/genfiles/TaskLeaseData.py bazel-out/k8-opt/genfiles/TaskReconstructionData.py bazel-out/k8-opt/genfiles/TaskTableData.py bazel-out/k8-opt/genfiles/TaskTableTestAndUpdate.py\n",
            "    + cp -f bazel-out/k8-opt/genfiles/TaskReconstructionData.py /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/\n",
            "    + for f in bazel-out/k8-opt/genfiles/ActorCheckpointIdData.py bazel-out/k8-opt/genfiles/ActorState.py bazel-out/k8-opt/genfiles/ActorTableData.py bazel-out/k8-opt/genfiles/Arg.py bazel-out/k8-opt/genfiles/ClassTableData.py bazel-out/k8-opt/genfiles/ClientTableData.py bazel-out/k8-opt/genfiles/ConfigTableData.py bazel-out/k8-opt/genfiles/CustomSerializerData.py bazel-out/k8-opt/genfiles/DriverTableData.py bazel-out/k8-opt/genfiles/EntryType.py bazel-out/k8-opt/genfiles/ErrorTableData.py bazel-out/k8-opt/genfiles/ErrorType.py bazel-out/k8-opt/genfiles/FunctionTableData.py bazel-out/k8-opt/genfiles/GcsTableEntry.py bazel-out/k8-opt/genfiles/HeartbeatBatchTableData.py bazel-out/k8-opt/genfiles/HeartbeatTableData.py bazel-out/k8-opt/genfiles/Language.py bazel-out/k8-opt/genfiles/ObjectTableData.py bazel-out/k8-opt/genfiles/ProfileEvent.py bazel-out/k8-opt/genfiles/ProfileTableData.py bazel-out/k8-opt/genfiles/RayResource.py bazel-out/k8-opt/genfiles/ResourcePair.py bazel-out/k8-opt/genfiles/SchedulingState.py bazel-out/k8-opt/genfiles/TablePrefix.py bazel-out/k8-opt/genfiles/TablePubsub.py bazel-out/k8-opt/genfiles/TaskInfo.py bazel-out/k8-opt/genfiles/TaskLeaseData.py bazel-out/k8-opt/genfiles/TaskReconstructionData.py bazel-out/k8-opt/genfiles/TaskTableData.py bazel-out/k8-opt/genfiles/TaskTableTestAndUpdate.py\n",
            "    + cp -f bazel-out/k8-opt/genfiles/TaskTableData.py /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/\n",
            "    + for f in bazel-out/k8-opt/genfiles/ActorCheckpointIdData.py bazel-out/k8-opt/genfiles/ActorState.py bazel-out/k8-opt/genfiles/ActorTableData.py bazel-out/k8-opt/genfiles/Arg.py bazel-out/k8-opt/genfiles/ClassTableData.py bazel-out/k8-opt/genfiles/ClientTableData.py bazel-out/k8-opt/genfiles/ConfigTableData.py bazel-out/k8-opt/genfiles/CustomSerializerData.py bazel-out/k8-opt/genfiles/DriverTableData.py bazel-out/k8-opt/genfiles/EntryType.py bazel-out/k8-opt/genfiles/ErrorTableData.py bazel-out/k8-opt/genfiles/ErrorType.py bazel-out/k8-opt/genfiles/FunctionTableData.py bazel-out/k8-opt/genfiles/GcsTableEntry.py bazel-out/k8-opt/genfiles/HeartbeatBatchTableData.py bazel-out/k8-opt/genfiles/HeartbeatTableData.py bazel-out/k8-opt/genfiles/Language.py bazel-out/k8-opt/genfiles/ObjectTableData.py bazel-out/k8-opt/genfiles/ProfileEvent.py bazel-out/k8-opt/genfiles/ProfileTableData.py bazel-out/k8-opt/genfiles/RayResource.py bazel-out/k8-opt/genfiles/ResourcePair.py bazel-out/k8-opt/genfiles/SchedulingState.py bazel-out/k8-opt/genfiles/TablePrefix.py bazel-out/k8-opt/genfiles/TablePubsub.py bazel-out/k8-opt/genfiles/TaskInfo.py bazel-out/k8-opt/genfiles/TaskLeaseData.py bazel-out/k8-opt/genfiles/TaskReconstructionData.py bazel-out/k8-opt/genfiles/TaskTableData.py bazel-out/k8-opt/genfiles/TaskTableTestAndUpdate.py\n",
            "    + cp -f bazel-out/k8-opt/genfiles/TaskTableTestAndUpdate.py /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/\n",
            "    + mkdir -p /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/ray/protocol/\n",
            "    + for f in bazel-out/k8-opt/genfiles/ray/protocol/DisconnectClient.py bazel-out/k8-opt/genfiles/ray/protocol/FetchOrReconstruct.py bazel-out/k8-opt/genfiles/ray/protocol/ForwardTaskRequest.py bazel-out/k8-opt/genfiles/ray/protocol/FreeObjectsRequest.py bazel-out/k8-opt/genfiles/ray/protocol/GetTaskReply.py bazel-out/k8-opt/genfiles/ray/protocol/MessageType.py bazel-out/k8-opt/genfiles/ray/protocol/NotifyUnblocked.py bazel-out/k8-opt/genfiles/ray/protocol/PushErrorRequest.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterClientReply.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterClientRequest.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterNodeManagerRequest.py bazel-out/k8-opt/genfiles/ray/protocol/ResourceIdSetInfo.py bazel-out/k8-opt/genfiles/ray/protocol/SubmitTaskRequest.py bazel-out/k8-opt/genfiles/ray/protocol/Task.py bazel-out/k8-opt/genfiles/ray/protocol/TaskExecutionSpecification.py bazel-out/k8-opt/genfiles/ray/protocol/WaitReply.py bazel-out/k8-opt/genfiles/ray/protocol/WaitRequest.py\n",
            "    + cp -f bazel-out/k8-opt/genfiles/ray/protocol/DisconnectClient.py /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/ray/protocol/\n",
            "    + for f in bazel-out/k8-opt/genfiles/ray/protocol/DisconnectClient.py bazel-out/k8-opt/genfiles/ray/protocol/FetchOrReconstruct.py bazel-out/k8-opt/genfiles/ray/protocol/ForwardTaskRequest.py bazel-out/k8-opt/genfiles/ray/protocol/FreeObjectsRequest.py bazel-out/k8-opt/genfiles/ray/protocol/GetTaskReply.py bazel-out/k8-opt/genfiles/ray/protocol/MessageType.py bazel-out/k8-opt/genfiles/ray/protocol/NotifyUnblocked.py bazel-out/k8-opt/genfiles/ray/protocol/PushErrorRequest.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterClientReply.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterClientRequest.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterNodeManagerRequest.py bazel-out/k8-opt/genfiles/ray/protocol/ResourceIdSetInfo.py bazel-out/k8-opt/genfiles/ray/protocol/SubmitTaskRequest.py bazel-out/k8-opt/genfiles/ray/protocol/Task.py bazel-out/k8-opt/genfiles/ray/protocol/TaskExecutionSpecification.py bazel-out/k8-opt/genfiles/ray/protocol/WaitReply.py bazel-out/k8-opt/genfiles/ray/protocol/WaitRequest.py\n",
            "    + cp -f bazel-out/k8-opt/genfiles/ray/protocol/FetchOrReconstruct.py /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/ray/protocol/\n",
            "    + for f in bazel-out/k8-opt/genfiles/ray/protocol/DisconnectClient.py bazel-out/k8-opt/genfiles/ray/protocol/FetchOrReconstruct.py bazel-out/k8-opt/genfiles/ray/protocol/ForwardTaskRequest.py bazel-out/k8-opt/genfiles/ray/protocol/FreeObjectsRequest.py bazel-out/k8-opt/genfiles/ray/protocol/GetTaskReply.py bazel-out/k8-opt/genfiles/ray/protocol/MessageType.py bazel-out/k8-opt/genfiles/ray/protocol/NotifyUnblocked.py bazel-out/k8-opt/genfiles/ray/protocol/PushErrorRequest.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterClientReply.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterClientRequest.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterNodeManagerRequest.py bazel-out/k8-opt/genfiles/ray/protocol/ResourceIdSetInfo.py bazel-out/k8-opt/genfiles/ray/protocol/SubmitTaskRequest.py bazel-out/k8-opt/genfiles/ray/protocol/Task.py bazel-out/k8-opt/genfiles/ray/protocol/TaskExecutionSpecification.py bazel-out/k8-opt/genfiles/ray/protocol/WaitReply.py bazel-out/k8-opt/genfiles/ray/protocol/WaitRequest.py\n",
            "    + cp -f bazel-out/k8-opt/genfiles/ray/protocol/ForwardTaskRequest.py /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/ray/protocol/\n",
            "    + for f in bazel-out/k8-opt/genfiles/ray/protocol/DisconnectClient.py bazel-out/k8-opt/genfiles/ray/protocol/FetchOrReconstruct.py bazel-out/k8-opt/genfiles/ray/protocol/ForwardTaskRequest.py bazel-out/k8-opt/genfiles/ray/protocol/FreeObjectsRequest.py bazel-out/k8-opt/genfiles/ray/protocol/GetTaskReply.py bazel-out/k8-opt/genfiles/ray/protocol/MessageType.py bazel-out/k8-opt/genfiles/ray/protocol/NotifyUnblocked.py bazel-out/k8-opt/genfiles/ray/protocol/PushErrorRequest.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterClientReply.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterClientRequest.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterNodeManagerRequest.py bazel-out/k8-opt/genfiles/ray/protocol/ResourceIdSetInfo.py bazel-out/k8-opt/genfiles/ray/protocol/SubmitTaskRequest.py bazel-out/k8-opt/genfiles/ray/protocol/Task.py bazel-out/k8-opt/genfiles/ray/protocol/TaskExecutionSpecification.py bazel-out/k8-opt/genfiles/ray/protocol/WaitReply.py bazel-out/k8-opt/genfiles/ray/protocol/WaitRequest.py\n",
            "    + cp -f bazel-out/k8-opt/genfiles/ray/protocol/FreeObjectsRequest.py /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/ray/protocol/\n",
            "    + for f in bazel-out/k8-opt/genfiles/ray/protocol/DisconnectClient.py bazel-out/k8-opt/genfiles/ray/protocol/FetchOrReconstruct.py bazel-out/k8-opt/genfiles/ray/protocol/ForwardTaskRequest.py bazel-out/k8-opt/genfiles/ray/protocol/FreeObjectsRequest.py bazel-out/k8-opt/genfiles/ray/protocol/GetTaskReply.py bazel-out/k8-opt/genfiles/ray/protocol/MessageType.py bazel-out/k8-opt/genfiles/ray/protocol/NotifyUnblocked.py bazel-out/k8-opt/genfiles/ray/protocol/PushErrorRequest.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterClientReply.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterClientRequest.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterNodeManagerRequest.py bazel-out/k8-opt/genfiles/ray/protocol/ResourceIdSetInfo.py bazel-out/k8-opt/genfiles/ray/protocol/SubmitTaskRequest.py bazel-out/k8-opt/genfiles/ray/protocol/Task.py bazel-out/k8-opt/genfiles/ray/protocol/TaskExecutionSpecification.py bazel-out/k8-opt/genfiles/ray/protocol/WaitReply.py bazel-out/k8-opt/genfiles/ray/protocol/WaitRequest.py\n",
            "    + cp -f bazel-out/k8-opt/genfiles/ray/protocol/GetTaskReply.py /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/ray/protocol/\n",
            "    + for f in bazel-out/k8-opt/genfiles/ray/protocol/DisconnectClient.py bazel-out/k8-opt/genfiles/ray/protocol/FetchOrReconstruct.py bazel-out/k8-opt/genfiles/ray/protocol/ForwardTaskRequest.py bazel-out/k8-opt/genfiles/ray/protocol/FreeObjectsRequest.py bazel-out/k8-opt/genfiles/ray/protocol/GetTaskReply.py bazel-out/k8-opt/genfiles/ray/protocol/MessageType.py bazel-out/k8-opt/genfiles/ray/protocol/NotifyUnblocked.py bazel-out/k8-opt/genfiles/ray/protocol/PushErrorRequest.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterClientReply.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterClientRequest.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterNodeManagerRequest.py bazel-out/k8-opt/genfiles/ray/protocol/ResourceIdSetInfo.py bazel-out/k8-opt/genfiles/ray/protocol/SubmitTaskRequest.py bazel-out/k8-opt/genfiles/ray/protocol/Task.py bazel-out/k8-opt/genfiles/ray/protocol/TaskExecutionSpecification.py bazel-out/k8-opt/genfiles/ray/protocol/WaitReply.py bazel-out/k8-opt/genfiles/ray/protocol/WaitRequest.py\n",
            "    + cp -f bazel-out/k8-opt/genfiles/ray/protocol/MessageType.py /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/ray/protocol/\n",
            "    + for f in bazel-out/k8-opt/genfiles/ray/protocol/DisconnectClient.py bazel-out/k8-opt/genfiles/ray/protocol/FetchOrReconstruct.py bazel-out/k8-opt/genfiles/ray/protocol/ForwardTaskRequest.py bazel-out/k8-opt/genfiles/ray/protocol/FreeObjectsRequest.py bazel-out/k8-opt/genfiles/ray/protocol/GetTaskReply.py bazel-out/k8-opt/genfiles/ray/protocol/MessageType.py bazel-out/k8-opt/genfiles/ray/protocol/NotifyUnblocked.py bazel-out/k8-opt/genfiles/ray/protocol/PushErrorRequest.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterClientReply.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterClientRequest.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterNodeManagerRequest.py bazel-out/k8-opt/genfiles/ray/protocol/ResourceIdSetInfo.py bazel-out/k8-opt/genfiles/ray/protocol/SubmitTaskRequest.py bazel-out/k8-opt/genfiles/ray/protocol/Task.py bazel-out/k8-opt/genfiles/ray/protocol/TaskExecutionSpecification.py bazel-out/k8-opt/genfiles/ray/protocol/WaitReply.py bazel-out/k8-opt/genfiles/ray/protocol/WaitRequest.py\n",
            "    + cp -f bazel-out/k8-opt/genfiles/ray/protocol/NotifyUnblocked.py /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/ray/protocol/\n",
            "    + for f in bazel-out/k8-opt/genfiles/ray/protocol/DisconnectClient.py bazel-out/k8-opt/genfiles/ray/protocol/FetchOrReconstruct.py bazel-out/k8-opt/genfiles/ray/protocol/ForwardTaskRequest.py bazel-out/k8-opt/genfiles/ray/protocol/FreeObjectsRequest.py bazel-out/k8-opt/genfiles/ray/protocol/GetTaskReply.py bazel-out/k8-opt/genfiles/ray/protocol/MessageType.py bazel-out/k8-opt/genfiles/ray/protocol/NotifyUnblocked.py bazel-out/k8-opt/genfiles/ray/protocol/PushErrorRequest.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterClientReply.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterClientRequest.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterNodeManagerRequest.py bazel-out/k8-opt/genfiles/ray/protocol/ResourceIdSetInfo.py bazel-out/k8-opt/genfiles/ray/protocol/SubmitTaskRequest.py bazel-out/k8-opt/genfiles/ray/protocol/Task.py bazel-out/k8-opt/genfiles/ray/protocol/TaskExecutionSpecification.py bazel-out/k8-opt/genfiles/ray/protocol/WaitReply.py bazel-out/k8-opt/genfiles/ray/protocol/WaitRequest.py\n",
            "    + cp -f bazel-out/k8-opt/genfiles/ray/protocol/PushErrorRequest.py /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/ray/protocol/\n",
            "    + for f in bazel-out/k8-opt/genfiles/ray/protocol/DisconnectClient.py bazel-out/k8-opt/genfiles/ray/protocol/FetchOrReconstruct.py bazel-out/k8-opt/genfiles/ray/protocol/ForwardTaskRequest.py bazel-out/k8-opt/genfiles/ray/protocol/FreeObjectsRequest.py bazel-out/k8-opt/genfiles/ray/protocol/GetTaskReply.py bazel-out/k8-opt/genfiles/ray/protocol/MessageType.py bazel-out/k8-opt/genfiles/ray/protocol/NotifyUnblocked.py bazel-out/k8-opt/genfiles/ray/protocol/PushErrorRequest.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterClientReply.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterClientRequest.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterNodeManagerRequest.py bazel-out/k8-opt/genfiles/ray/protocol/ResourceIdSetInfo.py bazel-out/k8-opt/genfiles/ray/protocol/SubmitTaskRequest.py bazel-out/k8-opt/genfiles/ray/protocol/Task.py bazel-out/k8-opt/genfiles/ray/protocol/TaskExecutionSpecification.py bazel-out/k8-opt/genfiles/ray/protocol/WaitReply.py bazel-out/k8-opt/genfiles/ray/protocol/WaitRequest.py\n",
            "    + cp -f bazel-out/k8-opt/genfiles/ray/protocol/RegisterClientReply.py /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/ray/protocol/\n",
            "    + for f in bazel-out/k8-opt/genfiles/ray/protocol/DisconnectClient.py bazel-out/k8-opt/genfiles/ray/protocol/FetchOrReconstruct.py bazel-out/k8-opt/genfiles/ray/protocol/ForwardTaskRequest.py bazel-out/k8-opt/genfiles/ray/protocol/FreeObjectsRequest.py bazel-out/k8-opt/genfiles/ray/protocol/GetTaskReply.py bazel-out/k8-opt/genfiles/ray/protocol/MessageType.py bazel-out/k8-opt/genfiles/ray/protocol/NotifyUnblocked.py bazel-out/k8-opt/genfiles/ray/protocol/PushErrorRequest.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterClientReply.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterClientRequest.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterNodeManagerRequest.py bazel-out/k8-opt/genfiles/ray/protocol/ResourceIdSetInfo.py bazel-out/k8-opt/genfiles/ray/protocol/SubmitTaskRequest.py bazel-out/k8-opt/genfiles/ray/protocol/Task.py bazel-out/k8-opt/genfiles/ray/protocol/TaskExecutionSpecification.py bazel-out/k8-opt/genfiles/ray/protocol/WaitReply.py bazel-out/k8-opt/genfiles/ray/protocol/WaitRequest.py\n",
            "    + cp -f bazel-out/k8-opt/genfiles/ray/protocol/RegisterClientRequest.py /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/ray/protocol/\n",
            "    + for f in bazel-out/k8-opt/genfiles/ray/protocol/DisconnectClient.py bazel-out/k8-opt/genfiles/ray/protocol/FetchOrReconstruct.py bazel-out/k8-opt/genfiles/ray/protocol/ForwardTaskRequest.py bazel-out/k8-opt/genfiles/ray/protocol/FreeObjectsRequest.py bazel-out/k8-opt/genfiles/ray/protocol/GetTaskReply.py bazel-out/k8-opt/genfiles/ray/protocol/MessageType.py bazel-out/k8-opt/genfiles/ray/protocol/NotifyUnblocked.py bazel-out/k8-opt/genfiles/ray/protocol/PushErrorRequest.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterClientReply.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterClientRequest.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterNodeManagerRequest.py bazel-out/k8-opt/genfiles/ray/protocol/ResourceIdSetInfo.py bazel-out/k8-opt/genfiles/ray/protocol/SubmitTaskRequest.py bazel-out/k8-opt/genfiles/ray/protocol/Task.py bazel-out/k8-opt/genfiles/ray/protocol/TaskExecutionSpecification.py bazel-out/k8-opt/genfiles/ray/protocol/WaitReply.py bazel-out/k8-opt/genfiles/ray/protocol/WaitRequest.py\n",
            "    + cp -f bazel-out/k8-opt/genfiles/ray/protocol/RegisterNodeManagerRequest.py /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/ray/protocol/\n",
            "    + for f in bazel-out/k8-opt/genfiles/ray/protocol/DisconnectClient.py bazel-out/k8-opt/genfiles/ray/protocol/FetchOrReconstruct.py bazel-out/k8-opt/genfiles/ray/protocol/ForwardTaskRequest.py bazel-out/k8-opt/genfiles/ray/protocol/FreeObjectsRequest.py bazel-out/k8-opt/genfiles/ray/protocol/GetTaskReply.py bazel-out/k8-opt/genfiles/ray/protocol/MessageType.py bazel-out/k8-opt/genfiles/ray/protocol/NotifyUnblocked.py bazel-out/k8-opt/genfiles/ray/protocol/PushErrorRequest.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterClientReply.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterClientRequest.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterNodeManagerRequest.py bazel-out/k8-opt/genfiles/ray/protocol/ResourceIdSetInfo.py bazel-out/k8-opt/genfiles/ray/protocol/SubmitTaskRequest.py bazel-out/k8-opt/genfiles/ray/protocol/Task.py bazel-out/k8-opt/genfiles/ray/protocol/TaskExecutionSpecification.py bazel-out/k8-opt/genfiles/ray/protocol/WaitReply.py bazel-out/k8-opt/genfiles/ray/protocol/WaitRequest.py\n",
            "    + cp -f bazel-out/k8-opt/genfiles/ray/protocol/ResourceIdSetInfo.py /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/ray/protocol/\n",
            "    + for f in bazel-out/k8-opt/genfiles/ray/protocol/DisconnectClient.py bazel-out/k8-opt/genfiles/ray/protocol/FetchOrReconstruct.py bazel-out/k8-opt/genfiles/ray/protocol/ForwardTaskRequest.py bazel-out/k8-opt/genfiles/ray/protocol/FreeObjectsRequest.py bazel-out/k8-opt/genfiles/ray/protocol/GetTaskReply.py bazel-out/k8-opt/genfiles/ray/protocol/MessageType.py bazel-out/k8-opt/genfiles/ray/protocol/NotifyUnblocked.py bazel-out/k8-opt/genfiles/ray/protocol/PushErrorRequest.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterClientReply.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterClientRequest.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterNodeManagerRequest.py bazel-out/k8-opt/genfiles/ray/protocol/ResourceIdSetInfo.py bazel-out/k8-opt/genfiles/ray/protocol/SubmitTaskRequest.py bazel-out/k8-opt/genfiles/ray/protocol/Task.py bazel-out/k8-opt/genfiles/ray/protocol/TaskExecutionSpecification.py bazel-out/k8-opt/genfiles/ray/protocol/WaitReply.py bazel-out/k8-opt/genfiles/ray/protocol/WaitRequest.py\n",
            "    + cp -f bazel-out/k8-opt/genfiles/ray/protocol/SubmitTaskRequest.py /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/ray/protocol/\n",
            "    + for f in bazel-out/k8-opt/genfiles/ray/protocol/DisconnectClient.py bazel-out/k8-opt/genfiles/ray/protocol/FetchOrReconstruct.py bazel-out/k8-opt/genfiles/ray/protocol/ForwardTaskRequest.py bazel-out/k8-opt/genfiles/ray/protocol/FreeObjectsRequest.py bazel-out/k8-opt/genfiles/ray/protocol/GetTaskReply.py bazel-out/k8-opt/genfiles/ray/protocol/MessageType.py bazel-out/k8-opt/genfiles/ray/protocol/NotifyUnblocked.py bazel-out/k8-opt/genfiles/ray/protocol/PushErrorRequest.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterClientReply.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterClientRequest.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterNodeManagerRequest.py bazel-out/k8-opt/genfiles/ray/protocol/ResourceIdSetInfo.py bazel-out/k8-opt/genfiles/ray/protocol/SubmitTaskRequest.py bazel-out/k8-opt/genfiles/ray/protocol/Task.py bazel-out/k8-opt/genfiles/ray/protocol/TaskExecutionSpecification.py bazel-out/k8-opt/genfiles/ray/protocol/WaitReply.py bazel-out/k8-opt/genfiles/ray/protocol/WaitRequest.py\n",
            "    + cp -f bazel-out/k8-opt/genfiles/ray/protocol/Task.py /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/ray/protocol/\n",
            "    + for f in bazel-out/k8-opt/genfiles/ray/protocol/DisconnectClient.py bazel-out/k8-opt/genfiles/ray/protocol/FetchOrReconstruct.py bazel-out/k8-opt/genfiles/ray/protocol/ForwardTaskRequest.py bazel-out/k8-opt/genfiles/ray/protocol/FreeObjectsRequest.py bazel-out/k8-opt/genfiles/ray/protocol/GetTaskReply.py bazel-out/k8-opt/genfiles/ray/protocol/MessageType.py bazel-out/k8-opt/genfiles/ray/protocol/NotifyUnblocked.py bazel-out/k8-opt/genfiles/ray/protocol/PushErrorRequest.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterClientReply.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterClientRequest.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterNodeManagerRequest.py bazel-out/k8-opt/genfiles/ray/protocol/ResourceIdSetInfo.py bazel-out/k8-opt/genfiles/ray/protocol/SubmitTaskRequest.py bazel-out/k8-opt/genfiles/ray/protocol/Task.py bazel-out/k8-opt/genfiles/ray/protocol/TaskExecutionSpecification.py bazel-out/k8-opt/genfiles/ray/protocol/WaitReply.py bazel-out/k8-opt/genfiles/ray/protocol/WaitRequest.py\n",
            "    + cp -f bazel-out/k8-opt/genfiles/ray/protocol/TaskExecutionSpecification.py /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/ray/protocol/\n",
            "    + for f in bazel-out/k8-opt/genfiles/ray/protocol/DisconnectClient.py bazel-out/k8-opt/genfiles/ray/protocol/FetchOrReconstruct.py bazel-out/k8-opt/genfiles/ray/protocol/ForwardTaskRequest.py bazel-out/k8-opt/genfiles/ray/protocol/FreeObjectsRequest.py bazel-out/k8-opt/genfiles/ray/protocol/GetTaskReply.py bazel-out/k8-opt/genfiles/ray/protocol/MessageType.py bazel-out/k8-opt/genfiles/ray/protocol/NotifyUnblocked.py bazel-out/k8-opt/genfiles/ray/protocol/PushErrorRequest.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterClientReply.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterClientRequest.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterNodeManagerRequest.py bazel-out/k8-opt/genfiles/ray/protocol/ResourceIdSetInfo.py bazel-out/k8-opt/genfiles/ray/protocol/SubmitTaskRequest.py bazel-out/k8-opt/genfiles/ray/protocol/Task.py bazel-out/k8-opt/genfiles/ray/protocol/TaskExecutionSpecification.py bazel-out/k8-opt/genfiles/ray/protocol/WaitReply.py bazel-out/k8-opt/genfiles/ray/protocol/WaitRequest.py\n",
            "    + cp -f bazel-out/k8-opt/genfiles/ray/protocol/WaitReply.py /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/ray/protocol/\n",
            "    + for f in bazel-out/k8-opt/genfiles/ray/protocol/DisconnectClient.py bazel-out/k8-opt/genfiles/ray/protocol/FetchOrReconstruct.py bazel-out/k8-opt/genfiles/ray/protocol/ForwardTaskRequest.py bazel-out/k8-opt/genfiles/ray/protocol/FreeObjectsRequest.py bazel-out/k8-opt/genfiles/ray/protocol/GetTaskReply.py bazel-out/k8-opt/genfiles/ray/protocol/MessageType.py bazel-out/k8-opt/genfiles/ray/protocol/NotifyUnblocked.py bazel-out/k8-opt/genfiles/ray/protocol/PushErrorRequest.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterClientReply.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterClientRequest.py bazel-out/k8-opt/genfiles/ray/protocol/RegisterNodeManagerRequest.py bazel-out/k8-opt/genfiles/ray/protocol/ResourceIdSetInfo.py bazel-out/k8-opt/genfiles/ray/protocol/SubmitTaskRequest.py bazel-out/k8-opt/genfiles/ray/protocol/Task.py bazel-out/k8-opt/genfiles/ray/protocol/TaskExecutionSpecification.py bazel-out/k8-opt/genfiles/ray/protocol/WaitReply.py bazel-out/k8-opt/genfiles/ray/protocol/WaitRequest.py\n",
            "    + cp -f bazel-out/k8-opt/genfiles/ray/protocol/WaitRequest.py /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray/python/ray/core/generated/ray/protocol/\n",
            "    + echo /root/.cache/bazel/_bazel_root/5ce3da532461beae7d59c38466ab6e2a/execroot/com_github_ray_project_ray\n",
            "    Target //:ray_pkg up-to-date:\n",
            "      bazel-genfiles/ray_pkg.out\n",
            "    INFO: Elapsed time: 636.443s, Critical Path: 114.37s\n",
            "    INFO: 566 processes: 1 local, 565 processwrapper-sandbox.\n",
            "    INFO: Build completed successfully, 648 total actions\n",
            "    INFO: Build completed successfully, 648 total actions\n",
            "    + popd\n",
            "    /content/ray-distr/python\n",
            "    Copying ray/core/src/ray/thirdparty/redis/src/redis-server to build/lib/ray/core/src/ray/thirdparty/redis/src/redis-server.\n",
            "    Copying ray/core/src/ray/gcs/redis_module/libray_redis_module.so to build/lib/ray/core/src/ray/gcs/redis_module/libray_redis_module.so.\n",
            "    Copying ray/core/src/plasma/plasma_store_server to build/lib/ray/core/src/plasma/plasma_store_server.\n",
            "    Copying ray/_raylet.so to build/lib/ray/_raylet.so.\n",
            "    Copying ray/core/src/ray/raylet/raylet_monitor to build/lib/ray/core/src/ray/raylet/raylet_monitor.\n",
            "    Copying ray/core/src/ray/raylet/raylet to build/lib/ray/core/src/ray/raylet/raylet.\n",
            "    Copying ray/dashboard/dashboard.py to build/lib/ray/dashboard/dashboard.py.\n",
            "    Copying ray/dashboard/index.html to build/lib/ray/dashboard/index.html.\n",
            "    Copying ray/dashboard/res/main.css to build/lib/ray/dashboard/res/main.css.\n",
            "    Copying ray/dashboard/res/main.js to build/lib/ray/dashboard/res/main.js.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/hdfs.py to build/lib/./ray/pyarrow_files/pyarrow/hdfs.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/_csv.pyx to build/lib/./ray/pyarrow_files/pyarrow/_csv.pyx.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/builder.pxi to build/lib/./ray/pyarrow_files/pyarrow/builder.pxi.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/serialization.pxi to build/lib/./ray/pyarrow_files/pyarrow/serialization.pxi.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/_orc.cpython-36m-x86_64-linux-gnu.so to build/lib/./ray/pyarrow_files/pyarrow/_orc.cpython-36m-x86_64-linux-gnu.so.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/feather.py to build/lib/./ray/pyarrow_files/pyarrow/feather.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/libarrow_python.so to build/lib/./ray/pyarrow_files/pyarrow/libarrow_python.so.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/_plasma.cpython-36m-x86_64-linux-gnu.so to build/lib/./ray/pyarrow_files/pyarrow/_plasma.cpython-36m-x86_64-linux-gnu.so.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/benchmark.pxi to build/lib/./ray/pyarrow_files/pyarrow/benchmark.pxi.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/libarrow_python.so.13 to build/lib/./ray/pyarrow_files/pyarrow/libarrow_python.so.13.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/ipc.pxi to build/lib/./ray/pyarrow_files/pyarrow/ipc.pxi.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/_csv.cpython-36m-x86_64-linux-gnu.so to build/lib/./ray/pyarrow_files/pyarrow/_csv.cpython-36m-x86_64-linux-gnu.so.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/plasma_store_server to build/lib/./ray/pyarrow_files/pyarrow/plasma_store_server.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/filesystem.py to build/lib/./ray/pyarrow_files/pyarrow/filesystem.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/pandas_compat.py to build/lib/./ray/pyarrow_files/pyarrow/pandas_compat.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/lib.pxd to build/lib/./ray/pyarrow_files/pyarrow/lib.pxd.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/io-hdfs.pxi to build/lib/./ray/pyarrow_files/pyarrow/io-hdfs.pxi.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/_parquet.cpython-36m-x86_64-linux-gnu.so to build/lib/./ray/pyarrow_files/pyarrow/_parquet.cpython-36m-x86_64-linux-gnu.so.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/flight.py to build/lib/./ray/pyarrow_files/pyarrow/flight.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/parquet.py to build/lib/./ray/pyarrow_files/pyarrow/parquet.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/_plasma.pyx to build/lib/./ray/pyarrow_files/pyarrow/_plasma.pyx.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/_parquet.cpp to build/lib/./ray/pyarrow_files/pyarrow/_parquet.cpp.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/util.py to build/lib/./ray/pyarrow_files/pyarrow/util.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/libarrow_boost_regex.so to build/lib/./ray/pyarrow_files/pyarrow/libarrow_boost_regex.so.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/memory.pxi to build/lib/./ray/pyarrow_files/pyarrow/memory.pxi.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/error.pxi to build/lib/./ray/pyarrow_files/pyarrow/error.pxi.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/types.py to build/lib/./ray/pyarrow_files/pyarrow/types.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/libparquet.so to build/lib/./ray/pyarrow_files/pyarrow/libparquet.so.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/feather.pxi to build/lib/./ray/pyarrow_files/pyarrow/feather.pxi.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/io.pxi to build/lib/./ray/pyarrow_files/pyarrow/io.pxi.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/libplasma.so.13 to build/lib/./ray/pyarrow_files/pyarrow/libplasma.so.13.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/gandiva.pyx to build/lib/./ray/pyarrow_files/pyarrow/gandiva.pyx.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/_csv.cpp to build/lib/./ray/pyarrow_files/pyarrow/_csv.cpp.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/lib_api.h to build/lib/./ray/pyarrow_files/pyarrow/lib_api.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/lib.pyx to build/lib/./ray/pyarrow_files/pyarrow/lib.pyx.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/libarrow_boost_filesystem.so to build/lib/./ray/pyarrow_files/pyarrow/libarrow_boost_filesystem.so.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/libarrow_boost_system.so.1.66.0 to build/lib/./ray/pyarrow_files/pyarrow/libarrow_boost_system.so.1.66.0.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/_plasma.cpp to build/lib/./ray/pyarrow_files/pyarrow/_plasma.cpp.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/libarrow_boost_filesystem.so.1.66.0 to build/lib/./ray/pyarrow_files/pyarrow/libarrow_boost_filesystem.so.1.66.0.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/csv.py to build/lib/./ray/pyarrow_files/pyarrow/csv.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/compat.py to build/lib/./ray/pyarrow_files/pyarrow/compat.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/serialization.py to build/lib/./ray/pyarrow_files/pyarrow/serialization.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/libarrow_boost_system.so to build/lib/./ray/pyarrow_files/pyarrow/libarrow_boost_system.so.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/scalar.pxi to build/lib/./ray/pyarrow_files/pyarrow/scalar.pxi.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/libgandiva.so.13 to build/lib/./ray/pyarrow_files/pyarrow/libgandiva.so.13.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/_orc.pyx to build/lib/./ray/pyarrow_files/pyarrow/_orc.pyx.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/orc.py to build/lib/./ray/pyarrow_files/pyarrow/orc.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/pandas-shim.pxi to build/lib/./ray/pyarrow_files/pyarrow/pandas-shim.pxi.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/_cuda.pxd to build/lib/./ray/pyarrow_files/pyarrow/_cuda.pxd.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/lib.cpython-36m-x86_64-linux-gnu.so to build/lib/./ray/pyarrow_files/pyarrow/lib.cpython-36m-x86_64-linux-gnu.so.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/libarrow_boost_regex.so.1.66.0 to build/lib/./ray/pyarrow_files/pyarrow/libarrow_boost_regex.so.1.66.0.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/libplasma.so to build/lib/./ray/pyarrow_files/pyarrow/libplasma.so.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/__init__.pxd to build/lib/./ray/pyarrow_files/pyarrow/__init__.pxd.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/libgandiva.so to build/lib/./ray/pyarrow_files/pyarrow/libgandiva.so.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/_parquet.pxd to build/lib/./ray/pyarrow_files/pyarrow/_parquet.pxd.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/cuda.py to build/lib/./ray/pyarrow_files/pyarrow/cuda.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/plasma.py to build/lib/./ray/pyarrow_files/pyarrow/plasma.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/libarrow.so.13 to build/lib/./ray/pyarrow_files/pyarrow/libarrow.so.13.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/benchmark.py to build/lib/./ray/pyarrow_files/pyarrow/benchmark.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/_flight.pyx to build/lib/./ray/pyarrow_files/pyarrow/_flight.pyx.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/gandiva.cpp to build/lib/./ray/pyarrow_files/pyarrow/gandiva.cpp.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/lib.cpp to build/lib/./ray/pyarrow_files/pyarrow/lib.cpp.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/_cuda.pyx to build/lib/./ray/pyarrow_files/pyarrow/_cuda.pyx.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/public-api.pxi to build/lib/./ray/pyarrow_files/pyarrow/public-api.pxi.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/table.pxi to build/lib/./ray/pyarrow_files/pyarrow/table.pxi.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/_orc.cpp to build/lib/./ray/pyarrow_files/pyarrow/_orc.cpp.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/ipc.py to build/lib/./ray/pyarrow_files/pyarrow/ipc.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/_generated_version.py to build/lib/./ray/pyarrow_files/pyarrow/_generated_version.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/libarrow.so to build/lib/./ray/pyarrow_files/pyarrow/libarrow.so.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/_parquet.pyx to build/lib/./ray/pyarrow_files/pyarrow/_parquet.pyx.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/jvm.py to build/lib/./ray/pyarrow_files/pyarrow/jvm.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/_orc.pxd to build/lib/./ray/pyarrow_files/pyarrow/_orc.pxd.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/types.pxi to build/lib/./ray/pyarrow_files/pyarrow/types.pxi.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/libparquet.so.13 to build/lib/./ray/pyarrow_files/pyarrow/libparquet.so.13.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/__init__.py to build/lib/./ray/pyarrow_files/pyarrow/__init__.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/array.pxi to build/lib/./ray/pyarrow_files/pyarrow/array.pxi.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/gandiva.cpython-36m-x86_64-linux-gnu.so to build/lib/./ray/pyarrow_files/pyarrow/gandiva.cpython-36m-x86_64-linux-gnu.so.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/test_plasma_tf_op.py to build/lib/./ray/pyarrow_files/pyarrow/tests/test_plasma_tf_op.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/test_serialization.py to build/lib/./ray/pyarrow_files/pyarrow/tests/test_serialization.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/test_csv.py to build/lib/./ray/pyarrow_files/pyarrow/tests/test_csv.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/test_strategies.py to build/lib/./ray/pyarrow_files/pyarrow/tests/test_strategies.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/test_memory.py to build/lib/./ray/pyarrow_files/pyarrow/tests/test_memory.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/test_plasma.py to build/lib/./ray/pyarrow_files/pyarrow/tests/test_plasma.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/strategies.py to build/lib/./ray/pyarrow_files/pyarrow/tests/strategies.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/test_feather.py to build/lib/./ray/pyarrow_files/pyarrow/tests/test_feather.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/test_filesystem.py to build/lib/./ray/pyarrow_files/pyarrow/tests/test_filesystem.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/test_orc.py to build/lib/./ray/pyarrow_files/pyarrow/tests/test_orc.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/util.py to build/lib/./ray/pyarrow_files/pyarrow/tests/util.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/test_schema.py to build/lib/./ray/pyarrow_files/pyarrow/tests/test_schema.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/test_pandas.py to build/lib/./ray/pyarrow_files/pyarrow/tests/test_pandas.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/test_types.py to build/lib/./ray/pyarrow_files/pyarrow/tests/test_types.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/test_hdfs.py to build/lib/./ray/pyarrow_files/pyarrow/tests/test_hdfs.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/test_table.py to build/lib/./ray/pyarrow_files/pyarrow/tests/test_table.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/test_scalars.py to build/lib/./ray/pyarrow_files/pyarrow/tests/test_scalars.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/test_cython.py to build/lib/./ray/pyarrow_files/pyarrow/tests/test_cython.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/test_tensor.py to build/lib/./ray/pyarrow_files/pyarrow/tests/test_tensor.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/test_gandiva.py to build/lib/./ray/pyarrow_files/pyarrow/tests/test_gandiva.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/conftest.py to build/lib/./ray/pyarrow_files/pyarrow/tests/conftest.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/test_misc.py to build/lib/./ray/pyarrow_files/pyarrow/tests/test_misc.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/test_io.py to build/lib/./ray/pyarrow_files/pyarrow/tests/test_io.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/test_deprecations.py to build/lib/./ray/pyarrow_files/pyarrow/tests/test_deprecations.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/test_cuda_numba_interop.py to build/lib/./ray/pyarrow_files/pyarrow/tests/test_cuda_numba_interop.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/test_cuda.py to build/lib/./ray/pyarrow_files/pyarrow/tests/test_cuda.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/test_builder.py to build/lib/./ray/pyarrow_files/pyarrow/tests/test_builder.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/test_flight.py to build/lib/./ray/pyarrow_files/pyarrow/tests/test_flight.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/test_convert_builtin.py to build/lib/./ray/pyarrow_files/pyarrow/tests/test_convert_builtin.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/pandas_examples.py to build/lib/./ray/pyarrow_files/pyarrow/tests/pandas_examples.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/test_jvm.py to build/lib/./ray/pyarrow_files/pyarrow/tests/test_jvm.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/test_array.py to build/lib/./ray/pyarrow_files/pyarrow/tests/test_array.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/test_ipc.py to build/lib/./ray/pyarrow_files/pyarrow/tests/test_ipc.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/__init__.py to build/lib/./ray/pyarrow_files/pyarrow/tests/__init__.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/pyarrow_cython_example.pyx to build/lib/./ray/pyarrow_files/pyarrow/tests/pyarrow_cython_example.pyx.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/test_parquet.py to build/lib/./ray/pyarrow_files/pyarrow/tests/test_parquet.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/deserialize_buffer.py to build/lib/./ray/pyarrow_files/pyarrow/tests/deserialize_buffer.py.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/data/parquet/v0.7.1.some-named-index.parquet to build/lib/./ray/pyarrow_files/pyarrow/tests/data/parquet/v0.7.1.some-named-index.parquet.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/data/parquet/v0.7.1.column-metadata-handling.parquet to build/lib/./ray/pyarrow_files/pyarrow/tests/data/parquet/v0.7.1.column-metadata-handling.parquet.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/data/parquet/v0.7.1.all-named-index.parquet to build/lib/./ray/pyarrow_files/pyarrow/tests/data/parquet/v0.7.1.all-named-index.parquet.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/data/parquet/v0.7.1.parquet to build/lib/./ray/pyarrow_files/pyarrow/tests/data/parquet/v0.7.1.parquet.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/data/orc/decimal.jsn.gz to build/lib/./ray/pyarrow_files/pyarrow/tests/data/orc/decimal.jsn.gz.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/data/orc/TestOrcFile.testDate1900.jsn.gz to build/lib/./ray/pyarrow_files/pyarrow/tests/data/orc/TestOrcFile.testDate1900.jsn.gz.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/data/orc/TestOrcFile.testDate1900.orc to build/lib/./ray/pyarrow_files/pyarrow/tests/data/orc/TestOrcFile.testDate1900.orc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/data/orc/TestOrcFile.test1.jsn.gz to build/lib/./ray/pyarrow_files/pyarrow/tests/data/orc/TestOrcFile.test1.jsn.gz.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/data/orc/TestOrcFile.test1.orc to build/lib/./ray/pyarrow_files/pyarrow/tests/data/orc/TestOrcFile.test1.orc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/data/orc/TestOrcFile.emptyFile.jsn.gz to build/lib/./ray/pyarrow_files/pyarrow/tests/data/orc/TestOrcFile.emptyFile.jsn.gz.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/data/orc/README.md to build/lib/./ray/pyarrow_files/pyarrow/tests/data/orc/README.md.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/data/orc/decimal.orc to build/lib/./ray/pyarrow_files/pyarrow/tests/data/orc/decimal.orc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/data/orc/TestOrcFile.emptyFile.orc to build/lib/./ray/pyarrow_files/pyarrow/tests/data/orc/TestOrcFile.emptyFile.orc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/__pycache__/test_pandas.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/tests/__pycache__/test_pandas.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/__pycache__/strategies.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/tests/__pycache__/strategies.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/__pycache__/test_flight.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/tests/__pycache__/test_flight.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/__pycache__/test_array.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/tests/__pycache__/test_array.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/__pycache__/test_serialization.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/tests/__pycache__/test_serialization.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/__pycache__/test_scalars.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/tests/__pycache__/test_scalars.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/__pycache__/test_io.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/tests/__pycache__/test_io.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/__pycache__/test_filesystem.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/tests/__pycache__/test_filesystem.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/__pycache__/pandas_examples.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/tests/__pycache__/pandas_examples.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/__pycache__/conftest.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/tests/__pycache__/conftest.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/__pycache__/deserialize_buffer.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/tests/__pycache__/deserialize_buffer.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/__pycache__/test_feather.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/tests/__pycache__/test_feather.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/__pycache__/test_schema.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/tests/__pycache__/test_schema.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/__pycache__/test_table.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/tests/__pycache__/test_table.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/__pycache__/test_builder.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/tests/__pycache__/test_builder.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/__pycache__/test_orc.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/tests/__pycache__/test_orc.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/__pycache__/test_cuda_numba_interop.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/tests/__pycache__/test_cuda_numba_interop.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/__pycache__/test_cuda.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/tests/__pycache__/test_cuda.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/__pycache__/test_jvm.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/tests/__pycache__/test_jvm.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/__pycache__/test_memory.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/tests/__pycache__/test_memory.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/__pycache__/test_plasma.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/tests/__pycache__/test_plasma.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/__pycache__/test_hdfs.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/tests/__pycache__/test_hdfs.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/__pycache__/test_cython.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/tests/__pycache__/test_cython.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/__pycache__/test_plasma_tf_op.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/tests/__pycache__/test_plasma_tf_op.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/__pycache__/test_misc.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/tests/__pycache__/test_misc.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/__pycache__/test_convert_builtin.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/tests/__pycache__/test_convert_builtin.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/__pycache__/test_gandiva.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/tests/__pycache__/test_gandiva.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/__pycache__/test_deprecations.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/tests/__pycache__/test_deprecations.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/__pycache__/test_tensor.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/tests/__pycache__/test_tensor.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/__pycache__/test_csv.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/tests/__pycache__/test_csv.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/__pycache__/test_parquet.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/tests/__pycache__/test_parquet.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/__pycache__/test_strategies.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/tests/__pycache__/test_strategies.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/__pycache__/test_ipc.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/tests/__pycache__/test_ipc.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/__pycache__/test_types.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/tests/__pycache__/test_types.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/__pycache__/__init__.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/tests/__pycache__/__init__.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tests/__pycache__/util.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/tests/__pycache__/util.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/includes/libarrow.pxd to build/lib/./ray/pyarrow_files/pyarrow/includes/libarrow.pxd.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/includes/common.pxd to build/lib/./ray/pyarrow_files/pyarrow/includes/common.pxd.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/includes/__init__.pxd to build/lib/./ray/pyarrow_files/pyarrow/includes/__init__.pxd.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/includes/libarrow_cuda.pxd to build/lib/./ray/pyarrow_files/pyarrow/includes/libarrow_cuda.pxd.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/includes/libgandiva.pxd to build/lib/./ray/pyarrow_files/pyarrow/includes/libgandiva.pxd.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/includes/libarrow_flight.pxd to build/lib/./ray/pyarrow_files/pyarrow/includes/libarrow_flight.pxd.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/__pycache__/jvm.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/__pycache__/jvm.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/__pycache__/ipc.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/__pycache__/ipc.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/__pycache__/pandas_compat.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/__pycache__/pandas_compat.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/__pycache__/hdfs.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/__pycache__/hdfs.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/__pycache__/orc.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/__pycache__/orc.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/__pycache__/cuda.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/__pycache__/cuda.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/__pycache__/flight.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/__pycache__/flight.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/__pycache__/types.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/__pycache__/types.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/__pycache__/plasma.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/__pycache__/plasma.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/__pycache__/feather.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/__pycache__/feather.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/__pycache__/csv.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/__pycache__/csv.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/__pycache__/parquet.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/__pycache__/parquet.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/__pycache__/benchmark.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/__pycache__/benchmark.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/__pycache__/serialization.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/__pycache__/serialization.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/__pycache__/_generated_version.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/__pycache__/_generated_version.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/__pycache__/__init__.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/__pycache__/__init__.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/__pycache__/filesystem.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/__pycache__/filesystem.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/__pycache__/compat.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/__pycache__/compat.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/__pycache__/util.cpython-36.pyc to build/lib/./ray/pyarrow_files/pyarrow/__pycache__/util.cpython-36.pyc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/tensorflow/plasma_op.cc to build/lib/./ray/pyarrow_files/pyarrow/tensorflow/plasma_op.cc.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/plasma/compat.h to build/lib/./ray/pyarrow_files/pyarrow/include/plasma/compat.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/plasma/events.h to build/lib/./ray/pyarrow_files/pyarrow/include/plasma/events.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/plasma/client.h to build/lib/./ray/pyarrow_files/pyarrow/include/plasma/client.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/plasma/test-util.h to build/lib/./ray/pyarrow_files/pyarrow/include/plasma/test-util.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/plasma/common.h to build/lib/./ray/pyarrow_files/pyarrow/include/plasma/common.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/function_registry_string.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/function_registry_string.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/decimal_xlarge.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/decimal_xlarge.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/field_descriptor.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/field_descriptor.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/function_registry_hash.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/function_registry_hash.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/decimal_ir.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/decimal_ir.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/visibility.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/visibility.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/dex_visitor.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/dex_visitor.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/function_ir_builder.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/function_ir_builder.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/gandiva_aliases.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/gandiva_aliases.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/compiled_expr.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/compiled_expr.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/function_holder.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/function_holder.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/function_holder_registry.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/function_holder_registry.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/annotator.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/annotator.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/condition.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/condition.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/execution_context.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/execution_context.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/exported_funcs_registry.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/exported_funcs_registry.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/function_registry.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/function_registry.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/in_holder.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/in_holder.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/projector_cache_key.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/projector_cache_key.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/tree_expr_builder.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/tree_expr_builder.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/llvm_generator.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/llvm_generator.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/function_registry_timestamp_arithmetic.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/function_registry_timestamp_arithmetic.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/literal_holder.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/literal_holder.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/local_bitmaps_holder.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/local_bitmaps_holder.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/bitmap_accumulator.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/bitmap_accumulator.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/expr_validator.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/expr_validator.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/date_utils.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/date_utils.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/engine.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/engine.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/expr_decomposer.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/expr_decomposer.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/function_signature.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/function_signature.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/filter_cache_key.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/filter_cache_key.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/llvm_includes.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/llvm_includes.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/expression.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/expression.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/native_function.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/native_function.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/decimal_scalar.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/decimal_scalar.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/filter.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/filter.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/selection_vector.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/selection_vector.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/configuration.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/configuration.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/decimal_type_util.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/decimal_type_util.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/function_registry_arithmetic.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/function_registry_arithmetic.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/func_descriptor.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/func_descriptor.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/expression_registry.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/expression_registry.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/value_validity_pair.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/value_validity_pair.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/function_registry_math_ops.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/function_registry_math_ops.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/dex.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/dex.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/lru_cache.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/lru_cache.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/selection_vector_impl.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/selection_vector_impl.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/lvalue.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/lvalue.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/gdv_function_stubs.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/gdv_function_stubs.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/like_holder.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/like_holder.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/eval_batch.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/eval_batch.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/projector.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/projector.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/node.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/node.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/arrow.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/arrow.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/basic_decimal_scalar.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/basic_decimal_scalar.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/function_registry_common.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/function_registry_common.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/regex_util.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/regex_util.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/cache.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/cache.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/function_registry_datetime.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/function_registry_datetime.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/node_visitor.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/node_visitor.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/logging.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/logging.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/simple_arena.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/simple_arena.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/to_date_holder.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/to_date_holder.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/llvm_types.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/llvm_types.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/gandiva/exported_funcs.h to build/lib/./ray/pyarrow_files/pyarrow/include/gandiva/exported_funcs.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/parquet/properties.h to build/lib/./ray/pyarrow_files/pyarrow/include/parquet/properties.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/parquet/types.h to build/lib/./ray/pyarrow_files/pyarrow/include/parquet/types.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/parquet/file_writer.h to build/lib/./ray/pyarrow_files/pyarrow/include/parquet/file_writer.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/parquet/printer.h to build/lib/./ray/pyarrow_files/pyarrow/include/parquet/printer.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/parquet/file_reader.h to build/lib/./ray/pyarrow_files/pyarrow/include/parquet/file_reader.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/parquet/test-util.h to build/lib/./ray/pyarrow_files/pyarrow/include/parquet/test-util.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/parquet/hasher.h to build/lib/./ray/pyarrow_files/pyarrow/include/parquet/hasher.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/parquet/thrift.h to build/lib/./ray/pyarrow_files/pyarrow/include/parquet/thrift.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/parquet/column_scanner.h to build/lib/./ray/pyarrow_files/pyarrow/include/parquet/column_scanner.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/parquet/schema.h to build/lib/./ray/pyarrow_files/pyarrow/include/parquet/schema.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/parquet/metadata.h to build/lib/./ray/pyarrow_files/pyarrow/include/parquet/metadata.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/parquet/column_reader.h to build/lib/./ray/pyarrow_files/pyarrow/include/parquet/column_reader.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/parquet/column_page.h to build/lib/./ray/pyarrow_files/pyarrow/include/parquet/column_page.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/parquet/murmur3.h to build/lib/./ray/pyarrow_files/pyarrow/include/parquet/murmur3.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/parquet/column_writer.h to build/lib/./ray/pyarrow_files/pyarrow/include/parquet/column_writer.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/parquet/exception.h to build/lib/./ray/pyarrow_files/pyarrow/include/parquet/exception.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/parquet/bloom_filter.h to build/lib/./ray/pyarrow_files/pyarrow/include/parquet/bloom_filter.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/parquet/test-specialization.h to build/lib/./ray/pyarrow_files/pyarrow/include/parquet/test-specialization.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/parquet/parquet_version.h to build/lib/./ray/pyarrow_files/pyarrow/include/parquet/parquet_version.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/parquet/encoding.h to build/lib/./ray/pyarrow_files/pyarrow/include/parquet/encoding.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/parquet/statistics.h to build/lib/./ray/pyarrow_files/pyarrow/include/parquet/statistics.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/parquet/api/reader.h to build/lib/./ray/pyarrow_files/pyarrow/include/parquet/api/reader.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/parquet/api/schema.h to build/lib/./ray/pyarrow_files/pyarrow/include/parquet/api/schema.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/parquet/api/writer.h to build/lib/./ray/pyarrow_files/pyarrow/include/parquet/api/writer.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/parquet/api/io.h to build/lib/./ray/pyarrow_files/pyarrow/include/parquet/api/io.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/parquet/arrow/record_reader.h to build/lib/./ray/pyarrow_files/pyarrow/include/parquet/arrow/record_reader.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/parquet/arrow/reader.h to build/lib/./ray/pyarrow_files/pyarrow/include/parquet/arrow/reader.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/parquet/arrow/test-util.h to build/lib/./ray/pyarrow_files/pyarrow/include/parquet/arrow/test-util.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/parquet/arrow/schema.h to build/lib/./ray/pyarrow_files/pyarrow/include/parquet/arrow/schema.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/parquet/arrow/writer.h to build/lib/./ray/pyarrow_files/pyarrow/include/parquet/arrow/writer.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/parquet/util/comparison.h to build/lib/./ray/pyarrow_files/pyarrow/include/parquet/util/comparison.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/parquet/util/visibility.h to build/lib/./ray/pyarrow_files/pyarrow/include/parquet/util/visibility.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/parquet/util/windows_compatibility.h to build/lib/./ray/pyarrow_files/pyarrow/include/parquet/util/windows_compatibility.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/parquet/util/memory.h to build/lib/./ray/pyarrow_files/pyarrow/include/parquet/util/memory.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/parquet/util/schema-util.h to build/lib/./ray/pyarrow_files/pyarrow/include/parquet/util/schema-util.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/parquet/util/macros.h to build/lib/./ray/pyarrow_files/pyarrow/include/parquet/util/macros.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/parquet/util/test-common.h to build/lib/./ray/pyarrow_files/pyarrow/include/parquet/util/test-common.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/parquet/util/crypto.h to build/lib/./ray/pyarrow_files/pyarrow/include/parquet/util/crypto.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/allocator.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/allocator.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/extension_type.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/extension_type.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/table_builder.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/table_builder.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/scalar.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/scalar.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/status.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/status.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/type_traits.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/type_traits.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/array.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/array.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/visitor_inline.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/visitor_inline.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/pretty_print.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/pretty_print.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/builder.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/builder.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/memory_pool.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/memory_pool.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/visitor.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/visitor.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/buffer-builder.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/buffer-builder.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/compare.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/compare.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/sparse_tensor.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/sparse_tensor.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/table.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/table.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/buffer.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/buffer.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/type_fwd.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/type_fwd.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/memory_pool-test.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/memory_pool-test.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/api.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/api.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/record_batch.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/record_batch.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/type.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/type.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/tensor.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/tensor.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/stl.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/stl.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/adapters/tensorflow/convert.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/adapters/tensorflow/convert.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/adapters/orc/adapter.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/adapters/orc/adapter.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/python/numpy_convert.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/python/numpy_convert.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/python/iterators.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/python/iterators.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/python/pyarrow_lib.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/python/pyarrow_lib.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/python/visibility.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/python/visibility.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/python/numpy_to_arrow.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/python/numpy_to_arrow.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/python/decimal.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/python/decimal.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/python/python_to_arrow.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/python/python_to_arrow.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/python/inference.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/python/inference.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/python/serialize.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/python/serialize.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/python/config.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/python/config.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/python/type_traits.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/python/type_traits.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/python/pyarrow.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/python/pyarrow.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/python/pyarrow_api.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/python/pyarrow_api.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/python/numpy_interop.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/python/numpy_interop.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/python/benchmark.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/python/benchmark.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/python/deserialize.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/python/deserialize.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/python/init.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/python/init.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/python/arrow_to_pandas.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/python/arrow_to_pandas.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/python/helpers.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/python/helpers.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/python/flight.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/python/flight.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/python/api.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/python/api.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/python/platform.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/python/platform.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/python/common.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/python/common.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/python/io.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/python/io.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/compute/context.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/compute/context.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/compute/test-util.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/compute/test-util.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/compute/expression.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/compute/expression.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/compute/logical_type.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/compute/logical_type.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/compute/type_fwd.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/compute/type_fwd.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/compute/kernel.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/compute/kernel.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/compute/operation.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/compute/operation.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/compute/api.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/compute/api.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/compute/kernels/sum.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/compute/kernels/sum.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/compute/kernels/aggregate.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/compute/kernels/aggregate.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/compute/kernels/boolean.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/compute/kernels/boolean.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/compute/kernels/mean.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/compute/kernels/mean.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/compute/kernels/count.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/compute/kernels/count.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/compute/kernels/hash.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/compute/kernels/hash.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/compute/kernels/cast.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/compute/kernels/cast.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/ipc/json-integration.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/ipc/json-integration.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/ipc/dictionary.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/ipc/dictionary.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/ipc/reader.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/ipc/reader.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/ipc/json-simple.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/ipc/json-simple.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/ipc/util.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/ipc/util.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/ipc/writer.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/ipc/writer.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/ipc/test-common.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/ipc/test-common.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/ipc/api.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/ipc/api.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/ipc/feather.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/ipc/feather.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/ipc/message.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/ipc/message.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/json/reader.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/json/reader.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/json/parser.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/json/parser.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/json/test-common.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/json/test-common.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/json/chunker.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/json/chunker.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/json/api.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/json/api.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/json/options.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/json/options.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/array/builder_dict.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/array/builder_dict.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/array/builder_binary.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/array/builder_binary.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/array/builder_decimal.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/array/builder_decimal.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/array/builder_nested.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/array/builder_nested.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/array/builder_union.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/array/builder_union.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/array/builder_primitive.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/array/builder_primitive.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/array/builder_adaptive.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/array/builder_adaptive.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/array/builder_base.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/array/builder_base.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/vendored/datetime.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/vendored/datetime.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/vendored/string_view.hpp to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/vendored/string_view.hpp.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/vendored/variant/recursive_wrapper.hpp to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/vendored/variant/recursive_wrapper.hpp.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/vendored/variant/variant.hpp to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/vendored/variant/variant.hpp.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/vendored/variant/variant_visitor.hpp to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/vendored/variant/variant_visitor.hpp.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/vendored/variant/variant_io.hpp to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/vendored/variant/variant_io.hpp.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/csv/reader.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/csv/reader.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/csv/parser.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/csv/parser.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/csv/converter.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/csv/converter.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/csv/test-common.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/csv/test-common.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/csv/chunker.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/csv/chunker.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/csv/api.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/csv/api.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/csv/column-builder.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/csv/column-builder.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/csv/options.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/csv/options.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/io/compressed.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/io/compressed.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/io/hdfs.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/io/hdfs.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/io/memory.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/io/memory.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/io/buffered.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/io/buffered.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/io/file.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/io/file.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/io/test-common.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/io/test-common.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/io/interfaces.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/io/interfaces.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/io/api.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/io/api.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/io/readahead.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/io/readahead.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/io/mman.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/io/mman.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/util/bit-stream-utils.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/util/bit-stream-utils.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/util/visibility.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/util/visibility.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/util/decimal.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/util/decimal.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/util/windows_compatibility.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/util/windows_compatibility.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/util/memory.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/util/memory.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/util/parsing.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/util/parsing.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/util/compression_zlib.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/util/compression_zlib.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/util/uri.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/util/uri.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/util/string_builder.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/util/string_builder.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/util/compression.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/util/compression.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/util/config.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/util/config.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/util/io-util.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/util/io-util.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/util/stopwatch.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/util/stopwatch.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/util/type_traits.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/util/type_traits.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/util/cpu-info.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/util/cpu-info.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/util/compiler-util.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/util/compiler-util.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/util/basic_decimal.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/util/basic_decimal.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/util/trie.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/util/trie.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/util/utf8.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/util/utf8.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/util/bit-util.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/util/bit-util.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/util/string.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/util/string.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/util/lazy.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/util/lazy.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/util/neon-util.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/util/neon-util.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/util/sse-util.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/util/sse-util.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/util/macros.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/util/macros.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/util/variant.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/util/variant.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/util/string_view.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/util/string_view.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/util/checked_cast.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/util/checked_cast.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/util/task-group.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/util/task-group.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/util/hashing.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/util/hashing.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/util/bpacking.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/util/bpacking.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/util/hash-util.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/util/hash-util.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/util/int-util.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/util/int-util.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/util/compression_zstd.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/util/compression_zstd.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/util/rle-encoding.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/util/rle-encoding.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/util/key_value_metadata.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/util/key_value_metadata.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/util/compression_bz2.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/util/compression_bz2.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/util/concatenate.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/util/concatenate.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/util/parallel.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/util/parallel.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/util/thread-pool.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/util/thread-pool.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/util/compression_lz4.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/util/compression_lz4.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/util/compression_snappy.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/util/compression_snappy.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/util/compression_brotli.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/util/compression_brotli.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/util/logging.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/util/logging.h.\n",
            "    Copying ./ray/pyarrow_files/pyarrow/include/arrow/util/stl.h to build/lib/./ray/pyarrow_files/pyarrow/include/arrow/util/stl.h.\n",
            "    Copying ./ray/modin/modin/error_message.py to build/lib/./ray/modin/modin/error_message.py.\n",
            "    Copying ./ray/modin/modin/__init__.py to build/lib/./ray/modin/modin/__init__.py.\n",
            "    Copying ./ray/modin/modin/pandas/general.py to build/lib/./ray/modin/modin/pandas/general.py.\n",
            "    Copying ./ray/modin/modin/pandas/indexing.py to build/lib/./ray/modin/modin/pandas/indexing.py.\n",
            "    Copying ./ray/modin/modin/pandas/datetimes.py to build/lib/./ray/modin/modin/pandas/datetimes.py.\n",
            "    Copying ./ray/modin/modin/pandas/groupby.py to build/lib/./ray/modin/modin/pandas/groupby.py.\n",
            "    Copying ./ray/modin/modin/pandas/base.py to build/lib/./ray/modin/modin/pandas/base.py.\n",
            "    Copying ./ray/modin/modin/pandas/iterator.py to build/lib/./ray/modin/modin/pandas/iterator.py.\n",
            "    Copying ./ray/modin/modin/pandas/utils.py to build/lib/./ray/modin/modin/pandas/utils.py.\n",
            "    Copying ./ray/modin/modin/pandas/series.py to build/lib/./ray/modin/modin/pandas/series.py.\n",
            "    Copying ./ray/modin/modin/pandas/reshape.py to build/lib/./ray/modin/modin/pandas/reshape.py.\n",
            "    Copying ./ray/modin/modin/pandas/io.py to build/lib/./ray/modin/modin/pandas/io.py.\n",
            "    Copying ./ray/modin/modin/pandas/concat.py to build/lib/./ray/modin/modin/pandas/concat.py.\n",
            "    Copying ./ray/modin/modin/pandas/dataframe.py to build/lib/./ray/modin/modin/pandas/dataframe.py.\n",
            "    Copying ./ray/modin/modin/pandas/plotting.py to build/lib/./ray/modin/modin/pandas/plotting.py.\n",
            "    Copying ./ray/modin/modin/pandas/__init__.py to build/lib/./ray/modin/modin/pandas/__init__.py.\n",
            "    Copying ./ray/modin/modin/pandas/test/test_api.py to build/lib/./ray/modin/modin/pandas/test/test_api.py.\n",
            "    Copying ./ray/modin/modin/pandas/test/test_dataframe.py to build/lib/./ray/modin/modin/pandas/test/test_dataframe.py.\n",
            "    Copying ./ray/modin/modin/pandas/test/utils.py to build/lib/./ray/modin/modin/pandas/test/utils.py.\n",
            "    Copying ./ray/modin/modin/pandas/test/test_io.py to build/lib/./ray/modin/modin/pandas/test/test_io.py.\n",
            "    Copying ./ray/modin/modin/pandas/test/test_groupby.py to build/lib/./ray/modin/modin/pandas/test/test_groupby.py.\n",
            "    Copying ./ray/modin/modin/pandas/test/test_series.py to build/lib/./ray/modin/modin/pandas/test/test_series.py.\n",
            "    Copying ./ray/modin/modin/pandas/test/test_reshape.py to build/lib/./ray/modin/modin/pandas/test/test_reshape.py.\n",
            "    Copying ./ray/modin/modin/pandas/test/test_concat.py to build/lib/./ray/modin/modin/pandas/test/test_concat.py.\n",
            "    Copying ./ray/modin/modin/pandas/test/test_general.py to build/lib/./ray/modin/modin/pandas/test/test_general.py.\n",
            "    Copying ./ray/modin/modin/pandas/test/__init__.py to build/lib/./ray/modin/modin/pandas/test/__init__.py.\n",
            "    Copying ./ray/modin/modin/pandas/index/partitioned_index.py to build/lib/./ray/modin/modin/pandas/index/partitioned_index.py.\n",
            "    Copying ./ray/modin/modin/pandas/index/__init__.py to build/lib/./ray/modin/modin/pandas/index/__init__.py.\n",
            "    Copying ./ray/modin/modin/experimental/__init__.py to build/lib/./ray/modin/modin/experimental/__init__.py.\n",
            "    Copying ./ray/modin/modin/experimental/pandas/io_exp.py to build/lib/./ray/modin/modin/experimental/pandas/io_exp.py.\n",
            "    Copying ./ray/modin/modin/experimental/pandas/__init__.py to build/lib/./ray/modin/modin/experimental/pandas/__init__.py.\n",
            "    Copying ./ray/modin/modin/experimental/engines/__init__.py to build/lib/./ray/modin/modin/experimental/engines/__init__.py.\n",
            "    Copying ./ray/modin/modin/experimental/engines/pandas_on_ray/io_exp.py to build/lib/./ray/modin/modin/experimental/engines/pandas_on_ray/io_exp.py.\n",
            "    Copying ./ray/modin/modin/experimental/engines/pandas_on_ray/sql.py to build/lib/./ray/modin/modin/experimental/engines/pandas_on_ray/sql.py.\n",
            "    Copying ./ray/modin/modin/experimental/engines/pandas_on_ray/__init__.py to build/lib/./ray/modin/modin/experimental/engines/pandas_on_ray/__init__.py.\n",
            "    Copying ./ray/modin/modin/experimental/engines/pyarrow_on_ray/io.py to build/lib/./ray/modin/modin/experimental/engines/pyarrow_on_ray/io.py.\n",
            "    Copying ./ray/modin/modin/experimental/engines/pyarrow_on_ray/__init__.py to build/lib/./ray/modin/modin/experimental/engines/pyarrow_on_ray/__init__.py.\n",
            "    Copying ./ray/modin/modin/experimental/engines/pyarrow_on_ray/series/__init__.py to build/lib/./ray/modin/modin/experimental/engines/pyarrow_on_ray/series/__init__.py.\n",
            "    Copying ./ray/modin/modin/experimental/engines/pyarrow_on_ray/frame/partition.py to build/lib/./ray/modin/modin/experimental/engines/pyarrow_on_ray/frame/partition.py.\n",
            "    Copying ./ray/modin/modin/experimental/engines/pyarrow_on_ray/frame/partition_manager.py to build/lib/./ray/modin/modin/experimental/engines/pyarrow_on_ray/frame/partition_manager.py.\n",
            "    Copying ./ray/modin/modin/experimental/engines/pyarrow_on_ray/frame/axis_partition.py to build/lib/./ray/modin/modin/experimental/engines/pyarrow_on_ray/frame/axis_partition.py.\n",
            "    Copying ./ray/modin/modin/experimental/engines/pyarrow_on_ray/frame/__init__.py to build/lib/./ray/modin/modin/experimental/engines/pyarrow_on_ray/frame/__init__.py.\n",
            "    Copying ./ray/modin/modin/backends/__init__.py to build/lib/./ray/modin/modin/backends/__init__.py.\n",
            "    Copying ./ray/modin/modin/backends/pandas/__init__.py to build/lib/./ray/modin/modin/backends/pandas/__init__.py.\n",
            "    Copying ./ray/modin/modin/backends/pandas/query_compiler.py to build/lib/./ray/modin/modin/backends/pandas/query_compiler.py.\n",
            "    Copying ./ray/modin/modin/backends/pyarrow/__init__.py to build/lib/./ray/modin/modin/backends/pyarrow/__init__.py.\n",
            "    Copying ./ray/modin/modin/backends/pyarrow/query_compiler.py to build/lib/./ray/modin/modin/backends/pyarrow/query_compiler.py.\n",
            "    Copying ./ray/modin/modin/backends/base/__init__.py to build/lib/./ray/modin/modin/backends/base/__init__.py.\n",
            "    Copying ./ray/modin/modin/backends/base/query_compiler.py to build/lib/./ray/modin/modin/backends/base/query_compiler.py.\n",
            "    Copying ./ray/modin/modin/data_management/factories.py to build/lib/./ray/modin/modin/data_management/factories.py.\n",
            "    Copying ./ray/modin/modin/data_management/utils.py to build/lib/./ray/modin/modin/data_management/utils.py.\n",
            "    Copying ./ray/modin/modin/data_management/__init__.py to build/lib/./ray/modin/modin/data_management/__init__.py.\n",
            "    Copying ./ray/modin/modin/sql/connection.py to build/lib/./ray/modin/modin/sql/connection.py.\n",
            "    Copying ./ray/modin/modin/sql/__init__.py to build/lib/./ray/modin/modin/sql/__init__.py.\n",
            "    Copying ./ray/modin/modin/engines/__init__.py to build/lib/./ray/modin/modin/engines/__init__.py.\n",
            "    Copying ./ray/modin/modin/engines/base/io.py to build/lib/./ray/modin/modin/engines/base/io.py.\n",
            "    Copying ./ray/modin/modin/engines/base/__init__.py to build/lib/./ray/modin/modin/engines/base/__init__.py.\n",
            "    Copying ./ray/modin/modin/engines/base/series/__init__.py to build/lib/./ray/modin/modin/engines/base/series/__init__.py.\n",
            "    Copying ./ray/modin/modin/engines/base/frame/partition.py to build/lib/./ray/modin/modin/engines/base/frame/partition.py.\n",
            "    Copying ./ray/modin/modin/engines/base/frame/partition_manager.py to build/lib/./ray/modin/modin/engines/base/frame/partition_manager.py.\n",
            "    Copying ./ray/modin/modin/engines/base/frame/axis_partition.py to build/lib/./ray/modin/modin/engines/base/frame/axis_partition.py.\n",
            "    Copying ./ray/modin/modin/engines/base/frame/__init__.py to build/lib/./ray/modin/modin/engines/base/frame/__init__.py.\n",
            "    Copying ./ray/modin/modin/engines/python/__init__.py to build/lib/./ray/modin/modin/engines/python/__init__.py.\n",
            "    Copying ./ray/modin/modin/engines/python/pandas_on_python/io.py to build/lib/./ray/modin/modin/engines/python/pandas_on_python/io.py.\n",
            "    Copying ./ray/modin/modin/engines/python/pandas_on_python/__init__.py to build/lib/./ray/modin/modin/engines/python/pandas_on_python/__init__.py.\n",
            "    Copying ./ray/modin/modin/engines/python/pandas_on_python/series/__init__.py to build/lib/./ray/modin/modin/engines/python/pandas_on_python/series/__init__.py.\n",
            "    Copying ./ray/modin/modin/engines/python/pandas_on_python/frame/partition.py to build/lib/./ray/modin/modin/engines/python/pandas_on_python/frame/partition.py.\n",
            "    Copying ./ray/modin/modin/engines/python/pandas_on_python/frame/partition_manager.py to build/lib/./ray/modin/modin/engines/python/pandas_on_python/frame/partition_manager.py.\n",
            "    Copying ./ray/modin/modin/engines/python/pandas_on_python/frame/axis_partition.py to build/lib/./ray/modin/modin/engines/python/pandas_on_python/frame/axis_partition.py.\n",
            "    Copying ./ray/modin/modin/engines/python/pandas_on_python/frame/__init__.py to build/lib/./ray/modin/modin/engines/python/pandas_on_python/frame/__init__.py.\n",
            "    Copying ./ray/modin/modin/engines/dask/__init__.py to build/lib/./ray/modin/modin/engines/dask/__init__.py.\n",
            "    Copying ./ray/modin/modin/engines/dask/pandas_on_dask_delayed/io.py to build/lib/./ray/modin/modin/engines/dask/pandas_on_dask_delayed/io.py.\n",
            "    Copying ./ray/modin/modin/engines/dask/pandas_on_dask_delayed/__init__.py to build/lib/./ray/modin/modin/engines/dask/pandas_on_dask_delayed/__init__.py.\n",
            "    Copying ./ray/modin/modin/engines/dask/pandas_on_dask_delayed/series/__init__.py to build/lib/./ray/modin/modin/engines/dask/pandas_on_dask_delayed/series/__init__.py.\n",
            "    Copying ./ray/modin/modin/engines/dask/pandas_on_dask_delayed/frame/partition.py to build/lib/./ray/modin/modin/engines/dask/pandas_on_dask_delayed/frame/partition.py.\n",
            "    Copying ./ray/modin/modin/engines/dask/pandas_on_dask_delayed/frame/partition_manager.py to build/lib/./ray/modin/modin/engines/dask/pandas_on_dask_delayed/frame/partition_manager.py.\n",
            "    Copying ./ray/modin/modin/engines/dask/pandas_on_dask_delayed/frame/axis_partition.py to build/lib/./ray/modin/modin/engines/dask/pandas_on_dask_delayed/frame/axis_partition.py.\n",
            "    Copying ./ray/modin/modin/engines/dask/pandas_on_dask_delayed/frame/__init__.py to build/lib/./ray/modin/modin/engines/dask/pandas_on_dask_delayed/frame/__init__.py.\n",
            "    Copying ./ray/modin/modin/engines/ray/utils.py to build/lib/./ray/modin/modin/engines/ray/utils.py.\n",
            "    Copying ./ray/modin/modin/engines/ray/__init__.py to build/lib/./ray/modin/modin/engines/ray/__init__.py.\n",
            "    Copying ./ray/modin/modin/engines/ray/pandas_on_ray/io.py to build/lib/./ray/modin/modin/engines/ray/pandas_on_ray/io.py.\n",
            "    Copying ./ray/modin/modin/engines/ray/pandas_on_ray/__init__.py to build/lib/./ray/modin/modin/engines/ray/pandas_on_ray/__init__.py.\n",
            "    Copying ./ray/modin/modin/engines/ray/pandas_on_ray/series/__init__.py to build/lib/./ray/modin/modin/engines/ray/pandas_on_ray/series/__init__.py.\n",
            "    Copying ./ray/modin/modin/engines/ray/pandas_on_ray/frame/partition.py to build/lib/./ray/modin/modin/engines/ray/pandas_on_ray/frame/partition.py.\n",
            "    Copying ./ray/modin/modin/engines/ray/pandas_on_ray/frame/partition_manager.py to build/lib/./ray/modin/modin/engines/ray/pandas_on_ray/frame/partition_manager.py.\n",
            "    Copying ./ray/modin/modin/engines/ray/pandas_on_ray/frame/axis_partition.py to build/lib/./ray/modin/modin/engines/ray/pandas_on_ray/frame/axis_partition.py.\n",
            "    Copying ./ray/modin/modin/engines/ray/pandas_on_ray/frame/__init__.py to build/lib/./ray/modin/modin/engines/ray/pandas_on_ray/frame/__init__.py.\n",
            "    Copying ./ray/modin/modin/engines/ray/generic/io.py to build/lib/./ray/modin/modin/engines/ray/generic/io.py.\n",
            "    Copying ./ray/modin/modin/engines/ray/generic/__init__.py to build/lib/./ray/modin/modin/engines/ray/generic/__init__.py.\n",
            "    Copying ./ray/modin/modin/engines/ray/generic/series/__init__.py to build/lib/./ray/modin/modin/engines/ray/generic/series/__init__.py.\n",
            "    Copying ./ray/modin/modin/engines/ray/generic/frame/partition_manager.py to build/lib/./ray/modin/modin/engines/ray/generic/frame/partition_manager.py.\n",
            "    Copying ./ray/modin/modin/engines/ray/generic/frame/__init__.py to build/lib/./ray/modin/modin/engines/ray/generic/frame/__init__.py.\n",
            "    Copying ./ray/modin/modin-0.5.0.dist-info/METADATA to build/lib/./ray/modin/modin-0.5.0.dist-info/METADATA.\n",
            "    Copying ./ray/modin/modin-0.5.0.dist-info/top_level.txt to build/lib/./ray/modin/modin-0.5.0.dist-info/top_level.txt.\n",
            "    Copying ./ray/modin/modin-0.5.0.dist-info/LICENSE to build/lib/./ray/modin/modin-0.5.0.dist-info/LICENSE.\n",
            "    Copying ./ray/modin/modin-0.5.0.dist-info/WHEEL to build/lib/./ray/modin/modin-0.5.0.dist-info/WHEEL.\n",
            "    Copying ./ray/modin/modin-0.5.0.dist-info/RECORD to build/lib/./ray/modin/modin-0.5.0.dist-info/RECORD.\n",
            "    Copying ray/core/generated/SchedulingState.py to build/lib/ray/core/generated/SchedulingState.py.\n",
            "    Copying ray/core/generated/ObjectTableData.py to build/lib/ray/core/generated/ObjectTableData.py.\n",
            "    Copying ray/core/generated/DriverTableData.py to build/lib/ray/core/generated/DriverTableData.py.\n",
            "    Copying ray/core/generated/ErrorType.py to build/lib/ray/core/generated/ErrorType.py.\n",
            "    Copying ray/core/generated/TaskTableData.py to build/lib/ray/core/generated/TaskTableData.py.\n",
            "    Copying ray/core/generated/ActorTableData.py to build/lib/ray/core/generated/ActorTableData.py.\n",
            "    Copying ray/core/generated/CustomSerializerData.py to build/lib/ray/core/generated/CustomSerializerData.py.\n",
            "    Copying ray/core/generated/RayResource.py to build/lib/ray/core/generated/RayResource.py.\n",
            "    Copying ray/core/generated/ProfileTableData.py to build/lib/ray/core/generated/ProfileTableData.py.\n",
            "    Copying ray/core/generated/ConfigTableData.py to build/lib/ray/core/generated/ConfigTableData.py.\n",
            "    Copying ray/core/generated/TaskReconstructionData.py to build/lib/ray/core/generated/TaskReconstructionData.py.\n",
            "    Copying ray/core/generated/Arg.py to build/lib/ray/core/generated/Arg.py.\n",
            "    Copying ray/core/generated/TaskTableTestAndUpdate.py to build/lib/ray/core/generated/TaskTableTestAndUpdate.py.\n",
            "    Copying ray/core/generated/ActorCheckpointIdData.py to build/lib/ray/core/generated/ActorCheckpointIdData.py.\n",
            "    Copying ray/core/generated/HeartbeatBatchTableData.py to build/lib/ray/core/generated/HeartbeatBatchTableData.py.\n",
            "    Copying ray/core/generated/ClassTableData.py to build/lib/ray/core/generated/ClassTableData.py.\n",
            "    Copying ray/core/generated/HeartbeatTableData.py to build/lib/ray/core/generated/HeartbeatTableData.py.\n",
            "    Copying ray/core/generated/ResourcePair.py to build/lib/ray/core/generated/ResourcePair.py.\n",
            "    Copying ray/core/generated/Language.py to build/lib/ray/core/generated/Language.py.\n",
            "    Copying ray/core/generated/ErrorTableData.py to build/lib/ray/core/generated/ErrorTableData.py.\n",
            "    Copying ray/core/generated/TablePrefix.py to build/lib/ray/core/generated/TablePrefix.py.\n",
            "    Copying ray/core/generated/FunctionTableData.py to build/lib/ray/core/generated/FunctionTableData.py.\n",
            "    Copying ray/core/generated/ProfileEvent.py to build/lib/ray/core/generated/ProfileEvent.py.\n",
            "    Copying ray/core/generated/TaskLeaseData.py to build/lib/ray/core/generated/TaskLeaseData.py.\n",
            "    Copying ray/core/generated/ClientTableData.py to build/lib/ray/core/generated/ClientTableData.py.\n",
            "    Copying ray/core/generated/GcsTableEntry.py to build/lib/ray/core/generated/GcsTableEntry.py.\n",
            "    Copying ray/core/generated/EntryType.py to build/lib/ray/core/generated/EntryType.py.\n",
            "    Copying ray/core/generated/ActorState.py to build/lib/ray/core/generated/ActorState.py.\n",
            "    Copying ray/core/generated/TaskInfo.py to build/lib/ray/core/generated/TaskInfo.py.\n",
            "    Copying ray/core/generated/__init__.py to build/lib/ray/core/generated/__init__.py.\n",
            "    Copying ray/core/generated/TablePubsub.py to build/lib/ray/core/generated/TablePubsub.py.\n",
            "    Copying ray/core/generated/ray/__init__.py to build/lib/ray/core/generated/ray/__init__.py.\n",
            "    Copying ray/core/generated/ray/protocol/WaitRequest.py to build/lib/ray/core/generated/ray/protocol/WaitRequest.py.\n",
            "    Copying ray/core/generated/ray/protocol/ResourceIdSetInfo.py to build/lib/ray/core/generated/ray/protocol/ResourceIdSetInfo.py.\n",
            "    Copying ray/core/generated/ray/protocol/MessageType.py to build/lib/ray/core/generated/ray/protocol/MessageType.py.\n",
            "    Copying ray/core/generated/ray/protocol/FreeObjectsRequest.py to build/lib/ray/core/generated/ray/protocol/FreeObjectsRequest.py.\n",
            "    Copying ray/core/generated/ray/protocol/WaitReply.py to build/lib/ray/core/generated/ray/protocol/WaitReply.py.\n",
            "    Copying ray/core/generated/ray/protocol/DisconnectClient.py to build/lib/ray/core/generated/ray/protocol/DisconnectClient.py.\n",
            "    Copying ray/core/generated/ray/protocol/SubmitTaskRequest.py to build/lib/ray/core/generated/ray/protocol/SubmitTaskRequest.py.\n",
            "    Copying ray/core/generated/ray/protocol/RegisterClientReply.py to build/lib/ray/core/generated/ray/protocol/RegisterClientReply.py.\n",
            "    Copying ray/core/generated/ray/protocol/NotifyUnblocked.py to build/lib/ray/core/generated/ray/protocol/NotifyUnblocked.py.\n",
            "    Copying ray/core/generated/ray/protocol/RegisterClientRequest.py to build/lib/ray/core/generated/ray/protocol/RegisterClientRequest.py.\n",
            "    Copying ray/core/generated/ray/protocol/TaskExecutionSpecification.py to build/lib/ray/core/generated/ray/protocol/TaskExecutionSpecification.py.\n",
            "    Copying ray/core/generated/ray/protocol/Task.py to build/lib/ray/core/generated/ray/protocol/Task.py.\n",
            "    Copying ray/core/generated/ray/protocol/RegisterNodeManagerRequest.py to build/lib/ray/core/generated/ray/protocol/RegisterNodeManagerRequest.py.\n",
            "    Copying ray/core/generated/ray/protocol/ForwardTaskRequest.py to build/lib/ray/core/generated/ray/protocol/ForwardTaskRequest.py.\n",
            "    Copying ray/core/generated/ray/protocol/GetTaskReply.py to build/lib/ray/core/generated/ray/protocol/GetTaskReply.py.\n",
            "    Copying ray/core/generated/ray/protocol/PushErrorRequest.py to build/lib/ray/core/generated/ray/protocol/PushErrorRequest.py.\n",
            "    Copying ray/core/generated/ray/protocol/FetchOrReconstruct.py to build/lib/ray/core/generated/ray/protocol/FetchOrReconstruct.py.\n",
            "    Copying ray/core/generated/ray/protocol/__init__.py to build/lib/ray/core/generated/ray/protocol/__init__.py.\n",
            "    Copying ray/autoscaler/aws/example-full.yaml to build/lib/ray/autoscaler/aws/example-full.yaml.\n",
            "    Copying ray/autoscaler/gcp/example-full.yaml to build/lib/ray/autoscaler/gcp/example-full.yaml.\n",
            "    Copying ray/autoscaler/local/example-full.yaml to build/lib/ray/autoscaler/local/example-full.yaml.\n",
            "    Creating /usr/local/lib/python3.6/dist-packages/ray.egg-link (link to .)\n",
            "    Adding ray 0.7.0 to easy-install.pth file\n",
            "    Installing ray script to /usr/local/bin\n",
            "    Installing rllib script to /usr/local/bin\n",
            "    Installing tune script to /usr/local/bin\n",
            "\n",
            "    Installed /content/ray-distr/python\n",
            "Successfully installed colorama-0.4.1 flatbuffers-1.11 funcsigs-1.0.2 ray redis-3.2.1\n",
            "Cleaning up...\n",
            "Removed build tracker '/tmp/pip-req-tracker-yv1_hsbl'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSOf6g3sfOP5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.append(os.path.join(\"\", '/content/ray-distr/python')) # To find local version of the library"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_iCFvpCJJLB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "182791a0-c3b9-40c1-a523-4d74e92fc6c0"
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import argparse\n",
        "import gym\n",
        "import logging\n",
        "import ray\n",
        "from ray import tune\n",
        "from ray.rllib.evaluation import PolicyGraph, PolicyEvaluator, SampleBatch\n",
        "from ray.rllib.evaluation.metrics import collect_metrics\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import scipy\n",
        "import scipy.signal\n",
        "from ray.rllib.utils.annotations import override\n",
        "logger = logging.getLogger(__name__)\n",
        "from ray.rllib.evaluation.postprocessing import compute_advantages,Postprocessing\n",
        "\n",
        "from torch.autograd import Variable\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--gpu\", action=\"store_true\")\n",
        "parser.add_argument(\"--num-iters\", type=int, default=20)\n",
        "parser.add_argument(\"--num-workers\", type=int, default=2)\n",
        "\n",
        "class TRPOAgent(nn.Module):\n",
        "    def __init__(self, state_shape, n_actions, hidden_size=32):\n",
        "        '''\n",
        "        Here you should define your model\n",
        "        You should have LOG-PROBABILITIES as output because you will need it to compute loss\n",
        "        We recommend that you start simple:\n",
        "        use 1-2 hidden layers with 100-500 units and relu for the first try\n",
        "        '''\n",
        "        nn.Module.__init__(self)\n",
        "\n",
        "        self.n_actions = n_actions\n",
        "        self.state_hape = state_shape\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(state_shape[0], hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, n_actions),\n",
        "            nn.LogSoftmax()\n",
        "        )\n",
        "\n",
        "    def forward(self, states):\n",
        "        \"\"\"\n",
        "        takes agent's observation (Variable), returns log-probabilities (Variable)\n",
        "        :param state_t: a batch of states, shape = [batch_size, state_shape]\n",
        "        \"\"\"\n",
        "\n",
        "        # Use your network to compute log_probs for given state\n",
        "        log_probs = self.model(states)\n",
        "        return log_probs\n",
        "\n",
        "    def get_log_probs(self, states):\n",
        "        '''\n",
        "        Log-probs for training\n",
        "        '''\n",
        "\n",
        "        return self.forward(states)\n",
        "\n",
        "    def get_probs(self, states):\n",
        "        '''\n",
        "        Probs for interaction\n",
        "        '''\n",
        "\n",
        "        return torch.exp(self.forward(states))\n",
        "\n",
        "    def act(self, obs, sample=True):\n",
        "        '''\n",
        "        Samples action from policy distribution (sample = True) or takes most likely action (sample = False)\n",
        "        :param: obs - single observation vector\n",
        "        :param sample: if True, samples from \\pi, otherwise takes most likely action\n",
        "        :returns: action (single integer) and probabilities for all actions\n",
        "        '''\n",
        "\n",
        "        probs = self.get_probs(Variable(torch.FloatTensor([obs]))).data.numpy()\n",
        "\n",
        "        if sample:\n",
        "            action = int(np.random.choice(self.n_actions, p=probs[0]))\n",
        "        else:\n",
        "            action = int(np.argmax(probs))\n",
        "\n",
        "        return action, probs[0]\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/compat.py:175: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qxmLg0Gdmqg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# UTIL FUNCTIONS\n",
        "def get_cummulative_returns(r, gamma=1):\n",
        "  \"\"\"\n",
        "  Computes cummulative discounted rewards given immediate rewards\n",
        "        G_i = r_i + gamma*r_{i+1} + gamma^2*r_{i+2} + ...\n",
        "        Also known as R(s,a)\n",
        "  \"\"\"\n",
        "  r = np.array(r)\n",
        "  assert r.ndim >= 1\n",
        "  return scipy.signal.lfilter([1], [1, -gamma], r[::-1], axis=0)[::-1]\n",
        "\n",
        "def conjugate_gradient(f_Ax, b, cg_iters=10, residual_tol=1e-10):\n",
        "    \"\"\"\n",
        "    This method solves system of equation Ax=b using iterative method called conjugate gradients\n",
        "    :f_Ax: function that returns Ax\n",
        "    :b: targets for Ax\n",
        "    :cg_iters: how many iterations this method should do\n",
        "    :residual_tol: epsilon for stability\n",
        "    \"\"\"\n",
        "    p = b.clone()\n",
        "    r = b.clone()\n",
        "    x = torch.zeros(b.size())\n",
        "    rdotr = torch.sum(r * r)\n",
        "    for i in range(cg_iters):\n",
        "        z = f_Ax(p)\n",
        "        v = rdotr / (torch.sum(p * z) + 1e-8)\n",
        "        x += v * p\n",
        "        r -= v * z\n",
        "        newrdotr = torch.sum(r * r)\n",
        "        mu = newrdotr / (rdotr + 1e-8)\n",
        "        p = r + mu * p\n",
        "        rdotr = newrdotr\n",
        "        if rdotr < residual_tol:\n",
        "            break\n",
        "    return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioP5xoJbJJZu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomPolicy(PolicyGraph):\n",
        "    \"\"\"Example of a custom policy graph written from scratch.\n",
        "    You might find it more convenient to extend TF/TorchPolicyGraph instead\n",
        "    for a real policy.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, observation_space, action_space, config):\n",
        "        PolicyGraph.__init__(self, observation_space, action_space, config)\n",
        "        # example parameter\n",
        "        self.w = 1.0\n",
        "        self.observation_shape = observation_space.shape\n",
        "        self.n_actions = action_space.n\n",
        "        self.agent = TRPOAgent(self.observation_shape, self.n_actions)\n",
        "        self.policy = []\n",
        "\n",
        "\n",
        "    def compute_actions(self,\n",
        "                        obs_batch,\n",
        "                        state_batches,\n",
        "                        prev_action_batch=None,\n",
        "                        prev_reward_batch=None,\n",
        "                        info_batch=None,\n",
        "                        episodes=None,\n",
        "                        **kwargs):\n",
        "        # return random actions\n",
        "        actions = []\n",
        "        action_probs = []\n",
        "        for obs in obs_batch:\n",
        "            action, policy = self.agent.act(obs)\n",
        "            actions.append(action)\n",
        "            action_probs.append(policy)\n",
        "\n",
        "        return actions, [], {\"action_probs\": action_probs}\n",
        "      \n",
        "    @override(PolicyGraph)\n",
        "    def postprocess_trajectory(self,\n",
        "                               sample_batch,\n",
        "                               other_agent_batches=None,\n",
        "                               episode=None):\n",
        "        traj = {}\n",
        "        for key in sample_batch:\n",
        "            traj[key] = np.stack(sample_batch[key])\n",
        "        traj[\"cummulative_returns\"] = get_cummulative_returns(traj[SampleBatch.REWARDS])\n",
        "        return SampleBatch(traj)\n",
        "\n",
        "\n",
        "    def get_flat_params_from(self, model):\n",
        "        params = []\n",
        "        for param in model.parameters():\n",
        "            params.append(param.data.view(-1))\n",
        "\n",
        "        flat_params = torch.cat(params)\n",
        "        return flat_params\n",
        "\n",
        "    def set_flat_params_to(self, model, flat_params):\n",
        "        prev_ind = 0\n",
        "        for param in model.parameters():\n",
        "            flat_size = int(np.prod(list(param.size())))\n",
        "            param.data.copy_(\n",
        "                flat_params[prev_ind:prev_ind + flat_size].view(param.size()))\n",
        "            prev_ind += flat_size\n",
        "\n",
        "    def get_loss(self, agent, observations, actions, cummulative_returns, old_probs):\n",
        "        \"\"\"\n",
        "        Computes TRPO objective\n",
        "        :param: observations - batch of observations\n",
        "        :param: actions - batch of actions\n",
        "        :param: cummulative_returns - batch of cummulative returns\n",
        "        :param: old_probs - batch of probabilities computed by old network\n",
        "        :returns: scalar value of the objective function\n",
        "        \"\"\"\n",
        "        batch_size = observations.shape[0]\n",
        "        log_probs_all = agent.get_log_probs(observations)\n",
        "        probs_all = torch.exp(log_probs_all)\n",
        "\n",
        "        probs_for_actions = probs_all[torch.arange(\n",
        "            0, batch_size, out=torch.LongTensor()), actions]\n",
        "        old_probs_for_actions = old_probs[torch.arange(\n",
        "            0, batch_size, out=torch.LongTensor()), actions]\n",
        "\n",
        "        # Compute surrogate loss, aka importance-sampled policy gradient\n",
        "        Loss = -torch.mean(cummulative_returns * (probs_for_actions / old_probs_for_actions))\n",
        "\n",
        "        return Loss\n",
        "\n",
        "    def get_kl(self, agent, observations, actions, cummulative_returns, old_probs_all):\n",
        "        \"\"\"\n",
        "        Computes KL-divergence between network policy and old policy\n",
        "        :param: observations - batch of observations\n",
        "        :param: actions - batch of actions\n",
        "        :param: cummulative_returns - batch of cummulative returns (we don't need it actually)\n",
        "        :param: old_probs - batch of probabilities computed by old network\n",
        "        :returns: scalar value of the KL-divergence\n",
        "        \"\"\"\n",
        "        batch_size = observations.shape[0]\n",
        "        log_probs_all = agent.get_log_probs(observations)\n",
        "        probs_all = torch.exp(log_probs_all)\n",
        "\n",
        "        # Compute Kullback-Leibler divergence (see formula above)\n",
        "        # Note: you need to sum KL and entropy over all actions, not just the ones agent took\n",
        "        old_log_probs_all = torch.log(old_probs_all + 1e-10)\n",
        "\n",
        "        kl = torch.sum(old_probs_all * (old_log_probs_all - log_probs_all)) / batch_size\n",
        "\n",
        "        return kl\n",
        "\n",
        "    def get_entropy(self, agent, observations):\n",
        "        \"\"\"\n",
        "        Computes entropy of the network policy\n",
        "        :param: observations - batch of observations\n",
        "        :returns: scalar value of the entropy\n",
        "        \"\"\"\n",
        "\n",
        "        observations = Variable(torch.FloatTensor(observations))\n",
        "\n",
        "        batch_size = observations.shape[0]\n",
        "        log_probs_all = agent.get_log_probs(observations)\n",
        "        probs_all = torch.exp(log_probs_all)\n",
        "\n",
        "        entropy = torch.sum(-probs_all * log_probs_all) / batch_size\n",
        "\n",
        "        return entropy\n",
        "\n",
        "    def linesearch(self, f, x, fullstep, max_kl):\n",
        "        \"\"\"\n",
        "        Linesearch finds the best parameters of neural networks in the direction of fullstep contrainted by KL divergence.\n",
        "        :param: f - function that returns loss, kl and arbitrary third component.\n",
        "        :param: x - old parameters of neural network.\n",
        "        :param: fullstep - direction in which we make search.\n",
        "        :param: max_kl - constraint of KL divergence.\n",
        "        :returns:\n",
        "        \"\"\"\n",
        "        max_backtracks = 10\n",
        "        loss, _, = f(x)\n",
        "        for stepfrac in .5 ** np.arange(max_backtracks):\n",
        "            xnew = x + stepfrac * fullstep\n",
        "            new_loss, kl = f(xnew)\n",
        "            actual_improve = new_loss - loss\n",
        "            if kl.data.numpy() <= max_kl and actual_improve.data.numpy() < 0:\n",
        "                x = xnew\n",
        "                loss = new_loss\n",
        "        return x\n",
        "\n",
        "    def learn_on_batch(self, samples):\n",
        "        # implement your learning code here\n",
        "        max_kl = 0.01\n",
        "        # Updating policy.\n",
        "        observations = samples['obs']\n",
        "        actions = samples['actions']\n",
        "        returns = samples['cummulative_returns']\n",
        "        old_probs = samples['action_probs']\n",
        "        loss, kl = self.update_step(observations, actions, returns, old_probs, max_kl)\n",
        "        \n",
        "        return {\n",
        "            \"loss\": loss,\n",
        "            \"kl\": kl\n",
        "        }\n",
        "\n",
        "    def get_weights(self):\n",
        "        return self.get_flat_params_from(self.agent)\n",
        "\n",
        "    def set_weights(self, weights):\n",
        "        self.set_flat_params_to(self.agent, weights)\n",
        "        \n",
        "    def update_step(self, observations, actions, cummulative_returns, old_probs, max_kl):\n",
        "      \"\"\"\n",
        "      This function does the TRPO update step\n",
        "      :param: observations - batch of observations\n",
        "      :param: actions - batch of actions\n",
        "      :param: cummulative_returns - batch of cummulative returns\n",
        "      :param: old_probs - batch of probabilities computed by old network\n",
        "      :param: max_kl - controls how big KL divergence may be between old and new policy every step.\n",
        "      :returns: KL between new and old policies and the value of the loss function.\n",
        "      \"\"\"\n",
        "      agent = self.agent\n",
        "\n",
        "      # Here we prepare the information\n",
        "      observations = Variable(torch.FloatTensor(observations))\n",
        "      actions = torch.LongTensor(actions)\n",
        "      cummulative_returns = Variable(torch.FloatTensor(cummulative_returns))\n",
        "      old_probs = Variable(torch.FloatTensor(old_probs))\n",
        "\n",
        "      # Here we compute gradient of the loss function\n",
        "      loss = self.get_loss(agent, observations, actions,\n",
        "                      cummulative_returns, old_probs)\n",
        "      grads = torch.autograd.grad(loss, agent.parameters())\n",
        "      loss_grad = torch.cat([grad.view(-1) for grad in grads]).data\n",
        "\n",
        "      def Fvp(v):\n",
        "          # Here we compute Fx to do solve Fx = g using conjugate gradients\n",
        "          # We actually do here a couple of tricks to compute it efficiently\n",
        "\n",
        "          kl = self.get_kl(agent, observations, actions,\n",
        "                      cummulative_returns, old_probs)\n",
        "\n",
        "          grads = torch.autograd.grad(kl, agent.parameters(), create_graph=True)\n",
        "          flat_grad_kl = torch.cat([grad.view(-1) for grad in grads])\n",
        "\n",
        "          kl_v = (flat_grad_kl * Variable(v)).sum()\n",
        "          grads = torch.autograd.grad(kl_v, agent.parameters())\n",
        "          flat_grad_grad_kl = torch.cat(\n",
        "              [grad.contiguous().view(-1) for grad in grads]).data\n",
        "\n",
        "          return flat_grad_grad_kl + v * 0.1\n",
        "\n",
        "      # Here we solveolve Fx = g system using conjugate gradients\n",
        "      stepdir = conjugate_gradient(Fvp, -loss_grad, 10)\n",
        "\n",
        "      # Here we compute the initial vector to do linear search\n",
        "      shs = 0.5 * (stepdir * Fvp(stepdir)).sum(0, keepdim=True)\n",
        "\n",
        "      lm = torch.sqrt(shs / max_kl)\n",
        "      fullstep = stepdir / lm[0]\n",
        "\n",
        "\n",
        "      # Here we get the start point\n",
        "      prev_params = self.get_weights()\n",
        "\n",
        "      def get_loss_kl(params):\n",
        "          # Helper for linear search\n",
        "          # Set new params and return loss + kl\n",
        "          self.set_weights(params)\n",
        "          return [self.get_loss(agent, observations, actions, cummulative_returns, old_probs),\n",
        "                  self.get_kl(agent, observations, actions, cummulative_returns, old_probs)]\n",
        "\n",
        "      # Here we find our new parameters\n",
        "      new_params = self.linesearch(get_loss_kl, prev_params, fullstep, max_kl)\n",
        "\n",
        "      return get_loss_kl(new_params)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIUf03whVqos",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ll39xhuvJJXL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def training_workflow(config, reporter):\n",
        "    # Setup policy and policy evaluation actors\n",
        "    env = gym.make(\"CartPole-v0\")\n",
        "    policy = CustomPolicy(env.observation_space, env.action_space, {})\n",
        "    workers = [\n",
        "        PolicyEvaluator.as_remote().remote(lambda c: gym.make(\"CartPole-v0\"),\n",
        "                                           CustomPolicy)\n",
        "        for _ in range(config[\"num_workers\"])\n",
        "    ]\n",
        "\n",
        "    for it in range(config[\"num_iters\"]):\n",
        "        print(\"\\n********** Iteration %i ************\" % it)\n",
        "        # Broadcast weights to the policy evaluation workers\n",
        "        weights = ray.put({\"default_policy\": policy.get_weights()})\n",
        "        for w in workers:\n",
        "            w.set_weights.remote(weights)\n",
        "\n",
        "        # Gather a batch of samples\n",
        "        samples = SampleBatch.concat_samples(ray.get([w.sample.remote() for w in workers]))\n",
        "       \n",
        "        \n",
        "\n",
        "#         prev_t = 0\n",
        "#         obervations, actions, rewards, action_probs, cum_returns = [], [], [], [], []\n",
        "#         for t in samples['t']:\n",
        "#           if t == 0 and prev_t != 0:\n",
        "            \n",
        "#             path = {\"observations\": np.array(obervations),\n",
        "#                     \"policy\": np.array(action_probs),\n",
        "#                     \"actions\": np.array(actions),\n",
        "#                     \"rewards\": np.array(rewards),\n",
        "#                     \"cumulative_returns\": np.array(cum_returns),\n",
        "#                     }\n",
        "#             obervations, actions, rewards, action_probs = [], [], [], []\n",
        "#             paths.append(path)\n",
        "#           else:  \n",
        "#             obervations.append(samples['obs'][t])\n",
        "#             actions.append(samples['actions'][t])\n",
        "#             action_probs.append(samples['action_probs'][t])\n",
        "#             rewards.append(samples['rewards'][t])   \n",
        "#             cum_returns.append(samples['cummulative_returns'][t])\n",
        "#             prev_t = t\n",
        "\n",
        "        # Improve the policy using the  batch\n",
        "        loss_stats =   policy.learn_on_batch(samples)\n",
        "        # Report current progress\n",
        "#         episode_rewards = np.array([path[\"rewards\"].sum() for path in paths])\n",
        "    \n",
        "        reporter(**collect_metrics(remote_evaluators=workers))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ds31NxLhw-xQ",
        "colab_type": "code",
        "outputId": "16f4c9da-5019-43c4-bef0-95796808f38d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        }
      },
      "source": [
        "ray.init()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-05-19 22:13:56,158\tWARNING worker.py:1341 -- WARNING: Not updating worker name since `setproctitle` is not installed. Install this with `pip install setproctitle` (or ray[debug]) to enable monitoring of worker processes.\n",
            "2019-05-19 22:13:56,161\tINFO node.py:498 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-05-19_22-13-56_160574_13215/logs.\n",
            "2019-05-19 22:13:56,286\tINFO services.py:409 -- Waiting for redis server at 127.0.0.1:60639 to respond...\n",
            "2019-05-19 22:13:56,432\tINFO services.py:409 -- Waiting for redis server at 127.0.0.1:24143 to respond...\n",
            "2019-05-19 22:13:56,439\tINFO services.py:806 -- Starting Redis shard with 2.52 GB max memory.\n",
            "2019-05-19 22:13:56,500\tINFO node.py:512 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-05-19_22-13-56_160574_13215/logs.\n",
            "2019-05-19 22:13:56,503\tINFO services.py:1442 -- Starting the Plasma object store with 3.78 GB memory using /dev/shm.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'node_ip_address': '172.28.0.2',\n",
              " 'object_store_address': '/tmp/ray/session_2019-05-19_22-13-56_160574_13215/sockets/plasma_store',\n",
              " 'raylet_socket_name': '/tmp/ray/session_2019-05-19_22-13-56_160574_13215/sockets/raylet',\n",
              " 'redis_address': '172.28.0.2:60639',\n",
              " 'session_dir': '/tmp/ray/session_2019-05-19_22-13-56_160574_13215',\n",
              " 'webui_url': None}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XslGt--JJR1",
        "colab_type": "code",
        "outputId": "a339b078-79cd-4cfe-f768-62c3863ed198",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2471
        }
      },
      "source": [
        "\n",
        "tune.run(\n",
        "        training_workflow,\n",
        "        resources_per_trial={\n",
        "            \"gpu\": 0,\n",
        "            \"cpu\": 1,\n",
        "            \"extra_cpu\": 1,\n",
        "        },\n",
        "        config={\n",
        "            \"num_workers\": 1,\n",
        "            \"num_iters\": 3,\n",
        "        })"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-05-19 23:52:23,984\tINFO tune.py:60 -- Tip: to resume incomplete experiments, pass resume='prompt' or resume=True to run()\n",
            "2019-05-19 23:52:23,986\tINFO tune.py:223 -- Starting a new experiment.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "== Status ==\n",
            "Using FIFO scheduling algorithm.\n",
            "Resources requested: 0/2 CPUs, 0/1 GPUs\n",
            "Memory usage on this node: 6.5/13.7 GB\n",
            "\n",
            "== Status ==\n",
            "Using FIFO scheduling algorithm.\n",
            "Resources requested: 2/2 CPUs, 0/1 GPUs\n",
            "Memory usage on this node: 6.5/13.7 GB\n",
            "Result logdir: /root/ray_results/training_workflow\n",
            "Number of trials: 1 ({'RUNNING': 1})\n",
            "RUNNING trials:\n",
            " - training_workflow_0:\tRUNNING\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=15582)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/compat.py:175: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=15582)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=15582)\u001b[0m non-resource variables are not supported in the long term\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/compat.py:175: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m non-resource variables are not supported in the long term\n",
            "\u001b[2m\u001b[36m(pid=15582)\u001b[0m 2019-05-19 23:52:27,460\tWARNING worker.py:204 -- Calling ray.get or ray.wait in a separate thread may lead to deadlock if the main thread blocks on this thread and there are not enough resources to execute more tasks\n",
            "\u001b[2m\u001b[36m(pid=15582)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=15582)\u001b[0m ********** Iteration 0 ************\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m 2019-05-19 23:52:27,812\tINFO policy_evaluator.py:732 -- Built policy map: {'default_policy': <__main__.CustomPolicy object at 0x7fb2a17bb9e8>}\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m 2019-05-19 23:52:27,812\tINFO policy_evaluator.py:733 -- Built preprocessor map: {'default_policy': <ray.rllib.models.preprocessors.NoPreprocessor object at 0x7fb3831c1470>}\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m 2019-05-19 23:52:27,812\tINFO policy_evaluator.py:344 -- Built filter map: {'default_policy': <ray.rllib.utils.filter.NoFilter object at 0x7fb3831c1438>}\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m 2019-05-19 23:52:27,817\tINFO policy_evaluator.py:438 -- Generating sample batch of size 100\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m 2019-05-19 23:52:27,818\tINFO sampler.py:308 -- Raw obs from env: { 0: { 'agent0': np.ndarray((4,), dtype=float64, min=0.021, max=0.037, mean=0.029)}}\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m 2019-05-19 23:52:27,818\tINFO sampler.py:309 -- Info return from env: {0: {'agent0': None}}\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m 2019-05-19 23:52:27,818\tINFO sampler.py:407 -- Preprocessed obs: np.ndarray((4,), dtype=float64, min=0.021, max=0.037, mean=0.029)\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m 2019-05-19 23:52:27,818\tINFO sampler.py:411 -- Filtered obs: np.ndarray((4,), dtype=float64, min=0.021, max=0.037, mean=0.029)\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m 2019-05-19 23:52:27,819\tINFO sampler.py:525 -- Inputs to compute_actions():\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m { 'default_policy': [ { 'data': { 'agent_id': 'agent0',\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m                                   'env_id': 0,\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m                                   'info': None,\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m                                   'obs': np.ndarray((4,), dtype=float64, min=0.021, max=0.037, mean=0.029),\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m                                   'prev_action': np.ndarray((), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m                                   'prev_reward': 0.0,\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m                                   'rnn_state': []},\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m                         'type': 'PolicyEvalData'}]}\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m /usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m   input = module(input)\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m 2019-05-19 23:52:27,821\tINFO sampler.py:552 -- Outputs of compute_actions():\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m { 'default_policy': ( [0],\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m                       [],\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m                       { 'action_probs': [ np.ndarray((2,), dtype=float32, min=0.428, max=0.572, mean=0.5)]})}\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m 2019-05-19 23:52:27,832\tINFO sample_batch_builder.py:161 -- Trajectory fragment after postprocess_trajectory():\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m { 'agent0': { 'data': { 'action_probs': np.ndarray((19, 2), dtype=float32, min=0.411, max=0.589, mean=0.5),\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m                         'actions': np.ndarray((19,), dtype=int64, min=0.0, max=1.0, mean=0.421),\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m                         'agent_index': np.ndarray((19,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m                         'cummulative_returns': np.ndarray((19,), dtype=float64, min=1.0, max=19.0, mean=10.0),\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m                         'dones': np.ndarray((19,), dtype=bool, min=0.0, max=1.0, mean=0.053),\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m                         'eps_id': np.ndarray((19,), dtype=int64, min=1198780670.0, max=1198780670.0, mean=1198780670.0),\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m                         'infos': np.ndarray((19,), dtype=object, head={}),\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m                         'new_obs': np.ndarray((19, 4), dtype=float32, min=-0.758, max=1.522, mean=0.115),\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m                         'obs': np.ndarray((19, 4), dtype=float32, min=-0.758, max=1.522, mean=0.104),\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m                         'prev_actions': np.ndarray((19,), dtype=int64, min=0.0, max=1.0, mean=0.421),\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m                         'prev_rewards': np.ndarray((19,), dtype=float32, min=0.0, max=1.0, mean=0.947),\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m                         'rewards': np.ndarray((19,), dtype=float32, min=1.0, max=1.0, mean=1.0),\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m                         't': np.ndarray((19,), dtype=int64, min=0.0, max=18.0, mean=9.0),\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m                         'unroll_id': np.ndarray((19,), dtype=int64, min=0.0, max=0.0, mean=0.0)},\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m               'type': 'SampleBatch'}}\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=15582)\u001b[0m /usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "\u001b[2m\u001b[36m(pid=15582)\u001b[0m   input = module(input)\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m 2019-05-19 23:52:27,875\tINFO policy_evaluator.py:475 -- Completed sample batch:\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m { 'data': { 'action_probs': np.ndarray((100, 2), dtype=float32, min=0.376, max=0.624, mean=0.5),\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m             'actions': np.ndarray((100,), dtype=int64, min=0.0, max=1.0, mean=0.46),\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m             'agent_index': np.ndarray((100,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m             'cummulative_returns': np.ndarray((100,), dtype=float32, min=1.0, max=26.0, mean=11.69),\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m             'dones': np.ndarray((100,), dtype=bool, min=0.0, max=1.0, mean=0.04),\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m             'eps_id': np.ndarray((100,), dtype=int64, min=312454174.0, max=1725812996.0, mean=1153435052.8),\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m             'infos': np.ndarray((100,), dtype=object, head={}),\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m             'new_obs': np.ndarray((100, 4), dtype=float32, min=-0.844, max=1.757, mean=0.075),\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m             'obs': np.ndarray((100, 4), dtype=float32, min=-0.818, max=1.522, mean=0.067),\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m             'prev_actions': np.ndarray((100,), dtype=int64, min=0.0, max=1.0, mean=0.44),\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m             'prev_rewards': np.ndarray((100,), dtype=float32, min=0.0, max=1.0, mean=0.95),\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m             'rewards': np.ndarray((100,), dtype=float32, min=1.0, max=1.0, mean=1.0),\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m             't': np.ndarray((100,), dtype=int64, min=0.0, max=25.0, mean=10.69),\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m             'unroll_id': np.ndarray((100,), dtype=int64, min=0.0, max=0.0, mean=0.0)},\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m   'type': 'SampleBatch'}\n",
            "\u001b[2m\u001b[36m(pid=15586)\u001b[0m \n",
            "Result for training_workflow_0:\n",
            "  custom_metrics: {}\n",
            "  date: 2019-05-19_23-52-27\n",
            "  done: false\n",
            "  episode_len_mean: 23.25\n",
            "  episode_reward_max: 26.0\n",
            "  episode_reward_mean: 23.25\n",
            "  episode_reward_min: 19.0\n",
            "  episodes_this_iter: 4\n",
            "  episodes_total: 4\n",
            "  experiment_id: dd0a5f3b034b400bab8c3e0bd30c7c04\n",
            "  hostname: 3db777dd2d2e\n",
            "  iterations_since_restore: 1\n",
            "  node_ip: 172.28.0.2\n",
            "  num_metric_batches_dropped: 0\n",
            "  off_policy_estimator: {}\n",
            "  pid: 15582\n",
            "  policy_reward_mean: {}\n",
            "  sampler_perf:\n",
            "    mean_env_wait_ms: 0.0551077398923364\n",
            "    mean_inference_ms: 0.33555880631550705\n",
            "    mean_processing_ms: 0.1601110590566503\n",
            "  time_since_restore: 0.4863307476043701\n",
            "  time_this_iter_s: 0.4863307476043701\n",
            "  time_total_s: 0.4863307476043701\n",
            "  timestamp: 1558309947\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  \n",
            "\u001b[2m\u001b[36m(pid=15582)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=15582)\u001b[0m ********** Iteration 1 ************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-05-19 23:52:28,141\tINFO ray_trial_executor.py:180 -- Destroying actor for trial training_workflow_0. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=15582)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=15582)\u001b[0m ********** Iteration 2 ************\n",
            "== Status ==\n",
            "Using FIFO scheduling algorithm.\n",
            "Resources requested: 0/2 CPUs, 0/1 GPUs\n",
            "Memory usage on this node: 6.9/13.7 GB\n",
            "Result logdir: /root/ray_results/training_workflow\n",
            "Number of trials: 1 ({'TERMINATED': 1})\n",
            "TERMINATED trials:\n",
            " - training_workflow_0:\tTERMINATED, [2 CPUs, 0 GPUs], [pid=15582], 0 s, 3 iter, 45 rew\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[training_workflow_0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "757HuIw26WiM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "sys.path.append(os.path.join(\"\", '/content/ray-custom-agents')) # To find local version of the library\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-IGYVLeIhYs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from trpo.trainer import DEFAULT_CONFIG,TRPOTrainer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doSKKtvv7cem",
        "colab_type": "code",
        "outputId": "ccfc5a17-bc39-4000-c3bf-985cf2b299e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\"\"\"Example of using two different training methods at once in multi-agent.\n",
        "Here we create a number of CartPole agents, some of which are trained with\n",
        "DQN, and some of which are trained with PPO. We periodically sync weights\n",
        "between the two trainers (note that no such syncing is needed when using just\n",
        "a single training method).\n",
        "For a simpler example, see also: multiagent_cartpole.py\n",
        "\"\"\"\n",
        "\n",
        "import argparse\n",
        "import gym\n",
        "\n",
        "import ray\n",
        "from ray.rllib.agents.dqn.dqn import DQNTrainer\n",
        "from ray.rllib.agents.dqn.dqn_policy_graph import DQNPolicyGraph\n",
        "from ray.rllib.agents.ppo.ppo import PPOTrainer\n",
        "from ray.rllib.agents.ppo.ppo_policy_graph import PPOTFPolicy\n",
        "from ray.rllib.tests.test_multi_agent_env import MultiCartpole\n",
        "from ray.tune.logger import pretty_print\n",
        "from ray.tune.registry import register_env"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/compat.py:175: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXzwBG1fbMyI",
        "colab_type": "code",
        "outputId": "68f24194-2477-4360-c2cf-1a71b3e0aafc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--num-iters\", type=int, default=20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreAction(option_strings=['--num-iters'], dest='num_iters', nargs=None, const=None, default=20, type=<class 'int'>, choices=None, help=None, metavar=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxA81Hs3bO-G",
        "colab_type": "code",
        "outputId": "25c8a835-5df4-4674-997b-65e8e4893090",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "num_iters = 20\n",
        "ray.init()\n",
        "\n",
        "# Simple environment with 4 independent cartpole entities\n",
        "register_env(\"multi_cartpole\", lambda _: MultiCartpole(4))\n",
        "single_env = gym.make(\"CartPole-v0\")\n",
        "obs_space = single_env.observation_space\n",
        "act_space = single_env.action_space\n",
        "\n",
        "# You can also have multiple policy graphs per trainer, but here we just\n",
        "# show one each for PPO and DQN.\n",
        "policy_graphs = {\n",
        "    \"ppo_policy\": (PPOTFPolicy, obs_space, act_space, {}),\n",
        "    \"dqn_policy\": (DQNPolicyGraph, obs_space, act_space, {}),\n",
        "}\n",
        "\n",
        "def policy_mapping_fn(agent_id):\n",
        "    if agent_id % 2 == 0:\n",
        "        return \"ppo_policy\"\n",
        "    else:\n",
        "        return \"dqn_policy\"\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-05-19 14:11:18,682\tWARNING worker.py:1341 -- WARNING: Not updating worker name since `setproctitle` is not installed. Install this with `pip install setproctitle` (or ray[debug]) to enable monitoring of worker processes.\n",
            "2019-05-19 14:11:18,685\tINFO node.py:498 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-05-19_14-11-18_684709_123/logs.\n",
            "2019-05-19 14:11:18,807\tINFO services.py:409 -- Waiting for redis server at 127.0.0.1:61930 to respond...\n",
            "2019-05-19 14:11:18,954\tINFO services.py:409 -- Waiting for redis server at 127.0.0.1:21384 to respond...\n",
            "2019-05-19 14:11:18,960\tINFO services.py:806 -- Starting Redis shard with 2.58 GB max memory.\n",
            "2019-05-19 14:11:19,015\tINFO node.py:512 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-05-19_14-11-18_684709_123/logs.\n",
            "2019-05-19 14:11:19,018\tINFO services.py:1442 -- Starting the Plasma object store with 3.87 GB memory using /dev/shm.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Md_idzJ7jz4",
        "colab_type": "code",
        "outputId": "47f70f84-7a7d-4403-8acc-623a973b1505",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1618
        }
      },
      "source": [
        "ppo_trainer = PPOTrainer(\n",
        "    env=\"multi_cartpole\",\n",
        "    config={\n",
        "        \"multiagent\": {\n",
        "            \"policy_graphs\": policy_graphs,\n",
        "            \"policy_mapping_fn\": policy_mapping_fn,\n",
        "            \"policies_to_train\": [\"ppo_policy\"],\n",
        "        },\n",
        "        # disable filters, otherwise we would need to synchronize those\n",
        "        # as well to the DQN agent\n",
        "        \"observation_filter\": \"NoFilter\",\n",
        "})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-05-19 14:11:45,290\tINFO ppo.py:149 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
            "2019-05-19 14:11:45,292\tWARNING ppo.py:154 -- FYI: By default, the value function will not share layers with the policy model ('vf_share_layers': False).\n",
            "2019-05-19 14:11:45,299\tINFO policy_evaluator.py:312 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/ray-distr/python/ray/rllib/models/fcnet.py:37: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/decorator_utils.py:145: GraphKeys.VARIABLES (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.GraphKeys.GLOBAL_VARIABLES` instead.\n",
            "WARNING:tensorflow:From /content/ray-distr/python/ray/rllib/agents/dqn/dqn_policy_graph.py:337: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.random.categorical instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-05-19 14:11:47,424\tINFO dynamic_tf_policy_graph.py:265 -- Initializing loss function with dummy input:\n",
            "\n",
            "{ 'action_prob': <tf.Tensor 'ppo_policy/action_prob:0' shape=(?,) dtype=float32>,\n",
            "  'actions': <tf.Tensor 'ppo_policy/actions:0' shape=(?,) dtype=int64>,\n",
            "  'advantages': <tf.Tensor 'ppo_policy/advantages:0' shape=(?,) dtype=float32>,\n",
            "  'behaviour_logits': <tf.Tensor 'ppo_policy/behaviour_logits:0' shape=(?, 2) dtype=float32>,\n",
            "  'dones': <tf.Tensor 'ppo_policy/dones:0' shape=(?,) dtype=bool>,\n",
            "  'new_obs': <tf.Tensor 'ppo_policy/new_obs:0' shape=(?, 4) dtype=float32>,\n",
            "  'obs': <tf.Tensor 'ppo_policy/observation:0' shape=(?, 4) dtype=float32>,\n",
            "  'prev_actions': <tf.Tensor 'ppo_policy/action:0' shape=(?,) dtype=int64>,\n",
            "  'prev_rewards': <tf.Tensor 'ppo_policy/prev_reward:0' shape=(?,) dtype=float32>,\n",
            "  'rewards': <tf.Tensor 'ppo_policy/rewards:0' shape=(?,) dtype=float32>,\n",
            "  'value_targets': <tf.Tensor 'ppo_policy/value_targets:0' shape=(?,) dtype=float32>,\n",
            "  'vf_preds': <tf.Tensor 'ppo_policy/vf_preds:0' shape=(?,) dtype=float32>}\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-05-19 14:11:48,909\tINFO policy_evaluator.py:732 -- Built policy map: {'dqn_policy': <ray.rllib.agents.dqn.dqn_policy_graph.DQNPolicyGraph object at 0x7f964a2bd898>, 'ppo_policy': <ray.rllib.evaluation.tf_policy_template.PPOTFPolicy object at 0x7f963b33cd30>}\n",
            "2019-05-19 14:11:48,911\tINFO policy_evaluator.py:733 -- Built preprocessor map: {'dqn_policy': <ray.rllib.models.preprocessors.NoPreprocessor object at 0x7f964a2bd4a8>, 'ppo_policy': <ray.rllib.models.preprocessors.NoPreprocessor object at 0x7f964a2bd5c0>}\n",
            "2019-05-19 14:11:48,918\tINFO policy_evaluator.py:344 -- Built filter map: {'dqn_policy': <ray.rllib.utils.filter.NoFilter object at 0x7f963b356b70>, 'ppo_policy': <ray.rllib.utils.filter.NoFilter object at 0x7f963b294550>}\n",
            "2019-05-19 14:11:48,953\tWARNING worker.py:342 -- WARNING: Falling back to serializing objects of type <class 'numpy.dtype'> by using pickle. This may be inefficient.\n",
            "2019-05-19 14:11:49,167\tINFO multi_gpu_optimizer.py:80 -- LocalMultiGPUOptimizer devices ['/cpu:0']\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/compat.py:175: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m non-resource variables are not supported in the long term\n",
            "\u001b[2m\u001b[36m(pid=11719)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/compat.py:175: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=11719)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=11719)\u001b[0m non-resource variables are not supported in the long term\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m 2019-05-19 14:11:54,565\tINFO policy_evaluator.py:312 -- Creating policy evaluation worker 1 on CPU (please ignore any CUDA init errors)\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m 2019-05-19 14:11:54.615841: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m 2019-05-19 14:11:54.616146: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x1824840 executing computations on platform Host. Devices:\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m 2019-05-19 14:11:54.616185: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "\u001b[2m\u001b[36m(pid=11719)\u001b[0m 2019-05-19 14:11:54,657\tINFO policy_evaluator.py:312 -- Creating policy evaluation worker 2 on CPU (please ignore any CUDA init errors)\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m WARNING:tensorflow:From /content/ray-distr/python/ray/rllib/models/fcnet.py:37: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m Use keras.layers.dense instead.\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m Colocations handled automatically by placer.\n",
            "\u001b[2m\u001b[36m(pid=11719)\u001b[0m 2019-05-19 14:11:54.688614: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "\u001b[2m\u001b[36m(pid=11719)\u001b[0m 2019-05-19 14:11:54.688908: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x21d8840 executing computations on platform Host. Devices:\n",
            "\u001b[2m\u001b[36m(pid=11719)\u001b[0m 2019-05-19 14:11:54.688943: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "\u001b[2m\u001b[36m(pid=11719)\u001b[0m WARNING:tensorflow:From /content/ray-distr/python/ray/rllib/models/fcnet.py:37: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=11719)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=11719)\u001b[0m Use keras.layers.dense instead.\n",
            "\u001b[2m\u001b[36m(pid=11719)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=11719)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=11719)\u001b[0m Colocations handled automatically by placer.\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/decorator_utils.py:145: GraphKeys.VARIABLES (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m Use `tf.GraphKeys.GLOBAL_VARIABLES` instead.\n",
            "\u001b[2m\u001b[36m(pid=11719)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/decorator_utils.py:145: GraphKeys.VARIABLES (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=11719)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=11719)\u001b[0m Use `tf.GraphKeys.GLOBAL_VARIABLES` instead.\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m WARNING:tensorflow:From /content/ray-distr/python/ray/rllib/agents/dqn/dqn_policy_graph.py:337: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m Use tf.random.categorical instead.\n",
            "\u001b[2m\u001b[36m(pid=11719)\u001b[0m WARNING:tensorflow:From /content/ray-distr/python/ray/rllib/agents/dqn/dqn_policy_graph.py:337: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=11719)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=11719)\u001b[0m Use tf.random.categorical instead.\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m Use tf.cast instead.\n",
            "\u001b[2m\u001b[36m(pid=11719)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=11719)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=11719)\u001b[0m Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJVV_x_ub2Pi",
        "colab_type": "code",
        "outputId": "92ec53b1-0b1e-4cbc-a2d8-6ae20027cd6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "dqn_trainer = DQNTrainer(\n",
        "    env=\"multi_cartpole\",\n",
        "    config={\n",
        "        \"multiagent\": {\n",
        "            \"policy_graphs\": policy_graphs,\n",
        "            \"policy_mapping_fn\": policy_mapping_fn,\n",
        "            \"policies_to_train\": [\"dqn_policy\"],\n",
        "        },\n",
        "        \"gamma\": 0.95,\n",
        "        \"n_step\": 3,\n",
        "})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-05-19 14:12:20,039\tINFO policy_evaluator.py:312 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "2019-05-19 14:12:23,485\tINFO policy_evaluator.py:732 -- Built policy map: {'dqn_policy': <ray.rllib.agents.dqn.dqn_policy_graph.DQNPolicyGraph object at 0x7f9552336e80>, 'ppo_policy': <ray.rllib.evaluation.tf_policy_template.PPOTFPolicy object at 0x7f95502e73c8>}\n",
            "2019-05-19 14:12:23,487\tINFO policy_evaluator.py:733 -- Built preprocessor map: {'dqn_policy': <ray.rllib.models.preprocessors.NoPreprocessor object at 0x7f9552336a90>, 'ppo_policy': <ray.rllib.models.preprocessors.NoPreprocessor object at 0x7f9552336ba8>}\n",
            "2019-05-19 14:12:23,488\tINFO policy_evaluator.py:344 -- Built filter map: {'dqn_policy': <ray.rllib.utils.filter.NoFilter object at 0x7f95502c8fd0>, 'ppo_policy': <ray.rllib.utils.filter.NoFilter object at 0x7f95502e7cf8>}\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsmNKPLTb9ir",
        "colab_type": "code",
        "outputId": "4cd0fda7-109e-4167-8d2f-cc01b4e55280",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "# disable DQN exploration when used by the PPO trainer\n",
        "ppo_trainer.optimizer.foreach_evaluator(\n",
        "    lambda ev: ev.for_policy(\n",
        "        lambda pi: pi.set_epsilon(0.0), policy_id=\"dqn_policy\"))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, None, None]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nhd0HVfncHik",
        "colab_type": "code",
        "outputId": "b27ef1a1-c9bc-453c-c487-93d66df1bde8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45327
        }
      },
      "source": [
        "# You should see both the printed X and Y approach 200 as this trains:\n",
        "# info:\n",
        "#   policy_reward_mean:\n",
        "#     dqn_policy: X\n",
        "#     ppo_policy: Y\n",
        "for i in range(num_iters):\n",
        "    print(\"== Iteration\", i, \"==\")\n",
        "\n",
        "    # improve the DQN policy\n",
        "    print(\"-- DQN --\")\n",
        "    print(pretty_print(dqn_trainer.train()))\n",
        "\n",
        "    # improve the PPO policy\n",
        "    print(\"-- PPO --\")\n",
        "    print(pretty_print(ppo_trainer.train()))\n",
        "\n",
        "    # swap weights to synchronize\n",
        "    dqn_trainer.set_weights(ppo_trainer.get_weights([\"ppo_policy\"]))\n",
        "    ppo_trainer.set_weights(dqn_trainer.get_weights([\"dqn_policy\"]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-05-19 14:13:47,632\tINFO policy_evaluator.py:438 -- Generating sample batch of size 4\n",
            "2019-05-19 14:13:47,635\tINFO sampler.py:308 -- Raw obs from env: { 0: { 0: np.ndarray((4,), dtype=float64, min=-0.047, max=0.028, mean=-0.015),\n",
            "       1: np.ndarray((4,), dtype=float64, min=-0.049, max=0.044, mean=0.003),\n",
            "       2: np.ndarray((4,), dtype=float64, min=-0.009, max=0.037, mean=0.022),\n",
            "       3: np.ndarray((4,), dtype=float64, min=-0.033, max=0.044, mean=0.005)}}\n",
            "2019-05-19 14:13:47,641\tINFO sampler.py:309 -- Info return from env: {0: {0: {}, 1: {}, 2: {}, 3: {}}}\n",
            "2019-05-19 14:13:47,644\tINFO sampler.py:407 -- Preprocessed obs: np.ndarray((4,), dtype=float64, min=-0.047, max=0.028, mean=-0.015)\n",
            "2019-05-19 14:13:47,646\tINFO sampler.py:411 -- Filtered obs: np.ndarray((4,), dtype=float64, min=-0.047, max=0.028, mean=-0.015)\n",
            "2019-05-19 14:13:47,650\tINFO sampler.py:525 -- Inputs to compute_actions():\n",
            "\n",
            "{ 'dqn_policy': [ { 'data': { 'agent_id': 1,\n",
            "                              'env_id': 0,\n",
            "                              'info': {},\n",
            "                              'obs': np.ndarray((4,), dtype=float64, min=-0.049, max=0.044, mean=0.003),\n",
            "                              'prev_action': np.ndarray((), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
            "                              'prev_reward': 0.0,\n",
            "                              'rnn_state': []},\n",
            "                    'type': 'PolicyEvalData'},\n",
            "                  { 'data': { 'agent_id': 3,\n",
            "                              'env_id': 0,\n",
            "                              'info': {},\n",
            "                              'obs': np.ndarray((4,), dtype=float64, min=-0.033, max=0.044, mean=0.005),\n",
            "                              'prev_action': np.ndarray((), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
            "                              'prev_reward': 0.0,\n",
            "                              'rnn_state': []},\n",
            "                    'type': 'PolicyEvalData'}],\n",
            "  'ppo_policy': [ { 'data': { 'agent_id': 0,\n",
            "                              'env_id': 0,\n",
            "                              'info': {},\n",
            "                              'obs': np.ndarray((4,), dtype=float64, min=-0.047, max=0.028, mean=-0.015),\n",
            "                              'prev_action': np.ndarray((), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
            "                              'prev_reward': 0.0,\n",
            "                              'rnn_state': []},\n",
            "                    'type': 'PolicyEvalData'},\n",
            "                  { 'data': { 'agent_id': 2,\n",
            "                              'env_id': 0,\n",
            "                              'info': {},\n",
            "                              'obs': np.ndarray((4,), dtype=float64, min=-0.009, max=0.037, mean=0.022),\n",
            "                              'prev_action': np.ndarray((), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
            "                              'prev_reward': 0.0,\n",
            "                              'rnn_state': []},\n",
            "                    'type': 'PolicyEvalData'}]}\n",
            "\n",
            "2019-05-19 14:13:47,652\tINFO tf_run_builder.py:92 -- Executing TF run without tracing. To dump TF timeline traces to disk, set the TF_TIMELINE_DIR environment variable.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "== Iteration 0 ==\n",
            "-- DQN --\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-05-19 14:13:47,886\tINFO sampler.py:552 -- Outputs of compute_actions():\n",
            "\n",
            "{ 'dqn_policy': ( np.ndarray((2,), dtype=int64, min=1.0, max=1.0, mean=1.0),\n",
            "                  [],\n",
            "                  { 'q_values': np.ndarray((2, 2), dtype=float32, min=0.026, max=0.042, mean=0.032)}),\n",
            "  'ppo_policy': ( np.ndarray((2,), dtype=int64, min=0.0, max=1.0, mean=0.5),\n",
            "                  [],\n",
            "                  { 'action_prob': np.ndarray((2,), dtype=float32, min=0.5, max=0.5, mean=0.5),\n",
            "                    'behaviour_logits': np.ndarray((2, 2), dtype=float32, min=-0.0, max=0.0, mean=-0.0),\n",
            "                    'vf_preds': np.ndarray((2,), dtype=float32, min=-0.0, max=0.0, mean=-0.0)})}\n",
            "\n",
            "2019-05-19 14:13:47,911\tINFO sample_batch_builder.py:161 -- Trajectory fragment after postprocess_trajectory():\n",
            "\n",
            "{ 0: { 'data': { 'action_prob': np.ndarray((4,), dtype=float32, min=0.5, max=0.5, mean=0.5),\n",
            "                 'actions': np.ndarray((4,), dtype=int64, min=0.0, max=1.0, mean=0.75),\n",
            "                 'advantages': np.ndarray((4,), dtype=float32, min=1.001, max=3.711, mean=2.379),\n",
            "                 'agent_index': np.ndarray((4,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
            "                 'behaviour_logits': np.ndarray((4, 2), dtype=float32, min=0.0, max=0.002, mean=0.001),\n",
            "                 'dones': np.ndarray((4,), dtype=bool, min=0.0, max=0.0, mean=0.0),\n",
            "                 'eps_id': np.ndarray((4,), dtype=int64, min=72380387.0, max=72380387.0, mean=72380387.0),\n",
            "                 'infos': np.ndarray((4,), dtype=object, head={}),\n",
            "                 'new_obs': np.ndarray((4, 4), dtype=float32, min=-0.632, max=0.418, mean=-0.041),\n",
            "                 'obs': np.ndarray((4, 4), dtype=float32, min=-0.337, max=0.223, mean=-0.028),\n",
            "                 'prev_actions': np.ndarray((4,), dtype=int64, min=0.0, max=1.0, mean=0.5),\n",
            "                 'prev_rewards': np.ndarray((4,), dtype=float32, min=0.0, max=1.0, mean=0.75),\n",
            "                 'rewards': np.ndarray((4,), dtype=float32, min=1.0, max=1.0, mean=1.0),\n",
            "                 't': np.ndarray((4,), dtype=int64, min=0.0, max=3.0, mean=1.5),\n",
            "                 'unroll_id': np.ndarray((4,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
            "                 'value_targets': np.ndarray((4,), dtype=float32, min=1.002, max=3.712, mean=2.38),\n",
            "                 'vf_preds': np.ndarray((4,), dtype=float32, min=0.0, max=0.001, mean=0.001)},\n",
            "       'type': 'SampleBatch'},\n",
            "  1: { 'data': { 'actions': np.ndarray((4,), dtype=int64, min=0.0, max=1.0, mean=0.25),\n",
            "                 'agent_index': np.ndarray((4,), dtype=int64, min=2.0, max=2.0, mean=2.0),\n",
            "                 'dones': np.ndarray((4,), dtype=bool, min=0.0, max=0.0, mean=0.0),\n",
            "                 'eps_id': np.ndarray((4,), dtype=int64, min=72380387.0, max=72380387.0, mean=72380387.0),\n",
            "                 'infos': np.ndarray((4,), dtype=object, head={}),\n",
            "                 'new_obs': np.ndarray((4, 4), dtype=float32, min=-0.343, max=0.517, mean=0.031),\n",
            "                 'obs': np.ndarray((4, 4), dtype=float32, min=-0.309, max=0.242, mean=-0.003),\n",
            "                 'prev_actions': np.ndarray((4,), dtype=int64, min=0.0, max=1.0, mean=0.25),\n",
            "                 'prev_rewards': np.ndarray((4,), dtype=float32, min=0.0, max=1.0, mean=0.75),\n",
            "                 'q_values': np.ndarray((4, 2), dtype=float32, min=-0.103, max=0.463, mean=0.077),\n",
            "                 'rewards': np.ndarray((4,), dtype=float32, min=1.0, max=2.852, mean=2.164),\n",
            "                 't': np.ndarray((4,), dtype=int64, min=0.0, max=3.0, mean=1.5),\n",
            "                 'unroll_id': np.ndarray((4,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
            "                 'weights': np.ndarray((4,), dtype=float32, min=1.0, max=1.0, mean=1.0)},\n",
            "       'type': 'SampleBatch'},\n",
            "  2: { 'data': { 'action_prob': np.ndarray((4,), dtype=float32, min=0.5, max=0.5, mean=0.5),\n",
            "                 'actions': np.ndarray((4,), dtype=int64, min=0.0, max=1.0, mean=0.25),\n",
            "                 'advantages': np.ndarray((4,), dtype=float32, min=0.999, max=3.708, mean=2.377),\n",
            "                 'agent_index': np.ndarray((4,), dtype=int64, min=1.0, max=1.0, mean=1.0),\n",
            "                 'behaviour_logits': np.ndarray((4, 2), dtype=float32, min=-0.002, max=-0.0, mean=-0.001),\n",
            "                 'dones': np.ndarray((4,), dtype=bool, min=0.0, max=0.0, mean=0.0),\n",
            "                 'eps_id': np.ndarray((4,), dtype=int64, min=72380387.0, max=72380387.0, mean=72380387.0),\n",
            "                 'infos': np.ndarray((4,), dtype=object, head={}),\n",
            "                 'new_obs': np.ndarray((4, 4), dtype=float32, min=-0.401, max=0.66, mean=0.052),\n",
            "                 'obs': np.ndarray((4, 4), dtype=float32, min=-0.206, max=0.356, mean=0.037),\n",
            "                 'prev_actions': np.ndarray((4,), dtype=int64, min=0.0, max=1.0, mean=0.25),\n",
            "                 'prev_rewards': np.ndarray((4,), dtype=float32, min=0.0, max=1.0, mean=0.75),\n",
            "                 'rewards': np.ndarray((4,), dtype=float32, min=1.0, max=1.0, mean=1.0),\n",
            "                 't': np.ndarray((4,), dtype=int64, min=0.0, max=3.0, mean=1.5),\n",
            "                 'unroll_id': np.ndarray((4,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
            "                 'value_targets': np.ndarray((4,), dtype=float32, min=0.998, max=3.708, mean=2.376),\n",
            "                 'vf_preds': np.ndarray((4,), dtype=float32, min=-0.001, max=-0.0, mean=-0.001)},\n",
            "       'type': 'SampleBatch'},\n",
            "  3: { 'data': { 'actions': np.ndarray((4,), dtype=int64, min=0.0, max=1.0, mean=0.25),\n",
            "                 'agent_index': np.ndarray((4,), dtype=int64, min=3.0, max=3.0, mean=3.0),\n",
            "                 'dones': np.ndarray((4,), dtype=bool, min=0.0, max=0.0, mean=0.0),\n",
            "                 'eps_id': np.ndarray((4,), dtype=int64, min=72380387.0, max=72380387.0, mean=72380387.0),\n",
            "                 'infos': np.ndarray((4,), dtype=object, head={}),\n",
            "                 'new_obs': np.ndarray((4, 4), dtype=float32, min=-0.344, max=0.575, mean=0.038),\n",
            "                 'obs': np.ndarray((4, 4), dtype=float32, min=-0.269, max=0.294, mean=0.001),\n",
            "                 'prev_actions': np.ndarray((4,), dtype=int64, min=0.0, max=1.0, mean=0.25),\n",
            "                 'prev_rewards': np.ndarray((4,), dtype=float32, min=0.0, max=1.0, mean=0.75),\n",
            "                 'q_values': np.ndarray((4, 2), dtype=float32, min=-0.065, max=0.473, mean=0.097),\n",
            "                 'rewards': np.ndarray((4,), dtype=float32, min=1.0, max=2.852, mean=2.164),\n",
            "                 't': np.ndarray((4,), dtype=int64, min=0.0, max=3.0, mean=1.5),\n",
            "                 'unroll_id': np.ndarray((4,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
            "                 'weights': np.ndarray((4,), dtype=float32, min=1.0, max=1.0, mean=1.0)},\n",
            "       'type': 'SampleBatch'}}\n",
            "\n",
            "2019-05-19 14:13:47,919\tINFO policy_evaluator.py:475 -- Completed sample batch:\n",
            "\n",
            "{ 'count': 4,\n",
            "  'policy_batches': { 'dqn_policy': { 'data': { 'actions': np.ndarray((8,), dtype=int64, min=0.0, max=1.0, mean=0.25),\n",
            "                                                'agent_index': np.ndarray((8,), dtype=int64, min=2.0, max=3.0, mean=2.5),\n",
            "                                                'dones': np.ndarray((8,), dtype=bool, min=0.0, max=0.0, mean=0.0),\n",
            "                                                'eps_id': np.ndarray((8,), dtype=int64, min=72380387.0, max=72380387.0, mean=72380387.0),\n",
            "                                                'infos': np.ndarray((8,), dtype=object, head={}),\n",
            "                                                'new_obs': np.ndarray((8, 4), dtype=float32, min=-0.344, max=0.575, mean=0.035),\n",
            "                                                'obs': np.ndarray((8, 4), dtype=float32, min=-0.309, max=0.294, mean=-0.001),\n",
            "                                                'prev_actions': np.ndarray((8,), dtype=int64, min=0.0, max=1.0, mean=0.25),\n",
            "                                                'prev_rewards': np.ndarray((8,), dtype=float32, min=0.0, max=1.0, mean=0.75),\n",
            "                                                'q_values': np.ndarray((8, 2), dtype=float32, min=-0.103, max=0.473, mean=0.087),\n",
            "                                                'rewards': np.ndarray((8,), dtype=float32, min=1.0, max=2.852, mean=2.164),\n",
            "                                                't': np.ndarray((8,), dtype=int64, min=0.0, max=3.0, mean=1.5),\n",
            "                                                'unroll_id': np.ndarray((8,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
            "                                                'weights': np.ndarray((8,), dtype=float32, min=1.0, max=1.0, mean=1.0)},\n",
            "                                      'type': 'SampleBatch'},\n",
            "                      'ppo_policy': { 'data': { 'action_prob': np.ndarray((8,), dtype=float32, min=0.5, max=0.5, mean=0.5),\n",
            "                                                'actions': np.ndarray((8,), dtype=int64, min=0.0, max=1.0, mean=0.5),\n",
            "                                                'advantages': np.ndarray((8,), dtype=float32, min=0.999, max=3.711, mean=2.378),\n",
            "                                                'agent_index': np.ndarray((8,), dtype=int64, min=0.0, max=1.0, mean=0.5),\n",
            "                                                'behaviour_logits': np.ndarray((8, 2), dtype=float32, min=-0.002, max=0.002, mean=-0.0),\n",
            "                                                'dones': np.ndarray((8,), dtype=bool, min=0.0, max=0.0, mean=0.0),\n",
            "                                                'eps_id': np.ndarray((8,), dtype=int64, min=72380387.0, max=72380387.0, mean=72380387.0),\n",
            "                                                'infos': np.ndarray((8,), dtype=object, head={}),\n",
            "                                                'new_obs': np.ndarray((8, 4), dtype=float32, min=-0.632, max=0.66, mean=0.006),\n",
            "                                                'obs': np.ndarray((8, 4), dtype=float32, min=-0.337, max=0.356, mean=0.005),\n",
            "                                                'prev_actions': np.ndarray((8,), dtype=int64, min=0.0, max=1.0, mean=0.375),\n",
            "                                                'prev_rewards': np.ndarray((8,), dtype=float32, min=0.0, max=1.0, mean=0.75),\n",
            "                                                'rewards': np.ndarray((8,), dtype=float32, min=1.0, max=1.0, mean=1.0),\n",
            "                                                't': np.ndarray((8,), dtype=int64, min=0.0, max=3.0, mean=1.5),\n",
            "                                                'unroll_id': np.ndarray((8,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
            "                                                'value_targets': np.ndarray((8,), dtype=float32, min=0.998, max=3.712, mean=2.378),\n",
            "                                                'vf_preds': np.ndarray((8,), dtype=float32, min=-0.001, max=0.001, mean=-0.0)},\n",
            "                                      'type': 'SampleBatch'}},\n",
            "  'type': 'MultiAgentBatch'}\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "custom_metrics: {}\n",
            "date: 2019-05-19_14-13-50\n",
            "done: false\n",
            "episode_len_mean: 34.67857142857143\n",
            "episode_reward_max: 147.0\n",
            "episode_reward_mean: 86.82142857142857\n",
            "episode_reward_min: 50.0\n",
            "episodes_this_iter: 28\n",
            "episodes_total: 28\n",
            "experiment_id: 15a9bb44309949c293858c3ef351adf4\n",
            "hostname: 44573652ebd5\n",
            "info:\n",
            "  grad_time_ms: .nan\n",
            "  learner: {}\n",
            "  max_exploration: 1.0\n",
            "  min_exploration: 1.0\n",
            "  num_steps_sampled: 1000\n",
            "  num_steps_trained: 0\n",
            "  num_target_updates: 1\n",
            "  opt_peak_throughput: 0.0\n",
            "  opt_samples: .nan\n",
            "  replay_time_ms: .nan\n",
            "  sample_time_ms: 9.656\n",
            "  update_time_ms: 0.002\n",
            "iterations_since_restore: 1\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 0\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 123\n",
            "policy_reward_mean:\n",
            "  dqn_policy: 21.875\n",
            "  ppo_policy: 21.535714285714285\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 0.10670862950526032\n",
            "  mean_inference_ms: 1.8492776316243575\n",
            "  mean_processing_ms: 0.7551121306824278\n",
            "time_since_restore: 3.345728635787964\n",
            "time_this_iter_s: 3.345728635787964\n",
            "time_total_s: 3.345728635787964\n",
            "timestamp: 1558275230\n",
            "timesteps_since_restore: 1000\n",
            "timesteps_this_iter: 1000\n",
            "timesteps_total: 1000\n",
            "training_iteration: 1\n",
            "\n",
            "-- PPO --\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m 2019-05-19 14:13:54,395\tINFO policy_evaluator.py:438 -- Generating sample batch of size 200\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m 2019-05-19 14:13:54,397\tINFO sampler.py:308 -- Raw obs from env: { 0: { 0: np.ndarray((4,), dtype=float64, min=-0.042, max=0.016, mean=-0.019),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m        1: np.ndarray((4,), dtype=float64, min=-0.037, max=0.047, mean=0.009),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m        2: np.ndarray((4,), dtype=float64, min=-0.046, max=0.045, mean=-0.001),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m        3: np.ndarray((4,), dtype=float64, min=-0.034, max=0.029, mean=0.007)}}\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m 2019-05-19 14:13:54,397\tINFO sampler.py:309 -- Info return from env: {0: {0: {}, 1: {}, 2: {}, 3: {}}}\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m 2019-05-19 14:13:54,397\tINFO sampler.py:407 -- Preprocessed obs: np.ndarray((4,), dtype=float64, min=-0.042, max=0.016, mean=-0.019)\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m 2019-05-19 14:13:54,398\tINFO sampler.py:411 -- Filtered obs: np.ndarray((4,), dtype=float64, min=-0.042, max=0.016, mean=-0.019)\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m 2019-05-19 14:13:54,400\tINFO sampler.py:525 -- Inputs to compute_actions():\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m { 'dqn_policy': [ { 'data': { 'agent_id': 1,\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                               'env_id': 0,\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                               'info': {},\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                               'obs': np.ndarray((4,), dtype=float64, min=-0.037, max=0.047, mean=0.009),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                               'prev_action': np.ndarray((), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                               'prev_reward': 0.0,\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                               'rnn_state': []},\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                     'type': 'PolicyEvalData'},\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                   { 'data': { 'agent_id': 3,\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                               'env_id': 0,\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                               'info': {},\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                               'obs': np.ndarray((4,), dtype=float64, min=-0.034, max=0.029, mean=0.007),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                               'prev_action': np.ndarray((), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                               'prev_reward': 0.0,\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                               'rnn_state': []},\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                     'type': 'PolicyEvalData'}],\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m   'ppo_policy': [ { 'data': { 'agent_id': 0,\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                               'env_id': 0,\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                               'info': {},\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                               'obs': np.ndarray((4,), dtype=float64, min=-0.042, max=0.016, mean=-0.019),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                               'prev_action': np.ndarray((), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                               'prev_reward': 0.0,\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                               'rnn_state': []},\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                     'type': 'PolicyEvalData'},\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                   { 'data': { 'agent_id': 2,\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                               'env_id': 0,\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                               'info': {},\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                               'obs': np.ndarray((4,), dtype=float64, min=-0.046, max=0.045, mean=-0.001),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                               'prev_action': np.ndarray((), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                               'prev_reward': 0.0,\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                               'rnn_state': []},\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                     'type': 'PolicyEvalData'}]}\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m 2019-05-19 14:13:54,400\tINFO tf_run_builder.py:92 -- Executing TF run without tracing. To dump TF timeline traces to disk, set the TF_TIMELINE_DIR environment variable.\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m 2019-05-19 14:13:54,536\tINFO sampler.py:552 -- Outputs of compute_actions():\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m { 'dqn_policy': ( np.ndarray((2,), dtype=int64, min=1.0, max=1.0, mean=1.0),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                   [],\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                   { 'q_values': np.ndarray((2, 2), dtype=float32, min=0.038, max=0.068, mean=0.051)}),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m   'ppo_policy': ( np.ndarray((2,), dtype=int64, min=1.0, max=1.0, mean=1.0),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                   [],\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                   { 'action_prob': np.ndarray((2,), dtype=float32, min=0.5, max=0.5, mean=0.5),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                     'behaviour_logits': np.ndarray((2, 2), dtype=float32, min=-0.0, max=0.0, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                     'vf_preds': np.ndarray((2,), dtype=float32, min=-0.0, max=0.001, mean=0.0)})}\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m 2019-05-19 14:13:54,780\tINFO sample_batch_builder.py:161 -- Trajectory fragment after postprocess_trajectory():\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m { 0: { 'data': { 'action_prob': np.ndarray((52,), dtype=float32, min=0.499, max=0.501, mean=0.5),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'actions': np.ndarray((52,), dtype=int64, min=0.0, max=1.0, mean=0.481),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'advantages': np.ndarray((52,), dtype=float32, min=0.999, max=40.704, mean=22.507),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'agent_index': np.ndarray((52,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'behaviour_logits': np.ndarray((52, 2), dtype=float32, min=-0.008, max=0.008, mean=-0.001),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'dones': np.ndarray((52,), dtype=bool, min=0.0, max=1.0, mean=0.019),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'eps_id': np.ndarray((52,), dtype=int64, min=1305866282.0, max=1305866282.0, mean=1305866282.0),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'infos': np.ndarray((52,), dtype=object, head={}),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'new_obs': np.ndarray((52, 4), dtype=float32, min=-1.237, max=1.208, mean=-0.057),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'obs': np.ndarray((52, 4), dtype=float32, min=-1.237, max=1.208, mean=-0.056),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'prev_actions': np.ndarray((52,), dtype=int64, min=0.0, max=1.0, mean=0.462),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'prev_rewards': np.ndarray((52,), dtype=float32, min=0.0, max=1.0, mean=0.981),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'rewards': np.ndarray((52,), dtype=float32, min=1.0, max=1.0, mean=1.0),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  't': np.ndarray((52,), dtype=int64, min=0.0, max=51.0, mean=25.5),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'unroll_id': np.ndarray((52,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'value_targets': np.ndarray((52,), dtype=float32, min=1.0, max=40.703, mean=22.507),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'vf_preds': np.ndarray((52,), dtype=float32, min=-0.002, max=0.002, mean=0.0)},\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m        'type': 'SampleBatch'},\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m   1: { 'data': { 'actions': np.ndarray((26,), dtype=int64, min=0.0, max=1.0, mean=0.5),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'agent_index': np.ndarray((26,), dtype=int64, min=2.0, max=2.0, mean=2.0),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'dones': np.ndarray((26,), dtype=bool, min=0.0, max=1.0, mean=0.038),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'eps_id': np.ndarray((26,), dtype=int64, min=1305866282.0, max=1305866282.0, mean=1305866282.0),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'infos': np.ndarray((26,), dtype=object, head={}),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'new_obs': np.ndarray((26, 4), dtype=float32, min=-0.97, max=0.211, mean=-0.084),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'obs': np.ndarray((26, 4), dtype=float32, min=-0.97, max=0.211, mean=-0.076),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'prev_actions': np.ndarray((26,), dtype=int64, min=0.0, max=1.0, mean=0.5),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'prev_rewards': np.ndarray((26,), dtype=float32, min=0.0, max=1.0, mean=0.962),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'q_values': np.ndarray((26, 2), dtype=float32, min=0.047, max=0.519, mean=0.218),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'rewards': np.ndarray((26,), dtype=float32, min=1.0, max=1.0, mean=1.0),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  't': np.ndarray((26,), dtype=int64, min=0.0, max=25.0, mean=12.5),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'unroll_id': np.ndarray((26,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'weights': np.ndarray((26,), dtype=float32, min=1.0, max=1.0, mean=1.0)},\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m        'type': 'SampleBatch'},\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m   2: { 'data': { 'action_prob': np.ndarray((30,), dtype=float32, min=0.499, max=0.501, mean=0.5),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'actions': np.ndarray((30,), dtype=int64, min=0.0, max=1.0, mean=0.467),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'advantages': np.ndarray((30,), dtype=float32, min=0.999, max=26.029, mean=14.1),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'agent_index': np.ndarray((30,), dtype=int64, min=1.0, max=1.0, mean=1.0),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'behaviour_logits': np.ndarray((30, 2), dtype=float32, min=-0.008, max=0.003, mean=-0.002),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'dones': np.ndarray((30,), dtype=bool, min=0.0, max=1.0, mean=0.033),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'eps_id': np.ndarray((30,), dtype=int64, min=1305866282.0, max=1305866282.0, mean=1305866282.0),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'infos': np.ndarray((30,), dtype=object, head={}),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'new_obs': np.ndarray((30, 4), dtype=float32, min=-0.768, max=1.137, mean=0.04),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'obs': np.ndarray((30, 4), dtype=float32, min=-0.768, max=1.137, mean=0.034),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'prev_actions': np.ndarray((30,), dtype=int64, min=0.0, max=1.0, mean=0.467),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'prev_rewards': np.ndarray((30,), dtype=float32, min=0.0, max=1.0, mean=0.967),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'rewards': np.ndarray((30,), dtype=float32, min=1.0, max=1.0, mean=1.0),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  't': np.ndarray((30,), dtype=int64, min=0.0, max=29.0, mean=14.5),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'unroll_id': np.ndarray((30,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'value_targets': np.ndarray((30,), dtype=float32, min=1.0, max=26.03, mean=14.101),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'vf_preds': np.ndarray((30,), dtype=float32, min=-0.0, max=0.002, mean=0.001)},\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m        'type': 'SampleBatch'},\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m   3: { 'data': { 'actions': np.ndarray((44,), dtype=int64, min=0.0, max=1.0, mean=0.386),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'agent_index': np.ndarray((44,), dtype=int64, min=3.0, max=3.0, mean=3.0),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'dones': np.ndarray((44,), dtype=bool, min=0.0, max=1.0, mean=0.023),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'eps_id': np.ndarray((44,), dtype=int64, min=1305866282.0, max=1305866282.0, mean=1305866282.0),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'infos': np.ndarray((44,), dtype=object, head={}),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'new_obs': np.ndarray((44, 4), dtype=float32, min=-1.941, max=3.161, mean=0.051),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'obs': np.ndarray((44, 4), dtype=float32, min=-1.745, max=2.814, mean=0.043),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'prev_actions': np.ndarray((44,), dtype=int64, min=0.0, max=1.0, mean=0.386),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'prev_rewards': np.ndarray((44,), dtype=float32, min=0.0, max=1.0, mean=0.977),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'q_values': np.ndarray((44, 2), dtype=float32, min=0.033, max=1.298, mean=0.29),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'rewards': np.ndarray((44,), dtype=float32, min=1.0, max=1.0, mean=1.0),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  't': np.ndarray((44,), dtype=int64, min=0.0, max=43.0, mean=21.5),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'unroll_id': np.ndarray((44,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                  'weights': np.ndarray((44,), dtype=float32, min=1.0, max=1.0, mean=1.0)},\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m        'type': 'SampleBatch'}}\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m 2019-05-19 14:13:55,169\tINFO policy_evaluator.py:475 -- Completed sample batch:\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m { 'count': 200,\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m   'policy_batches': { 'dqn_policy': { 'data': { 'actions': np.ndarray((192,), dtype=int64, min=0.0, max=1.0, mean=0.401),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                                                 'agent_index': np.ndarray((192,), dtype=int64, min=2.0, max=3.0, mean=2.766),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                                                 'dones': np.ndarray((192,), dtype=bool, min=0.0, max=1.0, mean=0.026),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                                                 'eps_id': np.ndarray((192,), dtype=int64, min=469100409.0, max=1305866282.0, mean=1209049137.531),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                                                 'infos': np.ndarray((192,), dtype=object, head={}),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                                                 'new_obs': np.ndarray((192, 4), dtype=float32, min=-1.941, max=3.161, mean=0.028),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                                                 'obs': np.ndarray((192, 4), dtype=float32, min=-1.745, max=2.814, mean=0.023),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                                                 'prev_actions': np.ndarray((192,), dtype=int64, min=0.0, max=1.0, mean=0.401),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                                                 'prev_rewards': np.ndarray((192,), dtype=float32, min=0.0, max=1.0, mean=0.969),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                                                 'q_values': np.ndarray((192, 2), dtype=float32, min=0.003, max=1.317, mean=0.297),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                                                 'rewards': np.ndarray((192,), dtype=float32, min=1.0, max=1.0, mean=1.0),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                                                 't': np.ndarray((192,), dtype=int64, min=0.0, max=93.0, mean=29.995),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                                                 'unroll_id': np.ndarray((192,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                                                 'weights': np.ndarray((192,), dtype=float32, min=1.0, max=1.0, mean=1.0)},\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                                       'type': 'SampleBatch'},\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                       'ppo_policy': { 'data': { 'action_prob': np.ndarray((175,), dtype=float32, min=0.498, max=0.502, mean=0.5),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                                                 'actions': np.ndarray((175,), dtype=int64, min=0.0, max=1.0, mean=0.48),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                                                 'advantages': np.ndarray((175,), dtype=float32, min=0.997, max=41.884, mean=17.901),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                                                 'agent_index': np.ndarray((175,), dtype=int64, min=0.0, max=1.0, mean=0.337),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                                                 'behaviour_logits': np.ndarray((175, 2), dtype=float32, min=-0.009, max=0.009, mean=-0.001),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                                                 'dones': np.ndarray((175,), dtype=bool, min=0.0, max=1.0, mean=0.034),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                                                 'eps_id': np.ndarray((175,), dtype=int64, min=469100409.0, max=1305866282.0, mean=952939434.291),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                                                 'infos': np.ndarray((175,), dtype=object, head={}),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                                                 'new_obs': np.ndarray((175, 4), dtype=float32, min=-2.039, max=1.7, mean=0.027),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                                                 'obs': np.ndarray((175, 4), dtype=float32, min=-1.696, max=1.7, mean=0.024),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                                                 'prev_actions': np.ndarray((175,), dtype=int64, min=0.0, max=1.0, mean=0.457),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                                                 'prev_rewards': np.ndarray((175,), dtype=float32, min=0.0, max=1.0, mean=0.966),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                                                 'rewards': np.ndarray((175,), dtype=float32, min=1.0, max=1.0, mean=1.0),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                                                 't': np.ndarray((175,), dtype=int64, min=0.0, max=53.0, mean=19.731),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                                                 'unroll_id': np.ndarray((175,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                                                 'value_targets': np.ndarray((175,), dtype=float32, min=1.0, max=41.883, mean=17.902),\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                                                 'vf_preds': np.ndarray((175,), dtype=float32, min=-0.003, max=0.003, mean=0.0)},\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m                                       'type': 'SampleBatch'}},\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m   'type': 'MultiAgentBatch'}\n",
            "\u001b[2m\u001b[36m(pid=11718)\u001b[0m \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-05-19 14:13:59,544\tINFO multi_gpu_impl.py:146 -- Training on concatenated sample batches:\n",
            "\n",
            "{ 'inputs': [ np.ndarray((4674,), dtype=int64, min=0.0, max=1.0, mean=0.493),\n",
            "              np.ndarray((4674,), dtype=float32, min=0.0, max=1.0, mean=0.955),\n",
            "              np.ndarray((4674, 4), dtype=float32, min=-2.844, max=2.871, mean=0.002),\n",
            "              np.ndarray((4674,), dtype=int64, min=0.0, max=1.0, mean=0.514),\n",
            "              np.ndarray((4674,), dtype=float32, min=-1.283, max=4.432, mean=0.0),\n",
            "              np.ndarray((4674, 2), dtype=float32, min=-0.01, max=0.01, mean=0.0),\n",
            "              np.ndarray((4674,), dtype=float32, min=0.999, max=53.412, mean=12.765),\n",
            "              np.ndarray((4674,), dtype=float32, min=-0.005, max=0.005, mean=-0.0)],\n",
            "  'placeholders': [ <tf.Tensor 'ppo_policy/action:0' shape=(?,) dtype=int64>,\n",
            "                    <tf.Tensor 'ppo_policy/prev_reward:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'ppo_policy/observation:0' shape=(?, 4) dtype=float32>,\n",
            "                    <tf.Tensor 'ppo_policy/actions:0' shape=(?,) dtype=int64>,\n",
            "                    <tf.Tensor 'ppo_policy/advantages:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'ppo_policy/behaviour_logits:0' shape=(?, 2) dtype=float32>,\n",
            "                    <tf.Tensor 'ppo_policy/value_targets:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'ppo_policy/vf_preds:0' shape=(?,) dtype=float32>],\n",
            "  'state_inputs': []}\n",
            "\n",
            "2019-05-19 14:13:59,546\tINFO multi_gpu_impl.py:191 -- Divided 4674 rollout sequences, each of length 1, among 1 devices.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "custom_metrics: {}\n",
            "date: 2019-05-19_14-14-08\n",
            "done: false\n",
            "episode_len_mean: 38.71568627450981\n",
            "episode_reward_max: 208.0\n",
            "episode_reward_mean: 85.72549019607843\n",
            "episode_reward_min: 40.0\n",
            "episodes_this_iter: 102\n",
            "episodes_total: 102\n",
            "experiment_id: a4bfe1eb1cbb431bbf10d96dc753816f\n",
            "hostname: 44573652ebd5\n",
            "info:\n",
            "  grad_time_ms: 9091.688\n",
            "  learner:\n",
            "    ppo_policy:\n",
            "      cur_kl_coeff: 0.19999998807907104\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 0.6632583141326904\n",
            "      kl: 0.030282454565167427\n",
            "      policy_loss: -0.04262179508805275\n",
            "      total_loss: 90.29634857177734\n",
            "      vf_explained_var: 0.14817292988300323\n",
            "      vf_loss: 90.33291625976562\n",
            "  load_time_ms: 101.647\n",
            "  num_steps_sampled: 4000\n",
            "  num_steps_trained: 4608\n",
            "  sample_time_ms: 5291.572\n",
            "  update_time_ms: 3096.36\n",
            "iterations_since_restore: 1\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 123\n",
            "policy_reward_mean:\n",
            "  dqn_policy: 20.230392156862745\n",
            "  ppo_policy: 22.63235294117647\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 0.11393835732165214\n",
            "  mean_inference_ms: 2.0037346484969474\n",
            "  mean_processing_ms: 0.3759879075153047\n",
            "time_since_restore: 17.70123314857483\n",
            "time_this_iter_s: 17.70123314857483\n",
            "time_total_s: 17.70123314857483\n",
            "timestamp: 1558275248\n",
            "timesteps_since_restore: 4000\n",
            "timesteps_this_iter: 4000\n",
            "timesteps_total: 4000\n",
            "training_iteration: 1\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-05-19 14:14:09,971\tINFO policy_evaluator.py:565 -- Training on concatenated sample batches:\n",
            "\n",
            "{ 'count': 32,\n",
            "  'policy_batches': { 'dqn_policy': { 'data': { 'actions': np.ndarray((32,), dtype=int64, min=0.0, max=1.0, mean=0.469),\n",
            "                                                'batch_indexes': np.ndarray((32,), dtype=int64, min=17.0, max=1199.0, mean=630.531),\n",
            "                                                'dones': np.ndarray((32,), dtype=bool, min=0.0, max=1.0, mean=0.125),\n",
            "                                                'new_obs': np.ndarray((32, 4), dtype=float32, min=-2.331, max=1.388, mean=-0.049),\n",
            "                                                'obs': np.ndarray((32, 4), dtype=float32, min=-1.982, max=1.249, mean=-0.039),\n",
            "                                                'rewards': np.ndarray((32,), dtype=float32, min=1.0, max=2.852, mean=2.164),\n",
            "                                                'weights': np.ndarray((32,), dtype=float64, min=1.0, max=1.0, mean=1.0)},\n",
            "                                      'type': 'SampleBatch'},\n",
            "                      'ppo_policy': { 'data': { 'actions': np.ndarray((32,), dtype=int64, min=0.0, max=1.0, mean=0.625),\n",
            "                                                'batch_indexes': np.ndarray((32,), dtype=int64, min=26.0, max=1243.0, mean=665.031),\n",
            "                                                'dones': np.ndarray((32,), dtype=bool, min=0.0, max=1.0, mean=0.031),\n",
            "                                                'new_obs': np.ndarray((32, 4), dtype=float32, min=-1.434, max=1.909, mean=-0.008),\n",
            "                                                'obs': np.ndarray((32, 4), dtype=float32, min=-1.497, max=1.563, mean=-0.001),\n",
            "                                                'rewards': np.ndarray((32,), dtype=float32, min=1.0, max=1.0, mean=1.0),\n",
            "                                                'weights': np.ndarray((32,), dtype=float64, min=1.0, max=1.0, mean=1.0)},\n",
            "                                      'type': 'SampleBatch'}},\n",
            "  'type': 'MultiAgentBatch'}\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "== Iteration 1 ==\n",
            "-- DQN --\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-05-19 14:14:10,233\tINFO policy_evaluator.py:587 -- Training output:\n",
            "\n",
            "{ 'dqn_policy': { 'learner_stats': { 'cur_lr': 0.0005000000237487257,\n",
            "                                     'max_q': 1.1783957,\n",
            "                                     'mean_q': 0.13968769,\n",
            "                                     'mean_td_error': -2.2150373,\n",
            "                                     'min_q': -0.3040439,\n",
            "                                     'model': {}},\n",
            "                  'td_error': np.ndarray((32,), dtype=float32, min=-3.565, max=-0.607, mean=-2.215)}}\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "custom_metrics: {}\n",
            "date: 2019-05-19_14-14-17\n",
            "done: false\n",
            "episode_len_mean: 43.108695652173914\n",
            "episode_reward_max: 196.0\n",
            "episode_reward_mean: 98.91304347826087\n",
            "episode_reward_min: 50.0\n",
            "episodes_this_iter: 18\n",
            "episodes_total: 46\n",
            "experiment_id: 15a9bb44309949c293858c3ef351adf4\n",
            "hostname: 44573652ebd5\n",
            "info:\n",
            "  grad_time_ms: 10.871\n",
            "  learner:\n",
            "    dqn_policy:\n",
            "      cur_lr: 0.0005000000237487257\n",
            "      max_q: 5.458551406860352\n",
            "      mean_q: 4.397507190704346\n",
            "      mean_td_error: 0.17537327110767365\n",
            "      min_q: 2.0352535247802734\n",
            "      model: {}\n",
            "  max_exploration: 0.902\n",
            "  min_exploration: 0.902\n",
            "  num_steps_sampled: 2000\n",
            "  num_steps_trained: 8000\n",
            "  num_target_updates: 3\n",
            "  opt_peak_throughput: 2943.694\n",
            "  opt_samples: 32.0\n",
            "  replay_time_ms: 7.406\n",
            "  sample_time_ms: 11.561\n",
            "  update_time_ms: 0.002\n",
            "iterations_since_restore: 2\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 0\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 123\n",
            "policy_reward_mean:\n",
            "  dqn_policy: 20.554347826086957\n",
            "  ppo_policy: 28.902173913043477\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 0.10597409801661595\n",
            "  mean_inference_ms: 1.7534468106482712\n",
            "  mean_processing_ms: 0.7522142828482299\n",
            "time_since_restore: 10.820792198181152\n",
            "time_this_iter_s: 7.4750635623931885\n",
            "time_total_s: 10.820792198181152\n",
            "timestamp: 1558275257\n",
            "timesteps_since_restore: 2000\n",
            "timesteps_this_iter: 1000\n",
            "timesteps_total: 2000\n",
            "training_iteration: 2\n",
            "\n",
            "-- PPO --\n",
            "custom_metrics: {}\n",
            "date: 2019-05-19_14-14-26\n",
            "done: false\n",
            "episode_len_mean: 65.8\n",
            "episode_reward_max: 519.0\n",
            "episode_reward_mean: 149.18\n",
            "episode_reward_min: 40.0\n",
            "episodes_this_iter: 22\n",
            "episodes_total: 124\n",
            "experiment_id: a4bfe1eb1cbb431bbf10d96dc753816f\n",
            "hostname: 44573652ebd5\n",
            "info:\n",
            "  grad_time_ms: 6372.606\n",
            "  learner:\n",
            "    ppo_policy:\n",
            "      cur_kl_coeff: 0.30000001192092896\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 0.6066855192184448\n",
            "      kl: 0.022204911336302757\n",
            "      policy_loss: -0.03725944086909294\n",
            "      total_loss: 263.2908935546875\n",
            "      vf_explained_var: 0.12717337906360626\n",
            "      vf_loss: 263.3215026855469\n",
            "  load_time_ms: 51.323\n",
            "  num_steps_sampled: 8000\n",
            "  num_steps_trained: 6656\n",
            "  sample_time_ms: 5165.598\n",
            "  update_time_ms: 1556.057\n",
            "iterations_since_restore: 2\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 123\n",
            "policy_reward_mean:\n",
            "  dqn_policy: 47.88\n",
            "  ppo_policy: 26.71\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 0.11517620261734535\n",
            "  mean_inference_ms: 2.001024107943366\n",
            "  mean_processing_ms: 0.3673456112998632\n",
            "time_since_restore: 26.42138123512268\n",
            "time_this_iter_s: 8.720148086547852\n",
            "time_total_s: 26.42138123512268\n",
            "timestamp: 1558275266\n",
            "timesteps_since_restore: 8000\n",
            "timesteps_this_iter: 4000\n",
            "timesteps_total: 8000\n",
            "training_iteration: 2\n",
            "\n",
            "== Iteration 2 ==\n",
            "-- DQN --\n",
            "custom_metrics: {}\n",
            "date: 2019-05-19_14-14-33\n",
            "done: false\n",
            "episode_len_mean: 53.735849056603776\n",
            "episode_reward_max: 457.0\n",
            "episode_reward_mean: 123.11320754716981\n",
            "episode_reward_min: 50.0\n",
            "episodes_this_iter: 7\n",
            "episodes_total: 53\n",
            "experiment_id: 15a9bb44309949c293858c3ef351adf4\n",
            "hostname: 44573652ebd5\n",
            "info:\n",
            "  grad_time_ms: 11.103\n",
            "  learner:\n",
            "    dqn_policy:\n",
            "      cur_lr: 0.0005000000237487257\n",
            "      max_q: 8.324807167053223\n",
            "      mean_q: 6.50535774230957\n",
            "      mean_td_error: 0.5911341309547424\n",
            "      min_q: 2.8321914672851562\n",
            "      model: {}\n",
            "  max_exploration: 0.804\n",
            "  min_exploration: 0.804\n",
            "  num_steps_sampled: 3000\n",
            "  num_steps_trained: 16000\n",
            "  num_target_updates: 5\n",
            "  opt_peak_throughput: 2882.046\n",
            "  opt_samples: 32.0\n",
            "  replay_time_ms: 7.178\n",
            "  sample_time_ms: 8.571\n",
            "  update_time_ms: 0.002\n",
            "iterations_since_restore: 3\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 0\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 123\n",
            "policy_reward_mean:\n",
            "  dqn_policy: 22.41509433962264\n",
            "  ppo_policy: 39.14150943396226\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 0.10585069881439212\n",
            "  mean_inference_ms: 1.72223398553862\n",
            "  mean_processing_ms: 0.7547524237402934\n",
            "time_since_restore: 18.1165189743042\n",
            "time_this_iter_s: 7.295726776123047\n",
            "time_total_s: 18.1165189743042\n",
            "timestamp: 1558275273\n",
            "timesteps_since_restore: 3000\n",
            "timesteps_this_iter: 1000\n",
            "timesteps_total: 3000\n",
            "training_iteration: 3\n",
            "\n",
            "-- PPO --\n",
            "custom_metrics: {}\n",
            "date: 2019-05-19_14-14-48\n",
            "done: false\n",
            "episode_len_mean: 97.36\n",
            "episode_reward_max: 519.0\n",
            "episode_reward_mean: 200.52\n",
            "episode_reward_min: 40.0\n",
            "episodes_this_iter: 32\n",
            "episodes_total: 156\n",
            "experiment_id: a4bfe1eb1cbb431bbf10d96dc753816f\n",
            "hostname: 44573652ebd5\n",
            "info:\n",
            "  grad_time_ms: 7750.064\n",
            "  learner:\n",
            "    ppo_policy:\n",
            "      cur_kl_coeff: 0.4500001072883606\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 0.5787159204483032\n",
            "      kl: 0.008435333147644997\n",
            "      policy_loss: -0.014375523664057255\n",
            "      total_loss: 551.9511108398438\n",
            "      vf_explained_var: 0.16111992299556732\n",
            "      vf_loss: 551.961669921875\n",
            "  load_time_ms: 34.725\n",
            "  num_steps_sampled: 12000\n",
            "  num_steps_trained: 12544\n",
            "  sample_time_ms: 4836.412\n",
            "  update_time_ms: 1045.448\n",
            "iterations_since_restore: 3\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 123\n",
            "policy_reward_mean:\n",
            "  dqn_policy: 50.915\n",
            "  ppo_policy: 49.345\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 0.11480683973339993\n",
            "  mean_inference_ms: 1.9577989257106578\n",
            "  mean_processing_ms: 0.35242243808989826\n",
            "time_since_restore: 41.143805503845215\n",
            "time_this_iter_s: 14.722424268722534\n",
            "time_total_s: 41.143805503845215\n",
            "timestamp: 1558275288\n",
            "timesteps_since_restore: 12000\n",
            "timesteps_this_iter: 4000\n",
            "timesteps_total: 12000\n",
            "training_iteration: 3\n",
            "\n",
            "== Iteration 3 ==\n",
            "-- DQN --\n",
            "custom_metrics: {}\n",
            "date: 2019-05-19_14-14-55\n",
            "done: false\n",
            "episode_len_mean: 67.23728813559322\n",
            "episode_reward_max: 567.0\n",
            "episode_reward_mean: 156.08474576271186\n",
            "episode_reward_min: 50.0\n",
            "episodes_this_iter: 6\n",
            "episodes_total: 59\n",
            "experiment_id: 15a9bb44309949c293858c3ef351adf4\n",
            "hostname: 44573652ebd5\n",
            "info:\n",
            "  grad_time_ms: 10.822\n",
            "  learner:\n",
            "    dqn_policy:\n",
            "      cur_lr: 0.0005000000237487257\n",
            "      max_q: 9.997117042541504\n",
            "      mean_q: 8.034812927246094\n",
            "      mean_td_error: 0.47781407833099365\n",
            "      min_q: 2.7867860794067383\n",
            "      model: {}\n",
            "  max_exploration: 0.706\n",
            "  min_exploration: 0.706\n",
            "  num_steps_sampled: 4000\n",
            "  num_steps_trained: 24000\n",
            "  num_target_updates: 7\n",
            "  opt_peak_throughput: 2956.82\n",
            "  opt_samples: 32.0\n",
            "  replay_time_ms: 7.364\n",
            "  sample_time_ms: 13.608\n",
            "  update_time_ms: 0.002\n",
            "iterations_since_restore: 4\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 0\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 123\n",
            "policy_reward_mean:\n",
            "  dqn_policy: 26.550847457627118\n",
            "  ppo_policy: 51.49152542372882\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 0.1058854224200807\n",
            "  mean_inference_ms: 1.698463141533414\n",
            "  mean_processing_ms: 0.757769593437058\n",
            "time_since_restore: 25.523558855056763\n",
            "time_this_iter_s: 7.4070398807525635\n",
            "time_total_s: 25.523558855056763\n",
            "timestamp: 1558275295\n",
            "timesteps_since_restore: 4000\n",
            "timesteps_this_iter: 1000\n",
            "timesteps_total: 4000\n",
            "training_iteration: 4\n",
            "\n",
            "-- PPO --\n",
            "custom_metrics: {}\n",
            "date: 2019-05-19_14-15-13\n",
            "done: false\n",
            "episode_len_mean: 129.76\n",
            "episode_reward_max: 798.0\n",
            "episode_reward_mean: 320.38\n",
            "episode_reward_min: 45.0\n",
            "episodes_this_iter: 20\n",
            "episodes_total: 176\n",
            "experiment_id: a4bfe1eb1cbb431bbf10d96dc753816f\n",
            "hostname: 44573652ebd5\n",
            "info:\n",
            "  grad_time_ms: 8562.532\n",
            "  learner:\n",
            "    ppo_policy:\n",
            "      cur_kl_coeff: 0.4500001072883606\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 0.5608354210853577\n",
            "      kl: 0.006002489477396011\n",
            "      policy_loss: -0.007887435145676136\n",
            "      total_loss: 461.4529724121094\n",
            "      vf_explained_var: 0.3500455617904663\n",
            "      vf_loss: 461.45806884765625\n",
            "  load_time_ms: 26.301\n",
            "  num_steps_sampled: 16000\n",
            "  num_steps_trained: 18560\n",
            "  sample_time_ms: 5286.306\n",
            "  update_time_ms: 788.01\n",
            "iterations_since_restore: 4\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 123\n",
            "policy_reward_mean:\n",
            "  dqn_policy: 85.095\n",
            "  ppo_policy: 75.095\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 0.11731058437340676\n",
            "  mean_inference_ms: 1.9747575630252014\n",
            "  mean_processing_ms: 0.35434659785394274\n",
            "time_since_restore: 58.80973482131958\n",
            "time_this_iter_s: 17.665929317474365\n",
            "time_total_s: 58.80973482131958\n",
            "timestamp: 1558275313\n",
            "timesteps_since_restore: 16000\n",
            "timesteps_this_iter: 4000\n",
            "timesteps_total: 16000\n",
            "training_iteration: 4\n",
            "\n",
            "== Iteration 4 ==\n",
            "-- DQN --\n",
            "custom_metrics: {}\n",
            "date: 2019-05-19_14-15-20\n",
            "done: false\n",
            "episode_len_mean: 77.0\n",
            "episode_reward_max: 567.0\n",
            "episode_reward_mean: 179.0\n",
            "episode_reward_min: 50.0\n",
            "episodes_this_iter: 5\n",
            "episodes_total: 64\n",
            "experiment_id: 15a9bb44309949c293858c3ef351adf4\n",
            "hostname: 44573652ebd5\n",
            "info:\n",
            "  grad_time_ms: 10.719\n",
            "  learner:\n",
            "    dqn_policy:\n",
            "      cur_lr: 0.0005000000237487257\n",
            "      max_q: 12.255966186523438\n",
            "      mean_q: 8.876020431518555\n",
            "      mean_td_error: 0.16500094532966614\n",
            "      min_q: 0.6584145426750183\n",
            "      model: {}\n",
            "  max_exploration: 0.608\n",
            "  min_exploration: 0.608\n",
            "  num_steps_sampled: 5000\n",
            "  num_steps_trained: 32000\n",
            "  num_target_updates: 9\n",
            "  opt_peak_throughput: 2985.243\n",
            "  opt_samples: 32.0\n",
            "  replay_time_ms: 7.684\n",
            "  sample_time_ms: 9.923\n",
            "  update_time_ms: 0.002\n",
            "iterations_since_restore: 5\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 0\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 123\n",
            "policy_reward_mean:\n",
            "  dqn_policy: 27.703125\n",
            "  ppo_policy: 61.796875\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 0.10596956224822399\n",
            "  mean_inference_ms: 1.679592540084333\n",
            "  mean_processing_ms: 0.7610616725491949\n",
            "time_since_restore: 32.94777512550354\n",
            "time_this_iter_s: 7.424216270446777\n",
            "time_total_s: 32.94777512550354\n",
            "timestamp: 1558275320\n",
            "timesteps_since_restore: 5000\n",
            "timesteps_this_iter: 1000\n",
            "timesteps_total: 5000\n",
            "training_iteration: 5\n",
            "\n",
            "-- PPO --\n",
            "custom_metrics: {}\n",
            "date: 2019-05-19_14-15-40\n",
            "done: false\n",
            "episode_len_mean: 159.96\n",
            "episode_reward_max: 798.0\n",
            "episode_reward_mean: 441.68\n",
            "episode_reward_min: 56.0\n",
            "episodes_this_iter: 20\n",
            "episodes_total: 196\n",
            "experiment_id: a4bfe1eb1cbb431bbf10d96dc753816f\n",
            "hostname: 44573652ebd5\n",
            "info:\n",
            "  grad_time_ms: 9451.424\n",
            "  learner:\n",
            "    ppo_policy:\n",
            "      cur_kl_coeff: 0.4500001072883606\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 0.5779649019241333\n",
            "      kl: 0.0028022434562444687\n",
            "      policy_loss: -0.004148381762206554\n",
            "      total_loss: 276.87103271484375\n",
            "      vf_explained_var: 0.5354129672050476\n",
            "      vf_loss: 276.8739318847656\n",
            "  load_time_ms: 21.28\n",
            "  num_steps_sampled: 20000\n",
            "  num_steps_trained: 25600\n",
            "  sample_time_ms: 5544.264\n",
            "  update_time_ms: 633.514\n",
            "iterations_since_restore: 5\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 123\n",
            "policy_reward_mean:\n",
            "  dqn_policy: 115.675\n",
            "  ppo_policy: 105.165\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 0.1214013715371701\n",
            "  mean_inference_ms: 2.0098905609642648\n",
            "  mean_processing_ms: 0.3621063604071078\n",
            "time_since_restore: 78.42412757873535\n",
            "time_this_iter_s: 19.61439275741577\n",
            "time_total_s: 78.42412757873535\n",
            "timestamp: 1558275340\n",
            "timesteps_since_restore: 20000\n",
            "timesteps_this_iter: 4000\n",
            "timesteps_total: 20000\n",
            "training_iteration: 5\n",
            "\n",
            "== Iteration 5 ==\n",
            "-- DQN --\n",
            "custom_metrics: {}\n",
            "date: 2019-05-19_14-15-48\n",
            "done: false\n",
            "episode_len_mean: 85.3768115942029\n",
            "episode_reward_max: 588.0\n",
            "episode_reward_mean: 202.5072463768116\n",
            "episode_reward_min: 50.0\n",
            "episodes_this_iter: 5\n",
            "episodes_total: 69\n",
            "experiment_id: 15a9bb44309949c293858c3ef351adf4\n",
            "hostname: 44573652ebd5\n",
            "info:\n",
            "  grad_time_ms: 10.952\n",
            "  learner:\n",
            "    dqn_policy:\n",
            "      cur_lr: 0.0005000000237487257\n",
            "      max_q: 12.109553337097168\n",
            "      mean_q: 9.664398193359375\n",
            "      mean_td_error: -0.4036151170730591\n",
            "      min_q: 0.750007688999176\n",
            "      model: {}\n",
            "  max_exploration: 0.51\n",
            "  min_exploration: 0.51\n",
            "  num_steps_sampled: 6000\n",
            "  num_steps_trained: 40000\n",
            "  num_target_updates: 11\n",
            "  opt_peak_throughput: 2921.829\n",
            "  opt_samples: 32.0\n",
            "  replay_time_ms: 7.248\n",
            "  sample_time_ms: 14.622\n",
            "  update_time_ms: 0.002\n",
            "iterations_since_restore: 6\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 0\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 123\n",
            "policy_reward_mean:\n",
            "  dqn_policy: 30.557971014492754\n",
            "  ppo_policy: 70.69565217391305\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 0.10616046161175509\n",
            "  mean_inference_ms: 1.663516241763959\n",
            "  mean_processing_ms: 0.7653012800315306\n",
            "time_since_restore: 40.62716794013977\n",
            "time_this_iter_s: 7.6793928146362305\n",
            "time_total_s: 40.62716794013977\n",
            "timestamp: 1558275348\n",
            "timesteps_since_restore: 6000\n",
            "timesteps_this_iter: 1000\n",
            "timesteps_total: 6000\n",
            "training_iteration: 6\n",
            "\n",
            "-- PPO --\n",
            "custom_metrics: {}\n",
            "date: 2019-05-19_14-16-07\n",
            "done: false\n",
            "episode_len_mean: 173.0\n",
            "episode_reward_max: 798.0\n",
            "episode_reward_mean: 491.78\n",
            "episode_reward_min: 94.0\n",
            "episodes_this_iter: 20\n",
            "episodes_total: 216\n",
            "experiment_id: a4bfe1eb1cbb431bbf10d96dc753816f\n",
            "hostname: 44573652ebd5\n",
            "info:\n",
            "  grad_time_ms: 10131.433\n",
            "  learner:\n",
            "    ppo_policy:\n",
            "      cur_kl_coeff: 0.2250000238418579\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 0.5484305024147034\n",
            "      kl: 0.004733589012175798\n",
            "      policy_loss: -0.0029542173724621534\n",
            "      total_loss: 241.52879333496094\n",
            "      vf_explained_var: 0.6181106567382812\n",
            "      vf_loss: 241.53070068359375\n",
            "  load_time_ms: 18.004\n",
            "  num_steps_sampled: 24000\n",
            "  num_steps_trained: 33024\n",
            "  sample_time_ms: 5509.926\n",
            "  update_time_ms: 531.653\n",
            "iterations_since_restore: 6\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 123\n",
            "policy_reward_mean:\n",
            "  dqn_policy: 110.885\n",
            "  ppo_policy: 135.005\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 0.12428031504171894\n",
            "  mean_inference_ms: 2.0349567519372265\n",
            "  mean_processing_ms: 0.3728838744473924\n",
            "time_since_restore: 97.33309769630432\n",
            "time_this_iter_s: 18.90897011756897\n",
            "time_total_s: 97.33309769630432\n",
            "timestamp: 1558275367\n",
            "timesteps_since_restore: 24000\n",
            "timesteps_this_iter: 4000\n",
            "timesteps_total: 24000\n",
            "training_iteration: 6\n",
            "\n",
            "== Iteration 6 ==\n",
            "-- DQN --\n",
            "custom_metrics: {}\n",
            "date: 2019-05-19_14-16-15\n",
            "done: false\n",
            "episode_len_mean: 92.86486486486487\n",
            "episode_reward_max: 687.0\n",
            "episode_reward_mean: 229.28378378378378\n",
            "episode_reward_min: 50.0\n",
            "episodes_this_iter: 5\n",
            "episodes_total: 74\n",
            "experiment_id: 15a9bb44309949c293858c3ef351adf4\n",
            "hostname: 44573652ebd5\n",
            "info:\n",
            "  grad_time_ms: 11.248\n",
            "  learner:\n",
            "    dqn_policy:\n",
            "      cur_lr: 0.0005000000237487257\n",
            "      max_q: 14.104368209838867\n",
            "      mean_q: 11.234687805175781\n",
            "      mean_td_error: 0.3904052972793579\n",
            "      min_q: 1.6919124126434326\n",
            "      model: {}\n",
            "  max_exploration: 0.41200000000000003\n",
            "  min_exploration: 0.41200000000000003\n",
            "  num_steps_sampled: 7000\n",
            "  num_steps_trained: 48000\n",
            "  num_target_updates: 13\n",
            "  opt_peak_throughput: 2844.825\n",
            "  opt_samples: 32.0\n",
            "  replay_time_ms: 7.427\n",
            "  sample_time_ms: 16.238\n",
            "  update_time_ms: 0.002\n",
            "iterations_since_restore: 7\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 0\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 123\n",
            "policy_reward_mean:\n",
            "  dqn_policy: 35.682432432432435\n",
            "  ppo_policy: 78.95945945945945\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 0.10652914534342742\n",
            "  mean_inference_ms: 1.6512620920154486\n",
            "  mean_processing_ms: 0.7705402414255266\n",
            "time_since_restore: 48.659199714660645\n",
            "time_this_iter_s: 8.032031774520874\n",
            "time_total_s: 48.659199714660645\n",
            "timestamp: 1558275375\n",
            "timesteps_since_restore: 7000\n",
            "timesteps_this_iter: 1000\n",
            "timesteps_total: 7000\n",
            "training_iteration: 7\n",
            "\n",
            "-- PPO --\n",
            "custom_metrics: {}\n",
            "date: 2019-05-19_14-16-36\n",
            "done: false\n",
            "episode_len_mean: 184.61\n",
            "episode_reward_max: 800.0\n",
            "episode_reward_mean: 582.78\n",
            "episode_reward_min: 94.0\n",
            "episodes_this_iter: 20\n",
            "episodes_total: 236\n",
            "experiment_id: a4bfe1eb1cbb431bbf10d96dc753816f\n",
            "hostname: 44573652ebd5\n",
            "info:\n",
            "  grad_time_ms: 10702.079\n",
            "  learner:\n",
            "    ppo_policy:\n",
            "      cur_kl_coeff: 0.11250001192092896\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 0.5517324209213257\n",
            "      kl: 0.008300093933939934\n",
            "      policy_loss: -0.004053599666804075\n",
            "      total_loss: 227.34512329101562\n",
            "      vf_explained_var: 0.672324538230896\n",
            "      vf_loss: 227.34823608398438\n",
            "  load_time_ms: 15.6\n",
            "  num_steps_sampled: 28000\n",
            "  num_steps_trained: 40576\n",
            "  sample_time_ms: 5813.229\n",
            "  update_time_ms: 458.43\n",
            "iterations_since_restore: 7\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 123\n",
            "policy_reward_mean:\n",
            "  dqn_policy: 132.91\n",
            "  ppo_policy: 158.48\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 0.1292739870526006\n",
            "  mean_inference_ms: 2.0986104100608483\n",
            "  mean_processing_ms: 0.3906303128541497\n",
            "time_since_restore: 119.12850713729858\n",
            "time_this_iter_s: 21.795409440994263\n",
            "time_total_s: 119.12850713729858\n",
            "timestamp: 1558275396\n",
            "timesteps_since_restore: 28000\n",
            "timesteps_this_iter: 4000\n",
            "timesteps_total: 28000\n",
            "training_iteration: 7\n",
            "\n",
            "== Iteration 7 ==\n",
            "-- DQN --\n",
            "custom_metrics: {}\n",
            "date: 2019-05-19_14-16-45\n",
            "done: false\n",
            "episode_len_mean: 99.64556962025317\n",
            "episode_reward_max: 742.0\n",
            "episode_reward_mean: 258.1898734177215\n",
            "episode_reward_min: 50.0\n",
            "episodes_this_iter: 5\n",
            "episodes_total: 79\n",
            "experiment_id: 15a9bb44309949c293858c3ef351adf4\n",
            "hostname: 44573652ebd5\n",
            "info:\n",
            "  grad_time_ms: 11.195\n",
            "  learner:\n",
            "    dqn_policy:\n",
            "      cur_lr: 0.0005000000237487257\n",
            "      max_q: 14.668352127075195\n",
            "      mean_q: 11.457469940185547\n",
            "      mean_td_error: -0.24772177636623383\n",
            "      min_q: 0.910417914390564\n",
            "      model: {}\n",
            "  max_exploration: 0.31400000000000006\n",
            "  min_exploration: 0.31400000000000006\n",
            "  num_steps_sampled: 8000\n",
            "  num_steps_trained: 56000\n",
            "  num_target_updates: 15\n",
            "  opt_peak_throughput: 2858.415\n",
            "  opt_samples: 32.0\n",
            "  replay_time_ms: 7.17\n",
            "  sample_time_ms: 14.016\n",
            "  update_time_ms: 0.002\n",
            "iterations_since_restore: 8\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 0\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 123\n",
            "policy_reward_mean:\n",
            "  dqn_policy: 42.75316455696203\n",
            "  ppo_policy: 86.34177215189874\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 0.10708135903664368\n",
            "  mean_inference_ms: 1.6422309226532048\n",
            "  mean_processing_ms: 0.7764044507482075\n",
            "time_since_restore: 56.88024187088013\n",
            "time_this_iter_s: 8.221042156219482\n",
            "time_total_s: 56.88024187088013\n",
            "timestamp: 1558275405\n",
            "timesteps_since_restore: 8000\n",
            "timesteps_this_iter: 1000\n",
            "timesteps_total: 8000\n",
            "training_iteration: 8\n",
            "\n",
            "-- PPO --\n",
            "custom_metrics: {}\n",
            "date: 2019-05-19_14-17-05\n",
            "done: false\n",
            "episode_len_mean: 197.56\n",
            "episode_reward_max: 800.0\n",
            "episode_reward_mean: 661.06\n",
            "episode_reward_min: 289.0\n",
            "episodes_this_iter: 20\n",
            "episodes_total: 256\n",
            "experiment_id: a4bfe1eb1cbb431bbf10d96dc753816f\n",
            "hostname: 44573652ebd5\n",
            "info:\n",
            "  grad_time_ms: 11168.263\n",
            "  learner:\n",
            "    ppo_policy:\n",
            "      cur_kl_coeff: 0.11250001937150955\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 0.5582923889160156\n",
            "      kl: 0.0028533099684864283\n",
            "      policy_loss: -0.003972430247813463\n",
            "      total_loss: 177.95584106445312\n",
            "      vf_explained_var: 0.721953272819519\n",
            "      vf_loss: 177.95950317382812\n",
            "  load_time_ms: 13.812\n",
            "  num_steps_sampled: 32000\n",
            "  num_steps_trained: 48384\n",
            "  sample_time_ms: 5856.616\n",
            "  update_time_ms: 403.452\n",
            "iterations_since_restore: 8\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 123\n",
            "policy_reward_mean:\n",
            "  dqn_policy: 151.71\n",
            "  ppo_policy: 178.82\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 0.1354892314408198\n",
            "  mean_inference_ms: 2.175765326484626\n",
            "  mean_processing_ms: 0.4108762219622626\n",
            "time_since_restore: 139.75535917282104\n",
            "time_this_iter_s: 20.62685203552246\n",
            "time_total_s: 139.75535917282104\n",
            "timestamp: 1558275425\n",
            "timesteps_since_restore: 32000\n",
            "timesteps_this_iter: 4000\n",
            "timesteps_total: 32000\n",
            "training_iteration: 8\n",
            "\n",
            "== Iteration 8 ==\n",
            "-- DQN --\n",
            "custom_metrics: {}\n",
            "date: 2019-05-19_14-17-14\n",
            "done: false\n",
            "episode_len_mean: 105.61904761904762\n",
            "episode_reward_max: 800.0\n",
            "episode_reward_mean: 285.3333333333333\n",
            "episode_reward_min: 50.0\n",
            "episodes_this_iter: 5\n",
            "episodes_total: 84\n",
            "experiment_id: 15a9bb44309949c293858c3ef351adf4\n",
            "hostname: 44573652ebd5\n",
            "info:\n",
            "  grad_time_ms: 12.07\n",
            "  learner:\n",
            "    dqn_policy:\n",
            "      cur_lr: 0.0005000000237487257\n",
            "      max_q: 14.43603229522705\n",
            "      mean_q: 13.097846984863281\n",
            "      mean_td_error: 0.4855149984359741\n",
            "      min_q: 8.718060493469238\n",
            "      model: {}\n",
            "  max_exploration: 0.21599999999999997\n",
            "  min_exploration: 0.21599999999999997\n",
            "  num_steps_sampled: 9000\n",
            "  num_steps_trained: 64000\n",
            "  num_target_updates: 17\n",
            "  opt_peak_throughput: 2651.262\n",
            "  opt_samples: 32.0\n",
            "  replay_time_ms: 7.515\n",
            "  sample_time_ms: 16.357\n",
            "  update_time_ms: 0.002\n",
            "iterations_since_restore: 9\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 0\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 123\n",
            "policy_reward_mean:\n",
            "  dqn_policy: 49.976190476190474\n",
            "  ppo_policy: 92.69047619047619\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 0.10771773965314066\n",
            "  mean_inference_ms: 1.6364588642919302\n",
            "  mean_processing_ms: 0.7827241098021565\n",
            "time_since_restore: 65.33818078041077\n",
            "time_this_iter_s: 8.45793890953064\n",
            "time_total_s: 65.33818078041077\n",
            "timestamp: 1558275434\n",
            "timesteps_since_restore: 9000\n",
            "timesteps_this_iter: 1000\n",
            "timesteps_total: 9000\n",
            "training_iteration: 9\n",
            "\n",
            "-- PPO --\n",
            "custom_metrics: {}\n",
            "date: 2019-05-19_14-17-36\n",
            "done: false\n",
            "episode_len_mean: 198.13\n",
            "episode_reward_max: 800.0\n",
            "episode_reward_mean: 664.55\n",
            "episode_reward_min: 467.0\n",
            "episodes_this_iter: 20\n",
            "episodes_total: 276\n",
            "experiment_id: a4bfe1eb1cbb431bbf10d96dc753816f\n",
            "hostname: 44573652ebd5\n",
            "info:\n",
            "  grad_time_ms: 11543.776\n",
            "  learner:\n",
            "    ppo_policy:\n",
            "      cur_kl_coeff: 0.056250009685754776\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 0.5397222638130188\n",
            "      kl: 0.005277481395751238\n",
            "      policy_loss: -0.0032350090332329273\n",
            "      total_loss: 315.6633605957031\n",
            "      vf_explained_var: 0.5591437816619873\n",
            "      vf_loss: 315.6662902832031\n",
            "  load_time_ms: 12.405\n",
            "  num_steps_sampled: 36000\n",
            "  num_steps_trained: 56192\n",
            "  sample_time_ms: 6032.035\n",
            "  update_time_ms: 360.578\n",
            "iterations_since_restore: 9\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 123\n",
            "policy_reward_mean:\n",
            "  dqn_policy: 144.245\n",
            "  ppo_policy: 188.03\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 0.14023849513956194\n",
            "  mean_inference_ms: 2.2291658726523975\n",
            "  mean_processing_ms: 0.42684341906553624\n",
            "time_since_restore: 161.77335929870605\n",
            "time_this_iter_s: 22.01800012588501\n",
            "time_total_s: 161.77335929870605\n",
            "timestamp: 1558275456\n",
            "timesteps_since_restore: 36000\n",
            "timesteps_this_iter: 4000\n",
            "timesteps_total: 36000\n",
            "training_iteration: 9\n",
            "\n",
            "== Iteration 9 ==\n",
            "-- DQN --\n",
            "custom_metrics: {}\n",
            "date: 2019-05-19_14-17-44\n",
            "done: false\n",
            "episode_len_mean: 110.92134831460675\n",
            "episode_reward_max: 800.0\n",
            "episode_reward_mean: 312.9325842696629\n",
            "episode_reward_min: 50.0\n",
            "episodes_this_iter: 5\n",
            "episodes_total: 89\n",
            "experiment_id: 15a9bb44309949c293858c3ef351adf4\n",
            "hostname: 44573652ebd5\n",
            "info:\n",
            "  grad_time_ms: 10.79\n",
            "  learner:\n",
            "    dqn_policy:\n",
            "      cur_lr: 0.0005000000237487257\n",
            "      max_q: 14.320094108581543\n",
            "      mean_q: 11.859759330749512\n",
            "      mean_td_error: 0.2664312422275543\n",
            "      min_q: 3.7544054985046387\n",
            "      model: {}\n",
            "  max_exploration: 0.118\n",
            "  min_exploration: 0.118\n",
            "  num_steps_sampled: 10000\n",
            "  num_steps_trained: 72000\n",
            "  num_target_updates: 19\n",
            "  opt_peak_throughput: 2965.777\n",
            "  opt_samples: 32.0\n",
            "  replay_time_ms: 7.453\n",
            "  sample_time_ms: 13.174\n",
            "  update_time_ms: 0.001\n",
            "iterations_since_restore: 10\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 0\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 123\n",
            "policy_reward_mean:\n",
            "  dqn_policy: 57.747191011235955\n",
            "  ppo_policy: 98.71910112359551\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 0.10841335639974874\n",
            "  mean_inference_ms: 1.6330070806831547\n",
            "  mean_processing_ms: 0.7893945665433915\n",
            "time_since_restore: 73.82925391197205\n",
            "time_this_iter_s: 8.49107313156128\n",
            "time_total_s: 73.82925391197205\n",
            "timestamp: 1558275464\n",
            "timesteps_since_restore: 10000\n",
            "timesteps_this_iter: 1000\n",
            "timesteps_total: 10000\n",
            "training_iteration: 10\n",
            "\n",
            "-- PPO --\n",
            "custom_metrics: {}\n",
            "date: 2019-05-19_14-18-07\n",
            "done: false\n",
            "episode_len_mean: 199.21\n",
            "episode_reward_max: 800.0\n",
            "episode_reward_mean: 683.23\n",
            "episode_reward_min: 467.0\n",
            "episodes_this_iter: 20\n",
            "episodes_total: 296\n",
            "experiment_id: a4bfe1eb1cbb431bbf10d96dc753816f\n",
            "hostname: 44573652ebd5\n",
            "info:\n",
            "  grad_time_ms: 11865.543\n",
            "  learner:\n",
            "    ppo_policy:\n",
            "      cur_kl_coeff: 0.056250009685754776\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 0.5506070852279663\n",
            "      kl: 0.004207488149404526\n",
            "      policy_loss: -0.0015741395764052868\n",
            "      total_loss: 370.1570739746094\n",
            "      vf_explained_var: 0.4894355237483978\n",
            "      vf_loss: 370.158447265625\n",
            "  load_time_ms: 11.28\n",
            "  num_steps_sampled: 40000\n",
            "  num_steps_trained: 64128\n",
            "  sample_time_ms: 6170.297\n",
            "  update_time_ms: 326.282\n",
            "iterations_since_restore: 10\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 123\n",
            "policy_reward_mean:\n",
            "  dqn_policy: 148.19\n",
            "  ppo_policy: 193.425\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 0.14373671036595465\n",
            "  mean_inference_ms: 2.2772564900217263\n",
            "  mean_processing_ms: 0.43825355062410865\n",
            "time_since_restore: 183.98397016525269\n",
            "time_this_iter_s: 22.21061086654663\n",
            "time_total_s: 183.98397016525269\n",
            "timestamp: 1558275487\n",
            "timesteps_since_restore: 40000\n",
            "timesteps_this_iter: 4000\n",
            "timesteps_total: 40000\n",
            "training_iteration: 10\n",
            "\n",
            "== Iteration 10 ==\n",
            "-- DQN --\n",
            "custom_metrics: {}\n",
            "date: 2019-05-19_14-18-15\n",
            "done: false\n",
            "episode_len_mean: 115.65957446808511\n",
            "episode_reward_max: 800.0\n",
            "episode_reward_mean: 332.7659574468085\n",
            "episode_reward_min: 50.0\n",
            "episodes_this_iter: 5\n",
            "episodes_total: 94\n",
            "experiment_id: 15a9bb44309949c293858c3ef351adf4\n",
            "hostname: 44573652ebd5\n",
            "info:\n",
            "  grad_time_ms: 11.249\n",
            "  learner:\n",
            "    dqn_policy:\n",
            "      cur_lr: 0.0005000000237487257\n",
            "      max_q: 14.844049453735352\n",
            "      mean_q: 12.378704071044922\n",
            "      mean_td_error: -0.5889686346054077\n",
            "      min_q: 2.9975037574768066\n",
            "      model: {}\n",
            "  max_exploration: 0.020000000000000018\n",
            "  min_exploration: 0.020000000000000018\n",
            "  num_steps_sampled: 11000\n",
            "  num_steps_trained: 80000\n",
            "  num_target_updates: 21\n",
            "  opt_peak_throughput: 2844.717\n",
            "  opt_samples: 32.0\n",
            "  replay_time_ms: 7.868\n",
            "  sample_time_ms: 16.562\n",
            "  update_time_ms: 0.002\n",
            "iterations_since_restore: 11\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 0\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 123\n",
            "policy_reward_mean:\n",
            "  dqn_policy: 62.276595744680854\n",
            "  ppo_policy: 104.1063829787234\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 0.10916021305691062\n",
            "  mean_inference_ms: 1.6306156959925693\n",
            "  mean_processing_ms: 0.7960145666352758\n",
            "time_since_restore: 82.13614773750305\n",
            "time_this_iter_s: 8.306893825531006\n",
            "time_total_s: 82.13614773750305\n",
            "timestamp: 1558275495\n",
            "timesteps_since_restore: 11000\n",
            "timesteps_this_iter: 1000\n",
            "timesteps_total: 11000\n",
            "training_iteration: 11\n",
            "\n",
            "-- PPO --\n",
            "custom_metrics: {}\n",
            "date: 2019-05-19_14-18-35\n",
            "done: false\n",
            "episode_len_mean: 199.8\n",
            "episode_reward_max: 800.0\n",
            "episode_reward_mean: 703.95\n",
            "episode_reward_min: 542.0\n",
            "episodes_this_iter: 20\n",
            "episodes_total: 316\n",
            "experiment_id: a4bfe1eb1cbb431bbf10d96dc753816f\n",
            "hostname: 44573652ebd5\n",
            "info:\n",
            "  grad_time_ms: 12370.468\n",
            "  learner:\n",
            "    ppo_policy:\n",
            "      cur_kl_coeff: 0.028125004842877388\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 0.5279555916786194\n",
            "      kl: 0.005570882000029087\n",
            "      policy_loss: -0.003156379796564579\n",
            "      total_loss: 392.40032958984375\n",
            "      vf_explained_var: 0.41195937991142273\n",
            "      vf_loss: 392.4031982421875\n",
            "  load_time_ms: 1.242\n",
            "  num_steps_sampled: 44000\n",
            "  num_steps_trained: 71936\n",
            "  sample_time_ms: 6264.737\n",
            "  update_time_ms: 18.289\n",
            "iterations_since_restore: 11\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 123\n",
            "policy_reward_mean:\n",
            "  dqn_policy: 155.875\n",
            "  ppo_policy: 196.1\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 0.1474578014251939\n",
            "  mean_inference_ms: 2.330036788598235\n",
            "  mean_processing_ms: 0.4495519232649407\n",
            "time_since_restore: 204.39307951927185\n",
            "time_this_iter_s: 20.409109354019165\n",
            "time_total_s: 204.39307951927185\n",
            "timestamp: 1558275515\n",
            "timesteps_since_restore: 44000\n",
            "timesteps_this_iter: 4000\n",
            "timesteps_total: 44000\n",
            "training_iteration: 11\n",
            "\n",
            "== Iteration 11 ==\n",
            "-- DQN --\n",
            "custom_metrics: {}\n",
            "date: 2019-05-19_14-18-44\n",
            "done: false\n",
            "episode_len_mean: 119.91919191919192\n",
            "episode_reward_max: 800.0\n",
            "episode_reward_mean: 350.34343434343435\n",
            "episode_reward_min: 50.0\n",
            "episodes_this_iter: 5\n",
            "episodes_total: 99\n",
            "experiment_id: 15a9bb44309949c293858c3ef351adf4\n",
            "hostname: 44573652ebd5\n",
            "info:\n",
            "  grad_time_ms: 11.556\n",
            "  learner:\n",
            "    dqn_policy:\n",
            "      cur_lr: 0.0005000000237487257\n",
            "      max_q: 15.744664192199707\n",
            "      mean_q: 13.697153091430664\n",
            "      mean_td_error: 1.5488450527191162\n",
            "      min_q: 7.13341760635376\n",
            "      model: {}\n",
            "  max_exploration: 0.020000000000000018\n",
            "  min_exploration: 0.020000000000000018\n",
            "  num_steps_sampled: 12000\n",
            "  num_steps_trained: 88000\n",
            "  num_target_updates: 23\n",
            "  opt_peak_throughput: 2769.06\n",
            "  opt_samples: 32.0\n",
            "  replay_time_ms: 7.571\n",
            "  sample_time_ms: 14.865\n",
            "  update_time_ms: 0.002\n",
            "iterations_since_restore: 12\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 0\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 123\n",
            "policy_reward_mean:\n",
            "  dqn_policy: 66.22222222222223\n",
            "  ppo_policy: 108.94949494949495\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 0.10986435689546854\n",
            "  mean_inference_ms: 1.6286949001754452\n",
            "  mean_processing_ms: 0.8023523224626281\n",
            "time_since_restore: 90.30447268486023\n",
            "time_this_iter_s: 8.168324947357178\n",
            "time_total_s: 90.30447268486023\n",
            "timestamp: 1558275524\n",
            "timesteps_since_restore: 12000\n",
            "timesteps_this_iter: 1000\n",
            "timesteps_total: 12000\n",
            "training_iteration: 12\n",
            "\n",
            "-- PPO --\n",
            "custom_metrics: {}\n",
            "date: 2019-05-19_14-19-07\n",
            "done: false\n",
            "episode_len_mean: 199.8\n",
            "episode_reward_max: 800.0\n",
            "episode_reward_mean: 710.57\n",
            "episode_reward_min: 542.0\n",
            "episodes_this_iter: 20\n",
            "episodes_total: 336\n",
            "experiment_id: a4bfe1eb1cbb431bbf10d96dc753816f\n",
            "hostname: 44573652ebd5\n",
            "info:\n",
            "  grad_time_ms: 13571.281\n",
            "  learner:\n",
            "    ppo_policy:\n",
            "      cur_kl_coeff: 0.028125004842877388\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 0.5383427739143372\n",
            "      kl: 0.004220324102789164\n",
            "      policy_loss: -0.0007013952708803117\n",
            "      total_loss: 388.6299133300781\n",
            "      vf_explained_var: 0.36401158571243286\n",
            "      vf_loss: 388.6304931640625\n",
            "  load_time_ms: 1.278\n",
            "  num_steps_sampled: 48000\n",
            "  num_steps_trained: 79872\n",
            "  sample_time_ms: 6509.067\n",
            "  update_time_ms: 18.846\n",
            "iterations_since_restore: 12\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 123\n",
            "policy_reward_mean:\n",
            "  dqn_policy: 157.45\n",
            "  ppo_policy: 197.835\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 0.14991287017241445\n",
            "  mean_inference_ms: 2.3679645296236487\n",
            "  mean_processing_ms: 0.45775396196598706\n",
            "time_since_restore: 227.5772042274475\n",
            "time_this_iter_s: 23.18412470817566\n",
            "time_total_s: 227.5772042274475\n",
            "timestamp: 1558275547\n",
            "timesteps_since_restore: 48000\n",
            "timesteps_this_iter: 4000\n",
            "timesteps_total: 48000\n",
            "training_iteration: 12\n",
            "\n",
            "== Iteration 12 ==\n",
            "-- DQN --\n",
            "custom_metrics: {}\n",
            "date: 2019-05-19_14-19-15\n",
            "done: false\n",
            "episode_len_mean: 126.98\n",
            "episode_reward_max: 800.0\n",
            "episode_reward_mean: 381.53\n",
            "episode_reward_min: 50.0\n",
            "episodes_this_iter: 5\n",
            "episodes_total: 104\n",
            "experiment_id: 15a9bb44309949c293858c3ef351adf4\n",
            "hostname: 44573652ebd5\n",
            "info:\n",
            "  grad_time_ms: 11.168\n",
            "  learner:\n",
            "    dqn_policy:\n",
            "      cur_lr: 0.0005000000237487257\n",
            "      max_q: 15.827275276184082\n",
            "      mean_q: 13.976757049560547\n",
            "      mean_td_error: 0.41925325989723206\n",
            "      min_q: 6.164405822753906\n",
            "      model: {}\n",
            "  max_exploration: 0.020000000000000018\n",
            "  min_exploration: 0.020000000000000018\n",
            "  num_steps_sampled: 13000\n",
            "  num_steps_trained: 96000\n",
            "  num_target_updates: 25\n",
            "  opt_peak_throughput: 2865.365\n",
            "  opt_samples: 32.0\n",
            "  replay_time_ms: 7.465\n",
            "  sample_time_ms: 15.568\n",
            "  update_time_ms: 0.002\n",
            "iterations_since_restore: 13\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 0\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 123\n",
            "policy_reward_mean:\n",
            "  dqn_policy: 74.0\n",
            "  ppo_policy: 116.765\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 0.1107272313142128\n",
            "  mean_inference_ms: 1.6188869995823034\n",
            "  mean_processing_ms: 0.8107753175825289\n",
            "time_since_restore: 98.82188558578491\n",
            "time_this_iter_s: 8.517412900924683\n",
            "time_total_s: 98.82188558578491\n",
            "timestamp: 1558275555\n",
            "timesteps_since_restore: 13000\n",
            "timesteps_this_iter: 1000\n",
            "timesteps_total: 13000\n",
            "training_iteration: 13\n",
            "\n",
            "-- PPO --\n",
            "custom_metrics: {}\n",
            "date: 2019-05-19_14-19-37\n",
            "done: false\n",
            "episode_len_mean: 199.8\n",
            "episode_reward_max: 800.0\n",
            "episode_reward_mean: 741.36\n",
            "episode_reward_min: 542.0\n",
            "episodes_this_iter: 20\n",
            "episodes_total: 356\n",
            "experiment_id: a4bfe1eb1cbb431bbf10d96dc753816f\n",
            "hostname: 44573652ebd5\n",
            "info:\n",
            "  grad_time_ms: 13960.826\n",
            "  learner:\n",
            "    ppo_policy:\n",
            "      cur_kl_coeff: 0.014062502421438694\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 0.524322509765625\n",
            "      kl: 0.01267916988581419\n",
            "      policy_loss: -0.0025779763236641884\n",
            "      total_loss: 480.7118835449219\n",
            "      vf_explained_var: 0.21096017956733704\n",
            "      vf_loss: 480.71429443359375\n",
            "  load_time_ms: 1.245\n",
            "  num_steps_sampled: 52000\n",
            "  num_steps_trained: 87808\n",
            "  sample_time_ms: 6802.968\n",
            "  update_time_ms: 18.326\n",
            "iterations_since_restore: 13\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 123\n",
            "policy_reward_mean:\n",
            "  dqn_policy: 172.215\n",
            "  ppo_policy: 198.465\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 0.15207913467929943\n",
            "  mean_inference_ms: 2.407909729262891\n",
            "  mean_processing_ms: 0.4657619000493568\n",
            "time_since_restore: 249.13082361221313\n",
            "time_this_iter_s: 21.553619384765625\n",
            "time_total_s: 249.13082361221313\n",
            "timestamp: 1558275577\n",
            "timesteps_since_restore: 52000\n",
            "timesteps_this_iter: 4000\n",
            "timesteps_total: 52000\n",
            "training_iteration: 13\n",
            "\n",
            "== Iteration 13 ==\n",
            "-- DQN --\n",
            "custom_metrics: {}\n",
            "date: 2019-05-19_14-19-45\n",
            "done: false\n",
            "episode_len_mean: 135.53\n",
            "episode_reward_max: 800.0\n",
            "episode_reward_mean: 413.01\n",
            "episode_reward_min: 50.0\n",
            "episodes_this_iter: 5\n",
            "episodes_total: 109\n",
            "experiment_id: 15a9bb44309949c293858c3ef351adf4\n",
            "hostname: 44573652ebd5\n",
            "info:\n",
            "  grad_time_ms: 10.922\n",
            "  learner:\n",
            "    dqn_policy:\n",
            "      cur_lr: 0.0005000000237487257\n",
            "      max_q: 16.19681739807129\n",
            "      mean_q: 14.355712890625\n",
            "      mean_td_error: 0.5708562135696411\n",
            "      min_q: 10.823670387268066\n",
            "      model: {}\n",
            "  max_exploration: 0.020000000000000018\n",
            "  min_exploration: 0.020000000000000018\n",
            "  num_steps_sampled: 14000\n",
            "  num_steps_trained: 104000\n",
            "  num_target_updates: 27\n",
            "  opt_peak_throughput: 2929.949\n",
            "  opt_samples: 32.0\n",
            "  replay_time_ms: 7.722\n",
            "  sample_time_ms: 14.591\n",
            "  update_time_ms: 0.002\n",
            "iterations_since_restore: 14\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 0\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 123\n",
            "policy_reward_mean:\n",
            "  dqn_policy: 80.755\n",
            "  ppo_policy: 125.75\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 0.11164665021385373\n",
            "  mean_inference_ms: 1.6069850266355499\n",
            "  mean_processing_ms: 0.8199609746231172\n",
            "time_since_restore: 106.95986747741699\n",
            "time_this_iter_s: 8.13798189163208\n",
            "time_total_s: 106.95986747741699\n",
            "timestamp: 1558275585\n",
            "timesteps_since_restore: 14000\n",
            "timesteps_this_iter: 1000\n",
            "timesteps_total: 14000\n",
            "training_iteration: 14\n",
            "\n",
            "-- PPO --\n",
            "custom_metrics: {}\n",
            "date: 2019-05-19_14-20-06\n",
            "done: false\n",
            "episode_len_mean: 199.8\n",
            "episode_reward_max: 800.0\n",
            "episode_reward_mean: 741.59\n",
            "episode_reward_min: 550.0\n",
            "episodes_this_iter: 20\n",
            "episodes_total: 376\n",
            "experiment_id: a4bfe1eb1cbb431bbf10d96dc753816f\n",
            "hostname: 44573652ebd5\n",
            "info:\n",
            "  grad_time_ms: 14296.93\n",
            "  learner:\n",
            "    ppo_policy:\n",
            "      cur_kl_coeff: 0.014062502421438694\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 0.5272403359413147\n",
            "      kl: 0.014562612399458885\n",
            "      policy_loss: -0.009362691082060337\n",
            "      total_loss: 272.7588806152344\n",
            "      vf_explained_var: 0.5582064986228943\n",
            "      vf_loss: 272.7680969238281\n",
            "  load_time_ms: 1.248\n",
            "  num_steps_sampled: 56000\n",
            "  num_steps_trained: 95744\n",
            "  sample_time_ms: 6768.997\n",
            "  update_time_ms: 19.429\n",
            "iterations_since_restore: 14\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 123\n",
            "policy_reward_mean:\n",
            "  dqn_policy: 171.59\n",
            "  ppo_policy: 199.205\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 0.15342054435746277\n",
            "  mean_inference_ms: 2.43340325696199\n",
            "  mean_processing_ms: 0.47136020687307334\n",
            "time_since_restore: 269.8381280899048\n",
            "time_this_iter_s: 20.70730447769165\n",
            "time_total_s: 269.8381280899048\n",
            "timestamp: 1558275606\n",
            "timesteps_since_restore: 56000\n",
            "timesteps_this_iter: 4000\n",
            "timesteps_total: 56000\n",
            "training_iteration: 14\n",
            "\n",
            "== Iteration 14 ==\n",
            "-- DQN --\n",
            "custom_metrics: {}\n",
            "date: 2019-05-19_14-20-14\n",
            "done: false\n",
            "episode_len_mean: 144.16\n",
            "episode_reward_max: 800.0\n",
            "episode_reward_mean: 447.94\n",
            "episode_reward_min: 50.0\n",
            "episodes_this_iter: 5\n",
            "episodes_total: 114\n",
            "experiment_id: 15a9bb44309949c293858c3ef351adf4\n",
            "hostname: 44573652ebd5\n",
            "info:\n",
            "  grad_time_ms: 10.989\n",
            "  learner:\n",
            "    dqn_policy:\n",
            "      cur_lr: 0.0005000000237487257\n",
            "      max_q: 16.32587242126465\n",
            "      mean_q: 13.643595695495605\n",
            "      mean_td_error: 1.3619017601013184\n",
            "      min_q: 0.10245001316070557\n",
            "      model: {}\n",
            "  max_exploration: 0.020000000000000018\n",
            "  min_exploration: 0.020000000000000018\n",
            "  num_steps_sampled: 15000\n",
            "  num_steps_trained: 112000\n",
            "  num_target_updates: 29\n",
            "  opt_peak_throughput: 2911.871\n",
            "  opt_samples: 32.0\n",
            "  replay_time_ms: 7.766\n",
            "  sample_time_ms: 15.124\n",
            "  update_time_ms: 0.002\n",
            "iterations_since_restore: 15\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 0\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 123\n",
            "policy_reward_mean:\n",
            "  dqn_policy: 89.145\n",
            "  ppo_policy: 134.825\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 0.11261549882785472\n",
            "  mean_inference_ms: 1.595590510721601\n",
            "  mean_processing_ms: 0.829534691959775\n",
            "time_since_restore: 115.37926292419434\n",
            "time_this_iter_s: 8.419395446777344\n",
            "time_total_s: 115.37926292419434\n",
            "timestamp: 1558275614\n",
            "timesteps_since_restore: 15000\n",
            "timesteps_this_iter: 1000\n",
            "timesteps_total: 15000\n",
            "training_iteration: 15\n",
            "\n",
            "-- PPO --\n",
            "custom_metrics: {}\n",
            "date: 2019-05-19_14-20-35\n",
            "done: false\n",
            "episode_len_mean: 199.8\n",
            "episode_reward_max: 800.0\n",
            "episode_reward_mean: 720.5\n",
            "episode_reward_min: 550.0\n",
            "episodes_this_iter: 20\n",
            "episodes_total: 396\n",
            "experiment_id: a4bfe1eb1cbb431bbf10d96dc753816f\n",
            "hostname: 44573652ebd5\n",
            "info:\n",
            "  grad_time_ms: 14415.0\n",
            "  learner:\n",
            "    ppo_policy:\n",
            "      cur_kl_coeff: 0.014062502421438694\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 0.5304228067398071\n",
            "      kl: 0.0055378456600010395\n",
            "      policy_loss: -0.0014665084891021252\n",
            "      total_loss: 477.0511474609375\n",
            "      vf_explained_var: 0.21976318955421448\n",
            "      vf_loss: 477.05255126953125\n",
            "  load_time_ms: 1.237\n",
            "  num_steps_sampled: 60000\n",
            "  num_steps_trained: 103680\n",
            "  sample_time_ms: 6747.265\n",
            "  update_time_ms: 20.714\n",
            "iterations_since_restore: 15\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 123\n",
            "policy_reward_mean:\n",
            "  dqn_policy: 161.045\n",
            "  ppo_policy: 199.205\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 0.15453145806517615\n",
            "  mean_inference_ms: 2.4455973504188977\n",
            "  mean_processing_ms: 0.476179023458179\n",
            "time_since_restore: 290.42948031425476\n",
            "time_this_iter_s: 20.591352224349976\n",
            "time_total_s: 290.42948031425476\n",
            "timestamp: 1558275635\n",
            "timesteps_since_restore: 60000\n",
            "timesteps_this_iter: 4000\n",
            "timesteps_total: 60000\n",
            "training_iteration: 15\n",
            "\n",
            "== Iteration 15 ==\n",
            "-- DQN --\n",
            "custom_metrics: {}\n",
            "date: 2019-05-19_14-20-43\n",
            "done: false\n",
            "episode_len_mean: 151.64\n",
            "episode_reward_max: 800.0\n",
            "episode_reward_mean: 478.55\n",
            "episode_reward_min: 50.0\n",
            "episodes_this_iter: 5\n",
            "episodes_total: 119\n",
            "experiment_id: 15a9bb44309949c293858c3ef351adf4\n",
            "hostname: 44573652ebd5\n",
            "info:\n",
            "  grad_time_ms: 11.053\n",
            "  learner:\n",
            "    dqn_policy:\n",
            "      cur_lr: 0.0005000000237487257\n",
            "      max_q: 16.293018341064453\n",
            "      mean_q: 14.791718482971191\n",
            "      mean_td_error: 1.6824727058410645\n",
            "      min_q: 11.037803649902344\n",
            "      model: {}\n",
            "  max_exploration: 0.020000000000000018\n",
            "  min_exploration: 0.020000000000000018\n",
            "  num_steps_sampled: 16000\n",
            "  num_steps_trained: 120000\n",
            "  num_target_updates: 31\n",
            "  opt_peak_throughput: 2895.257\n",
            "  opt_samples: 32.0\n",
            "  replay_time_ms: 7.22\n",
            "  sample_time_ms: 14.872\n",
            "  update_time_ms: 0.002\n",
            "iterations_since_restore: 16\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 0\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 123\n",
            "policy_reward_mean:\n",
            "  dqn_policy: 95.555\n",
            "  ppo_policy: 143.72\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 0.11360409371535246\n",
            "  mean_inference_ms: 1.5843118364262687\n",
            "  mean_processing_ms: 0.8393248929128648\n",
            "time_since_restore: 123.5921561717987\n",
            "time_this_iter_s: 8.21289324760437\n",
            "time_total_s: 123.5921561717987\n",
            "timestamp: 1558275643\n",
            "timesteps_since_restore: 16000\n",
            "timesteps_this_iter: 1000\n",
            "timesteps_total: 16000\n",
            "training_iteration: 16\n",
            "\n",
            "-- PPO --\n",
            "custom_metrics: {}\n",
            "date: 2019-05-19_14-21-03\n",
            "done: false\n",
            "episode_len_mean: 200.0\n",
            "episode_reward_max: 800.0\n",
            "episode_reward_mean: 726.61\n",
            "episode_reward_min: 656.0\n",
            "episodes_this_iter: 20\n",
            "episodes_total: 416\n",
            "experiment_id: a4bfe1eb1cbb431bbf10d96dc753816f\n",
            "hostname: 44573652ebd5\n",
            "info:\n",
            "  grad_time_ms: 14493.941\n",
            "  learner:\n",
            "    ppo_policy:\n",
            "      cur_kl_coeff: 0.014062502421438694\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 0.5213549733161926\n",
            "      kl: 0.004963425919413567\n",
            "      policy_loss: -0.0011510305339470506\n",
            "      total_loss: 518.8142700195312\n",
            "      vf_explained_var: 0.1392897069454193\n",
            "      vf_loss: 518.8153686523438\n",
            "  load_time_ms: 1.365\n",
            "  num_steps_sampled: 64000\n",
            "  num_steps_trained: 111616\n",
            "  sample_time_ms: 6805.014\n",
            "  update_time_ms: 20.37\n",
            "iterations_since_restore: 16\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 123\n",
            "policy_reward_mean:\n",
            "  dqn_policy: 163.305\n",
            "  ppo_policy: 200.0\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 0.15550621725883723\n",
            "  mean_inference_ms: 2.4551878991445344\n",
            "  mean_processing_ms: 0.4806384045582729\n",
            "time_since_restore: 310.7041931152344\n",
            "time_this_iter_s: 20.274712800979614\n",
            "time_total_s: 310.7041931152344\n",
            "timestamp: 1558275663\n",
            "timesteps_since_restore: 64000\n",
            "timesteps_this_iter: 4000\n",
            "timesteps_total: 64000\n",
            "training_iteration: 16\n",
            "\n",
            "== Iteration 16 ==\n",
            "-- DQN --\n",
            "custom_metrics: {}\n",
            "date: 2019-05-19_14-21-11\n",
            "done: false\n",
            "episode_len_mean: 159.91\n",
            "episode_reward_max: 800.0\n",
            "episode_reward_mean: 507.76\n",
            "episode_reward_min: 50.0\n",
            "episodes_this_iter: 5\n",
            "episodes_total: 124\n",
            "experiment_id: 15a9bb44309949c293858c3ef351adf4\n",
            "hostname: 44573652ebd5\n",
            "info:\n",
            "  grad_time_ms: 10.921\n",
            "  learner:\n",
            "    dqn_policy:\n",
            "      cur_lr: 0.0005000000237487257\n",
            "      max_q: 15.689743041992188\n",
            "      mean_q: 14.637994766235352\n",
            "      mean_td_error: 0.4411236345767975\n",
            "      min_q: 11.221920013427734\n",
            "      model: {}\n",
            "  max_exploration: 0.020000000000000018\n",
            "  min_exploration: 0.020000000000000018\n",
            "  num_steps_sampled: 17000\n",
            "  num_steps_trained: 128000\n",
            "  num_target_updates: 33\n",
            "  opt_peak_throughput: 2930.057\n",
            "  opt_samples: 32.0\n",
            "  replay_time_ms: 7.464\n",
            "  sample_time_ms: 14.904\n",
            "  update_time_ms: 0.001\n",
            "iterations_since_restore: 17\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 0\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 123\n",
            "policy_reward_mean:\n",
            "  dqn_policy: 101.37\n",
            "  ppo_policy: 152.51\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 0.11460874179698873\n",
            "  mean_inference_ms: 1.5730890330846676\n",
            "  mean_processing_ms: 0.8493118201087989\n",
            "time_since_restore: 131.76322102546692\n",
            "time_this_iter_s: 8.171064853668213\n",
            "time_total_s: 131.76322102546692\n",
            "timestamp: 1558275671\n",
            "timesteps_since_restore: 17000\n",
            "timesteps_this_iter: 1000\n",
            "timesteps_total: 17000\n",
            "training_iteration: 17\n",
            "\n",
            "-- PPO --\n",
            "custom_metrics: {}\n",
            "date: 2019-05-19_14-21-33\n",
            "done: false\n",
            "episode_len_mean: 200.0\n",
            "episode_reward_max: 800.0\n",
            "episode_reward_mean: 718.79\n",
            "episode_reward_min: 656.0\n",
            "episodes_this_iter: 20\n",
            "episodes_total: 436\n",
            "experiment_id: a4bfe1eb1cbb431bbf10d96dc753816f\n",
            "hostname: 44573652ebd5\n",
            "info:\n",
            "  grad_time_ms: 14565.489\n",
            "  learner:\n",
            "    ppo_policy:\n",
            "      cur_kl_coeff: 0.007031251210719347\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 0.5038431882858276\n",
            "      kl: 0.0062624686397612095\n",
            "      policy_loss: -0.003021766897290945\n",
            "      total_loss: 600.4334716796875\n",
            "      vf_explained_var: 0.01735580526292324\n",
            "      vf_loss: 600.4364013671875\n",
            "  load_time_ms: 1.354\n",
            "  num_steps_sampled: 68000\n",
            "  num_steps_trained: 119552\n",
            "  sample_time_ms: 6740.975\n",
            "  update_time_ms: 21.187\n",
            "iterations_since_restore: 17\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 123\n",
            "policy_reward_mean:\n",
            "  dqn_policy: 159.395\n",
            "  ppo_policy: 200.0\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 0.15637772907759367\n",
            "  mean_inference_ms: 2.4586290576757013\n",
            "  mean_processing_ms: 0.4845226087114326\n",
            "time_since_restore: 332.58374881744385\n",
            "time_this_iter_s: 21.879555702209473\n",
            "time_total_s: 332.58374881744385\n",
            "timestamp: 1558275693\n",
            "timesteps_since_restore: 68000\n",
            "timesteps_this_iter: 4000\n",
            "timesteps_total: 68000\n",
            "training_iteration: 17\n",
            "\n",
            "== Iteration 17 ==\n",
            "-- DQN --\n",
            "custom_metrics: {}\n",
            "date: 2019-05-19_14-21-42\n",
            "done: false\n",
            "episode_len_mean: 168.65\n",
            "episode_reward_max: 800.0\n",
            "episode_reward_mean: 538.06\n",
            "episode_reward_min: 56.0\n",
            "episodes_this_iter: 5\n",
            "episodes_total: 129\n",
            "experiment_id: 15a9bb44309949c293858c3ef351adf4\n",
            "hostname: 44573652ebd5\n",
            "info:\n",
            "  grad_time_ms: 11.766\n",
            "  learner:\n",
            "    dqn_policy:\n",
            "      cur_lr: 0.0005000000237487257\n",
            "      max_q: 16.509227752685547\n",
            "      mean_q: 14.842838287353516\n",
            "      mean_td_error: 1.4691191911697388\n",
            "      min_q: 9.107987403869629\n",
            "      model: {}\n",
            "  max_exploration: 0.020000000000000018\n",
            "  min_exploration: 0.020000000000000018\n",
            "  num_steps_sampled: 18000\n",
            "  num_steps_trained: 136000\n",
            "  num_target_updates: 35\n",
            "  opt_peak_throughput: 2719.645\n",
            "  opt_samples: 32.0\n",
            "  replay_time_ms: 7.441\n",
            "  sample_time_ms: 14.689\n",
            "  update_time_ms: 0.002\n",
            "iterations_since_restore: 18\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 0\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 123\n",
            "policy_reward_mean:\n",
            "  dqn_policy: 107.495\n",
            "  ppo_policy: 161.535\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 0.11564246404401052\n",
            "  mean_inference_ms: 1.5643884164156412\n",
            "  mean_processing_ms: 0.859514785048122\n",
            "time_since_restore: 139.96454644203186\n",
            "time_this_iter_s: 8.201325416564941\n",
            "time_total_s: 139.96454644203186\n",
            "timestamp: 1558275702\n",
            "timesteps_since_restore: 18000\n",
            "timesteps_this_iter: 1000\n",
            "timesteps_total: 18000\n",
            "training_iteration: 18\n",
            "\n",
            "-- PPO --\n",
            "custom_metrics: {}\n",
            "date: 2019-05-19_14-22-03\n",
            "done: false\n",
            "episode_len_mean: 200.0\n",
            "episode_reward_max: 798.0\n",
            "episode_reward_mean: 702.85\n",
            "episode_reward_min: 656.0\n",
            "episodes_this_iter: 20\n",
            "episodes_total: 456\n",
            "experiment_id: a4bfe1eb1cbb431bbf10d96dc753816f\n",
            "hostname: 44573652ebd5\n",
            "info:\n",
            "  grad_time_ms: 14590.543\n",
            "  learner:\n",
            "    ppo_policy:\n",
            "      cur_kl_coeff: 0.007031251210719347\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 0.5314792990684509\n",
            "      kl: 0.005010542459785938\n",
            "      policy_loss: -0.00164172297809273\n",
            "      total_loss: 607.334228515625\n",
            "      vf_explained_var: 0.007197272498160601\n",
            "      vf_loss: 607.3357543945312\n",
            "  load_time_ms: 1.334\n",
            "  num_steps_sampled: 72000\n",
            "  num_steps_trained: 127488\n",
            "  sample_time_ms: 6790.883\n",
            "  update_time_ms: 21.301\n",
            "iterations_since_restore: 18\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 123\n",
            "policy_reward_mean:\n",
            "  dqn_policy: 151.425\n",
            "  ppo_policy: 200.0\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 0.15696876514014907\n",
            "  mean_inference_ms: 2.4587056734265142\n",
            "  mean_processing_ms: 0.487080167779793\n",
            "time_since_restore: 353.9609487056732\n",
            "time_this_iter_s: 21.37719988822937\n",
            "time_total_s: 353.9609487056732\n",
            "timestamp: 1558275723\n",
            "timesteps_since_restore: 72000\n",
            "timesteps_this_iter: 4000\n",
            "timesteps_total: 72000\n",
            "training_iteration: 18\n",
            "\n",
            "== Iteration 18 ==\n",
            "-- DQN --\n",
            "custom_metrics: {}\n",
            "date: 2019-05-19_14-22-11\n",
            "done: false\n",
            "episode_len_mean: 176.5\n",
            "episode_reward_max: 800.0\n",
            "episode_reward_mean: 565.47\n",
            "episode_reward_min: 56.0\n",
            "episodes_this_iter: 5\n",
            "episodes_total: 134\n",
            "experiment_id: 15a9bb44309949c293858c3ef351adf4\n",
            "hostname: 44573652ebd5\n",
            "info:\n",
            "  grad_time_ms: 11.301\n",
            "  learner:\n",
            "    dqn_policy:\n",
            "      cur_lr: 0.0005000000237487257\n",
            "      max_q: 16.10485076904297\n",
            "      mean_q: 14.578313827514648\n",
            "      mean_td_error: 1.6609643697738647\n",
            "      min_q: 6.584770202636719\n",
            "      model: {}\n",
            "  max_exploration: 0.020000000000000018\n",
            "  min_exploration: 0.020000000000000018\n",
            "  num_steps_sampled: 19000\n",
            "  num_steps_trained: 144000\n",
            "  num_target_updates: 37\n",
            "  opt_peak_throughput: 2831.693\n",
            "  opt_samples: 32.0\n",
            "  replay_time_ms: 7.705\n",
            "  sample_time_ms: 10.378\n",
            "  update_time_ms: 0.002\n",
            "iterations_since_restore: 19\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 0\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 123\n",
            "policy_reward_mean:\n",
            "  dqn_policy: 113.005\n",
            "  ppo_policy: 169.73\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 0.11676296323737184\n",
            "  mean_inference_ms: 1.5655113781926857\n",
            "  mean_processing_ms: 0.8701227037153348\n",
            "time_since_restore: 148.13191485404968\n",
            "time_this_iter_s: 8.167368412017822\n",
            "time_total_s: 148.13191485404968\n",
            "timestamp: 1558275731\n",
            "timesteps_since_restore: 19000\n",
            "timesteps_this_iter: 1000\n",
            "timesteps_total: 19000\n",
            "training_iteration: 19\n",
            "\n",
            "-- PPO --\n",
            "custom_metrics: {}\n",
            "date: 2019-05-19_14-22-33\n",
            "done: false\n",
            "episode_len_mean: 200.0\n",
            "episode_reward_max: 794.0\n",
            "episode_reward_mean: 691.75\n",
            "episode_reward_min: 622.0\n",
            "episodes_this_iter: 20\n",
            "episodes_total: 476\n",
            "experiment_id: a4bfe1eb1cbb431bbf10d96dc753816f\n",
            "hostname: 44573652ebd5\n",
            "info:\n",
            "  grad_time_ms: 14692.621\n",
            "  learner:\n",
            "    ppo_policy:\n",
            "      cur_kl_coeff: 0.007031251210719347\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 0.4842018187046051\n",
            "      kl: 0.010029854252934456\n",
            "      policy_loss: -0.0019330923678353429\n",
            "      total_loss: 595.7228393554688\n",
            "      vf_explained_var: 0.013367020525038242\n",
            "      vf_loss: 595.7247314453125\n",
            "  load_time_ms: 1.374\n",
            "  num_steps_sampled: 76000\n",
            "  num_steps_trained: 135424\n",
            "  sample_time_ms: 6674.1\n",
            "  update_time_ms: 21.525\n",
            "iterations_since_restore: 19\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 123\n",
            "policy_reward_mean:\n",
            "  dqn_policy: 145.875\n",
            "  ppo_policy: 200.0\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 0.15752908905443105\n",
            "  mean_inference_ms: 2.4581820404579453\n",
            "  mean_processing_ms: 0.4895466133051714\n",
            "time_since_restore: 375.834189414978\n",
            "time_this_iter_s: 21.87324070930481\n",
            "time_total_s: 375.834189414978\n",
            "timestamp: 1558275753\n",
            "timesteps_since_restore: 76000\n",
            "timesteps_this_iter: 4000\n",
            "timesteps_total: 76000\n",
            "training_iteration: 19\n",
            "\n",
            "== Iteration 19 ==\n",
            "-- DQN --\n",
            "custom_metrics: {}\n",
            "date: 2019-05-19_14-22-41\n",
            "done: false\n",
            "episode_len_mean: 183.71\n",
            "episode_reward_max: 800.0\n",
            "episode_reward_mean: 592.07\n",
            "episode_reward_min: 56.0\n",
            "episodes_this_iter: 5\n",
            "episodes_total: 139\n",
            "experiment_id: 15a9bb44309949c293858c3ef351adf4\n",
            "hostname: 44573652ebd5\n",
            "info:\n",
            "  grad_time_ms: 11.085\n",
            "  learner:\n",
            "    dqn_policy:\n",
            "      cur_lr: 0.0005000000237487257\n",
            "      max_q: 15.929444313049316\n",
            "      mean_q: 14.208419799804688\n",
            "      mean_td_error: 0.561693549156189\n",
            "      min_q: 4.715492248535156\n",
            "      model: {}\n",
            "  max_exploration: 0.020000000000000018\n",
            "  min_exploration: 0.020000000000000018\n",
            "  num_steps_sampled: 20000\n",
            "  num_steps_trained: 152000\n",
            "  num_target_updates: 39\n",
            "  opt_peak_throughput: 2886.657\n",
            "  opt_samples: 32.0\n",
            "  replay_time_ms: 7.533\n",
            "  sample_time_ms: 14.862\n",
            "  update_time_ms: 0.003\n",
            "iterations_since_restore: 20\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 0\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 123\n",
            "policy_reward_mean:\n",
            "  dqn_policy: 118.165\n",
            "  ppo_policy: 177.87\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 0.11789596361920583\n",
            "  mean_inference_ms: 1.5666178766549965\n",
            "  mean_processing_ms: 0.8808251630438985\n",
            "time_since_restore: 156.28526210784912\n",
            "time_this_iter_s: 8.153347253799438\n",
            "time_total_s: 156.28526210784912\n",
            "timestamp: 1558275761\n",
            "timesteps_since_restore: 20000\n",
            "timesteps_this_iter: 1000\n",
            "timesteps_total: 20000\n",
            "training_iteration: 20\n",
            "\n",
            "-- PPO --\n",
            "custom_metrics: {}\n",
            "date: 2019-05-19_14-23-02\n",
            "done: false\n",
            "episode_len_mean: 200.0\n",
            "episode_reward_max: 794.0\n",
            "episode_reward_mean: 685.75\n",
            "episode_reward_min: 614.0\n",
            "episodes_this_iter: 20\n",
            "episodes_total: 496\n",
            "experiment_id: a4bfe1eb1cbb431bbf10d96dc753816f\n",
            "hostname: 44573652ebd5\n",
            "info:\n",
            "  grad_time_ms: 14666.353\n",
            "  learner:\n",
            "    ppo_policy:\n",
            "      cur_kl_coeff: 0.007031251210719347\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 0.47925782203674316\n",
            "      kl: 0.004146489314734936\n",
            "      policy_loss: -0.0005908302264288068\n",
            "      total_loss: 599.2318115234375\n",
            "      vf_explained_var: 0.0069757988676428795\n",
            "      vf_loss: 599.2322387695312\n",
            "  load_time_ms: 1.365\n",
            "  num_steps_sampled: 80000\n",
            "  num_steps_trained: 143360\n",
            "  sample_time_ms: 6542.296\n",
            "  update_time_ms: 21.998\n",
            "iterations_since_restore: 20\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 123\n",
            "policy_reward_mean:\n",
            "  dqn_policy: 142.875\n",
            "  ppo_policy: 200.0\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 0.15788311186005555\n",
            "  mean_inference_ms: 2.4563108706121475\n",
            "  mean_processing_ms: 0.4916122818946627\n",
            "time_since_restore: 396.46795082092285\n",
            "time_this_iter_s: 20.633761405944824\n",
            "time_total_s: 396.46795082092285\n",
            "timestamp: 1558275782\n",
            "timesteps_since_restore: 80000\n",
            "timesteps_this_iter: 4000\n",
            "timesteps_total: 80000\n",
            "training_iteration: 20\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2a04ovk7moE",
        "colab_type": "code",
        "outputId": "beff4589-297b-4851-a4dc-97ed1337b02f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1327
        }
      },
      "source": [
        "config = DEFAULT_CONFIG.copy()\n",
        "config['num_workers'] = 2\n",
        "config['num_sgd_iter'] = 30\n",
        "config['num_gpus'] = 3\n",
        "config['sgd_minibatch_size'] = 128\n",
        "config['model']['fcnet_hiddens'] = [100, 100]\n",
        "config['num_cpus_per_worker'] = 0  # This avoids running out of resources in the notebook environment when this cell is re-executed\n",
        "\n",
        "agent = TRPOTrainer(config, 'CartPole-v0')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FYI: By default, the value function will not share layers with the policy model ('vf_share_layers': False).\n",
            "2019-05-18 19:21:34,429\tINFO policy_evaluator.py:312 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/ray-distr/python/ray/rllib/models/fcnet.py:37: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /content/ray-distr/python/ray/rllib/models/action_dist.py:123: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.random.categorical instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-05-18 19:21:35,945\tINFO policy_evaluator.py:732 -- Built policy map: {'default_policy': <trpo.trpo_policy_graph.TRPOPolicyGraph object at 0x7f6e7f6f74e0>}\n",
            "2019-05-18 19:21:35,947\tINFO policy_evaluator.py:733 -- Built preprocessor map: {'default_policy': <ray.rllib.models.preprocessors.NoPreprocessor object at 0x7f6e7f6f7198>}\n",
            "2019-05-18 19:21:35,949\tINFO policy_evaluator.py:344 -- Built filter map: {'default_policy': <ray.rllib.utils.filter.NoFilter object at 0x7f6e7f61a048>}\n",
            "2019-05-18 19:21:36,006\tINFO multi_gpu_optimizer.py:80 -- LocalMultiGPUOptimizer devices ['/gpu:0', '/gpu:1', '/gpu:2']\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/compat.py:175: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m non-resource variables are not supported in the long term\n",
            "\u001b[2m\u001b[36m(pid=11727)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/compat.py:175: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=11727)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=11727)\u001b[0m non-resource variables are not supported in the long term\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m 2019-05-18 19:21:41,039\tINFO policy_evaluator.py:312 -- Creating policy evaluation worker 1 on CPU (please ignore any CUDA init errors)\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m 2019-05-18 19:21:41.065532: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m 2019-05-18 19:21:41.065807: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x18ae840 executing computations on platform Host. Devices:\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m 2019-05-18 19:21:41.065845: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m WARNING:tensorflow:From /content/ray-distr/python/ray/rllib/models/fcnet.py:37: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m Use keras.layers.dense instead.\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m Colocations handled automatically by placer.\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m WARNING:tensorflow:From /content/ray-distr/python/ray/rllib/models/action_dist.py:123: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m Use tf.random.categorical instead.\n",
            "\u001b[2m\u001b[36m(pid=11727)\u001b[0m 2019-05-18 19:21:41,186\tINFO policy_evaluator.py:312 -- Creating policy evaluation worker 2 on CPU (please ignore any CUDA init errors)\n",
            "\u001b[2m\u001b[36m(pid=11727)\u001b[0m 2019-05-18 19:21:41.212458: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "\u001b[2m\u001b[36m(pid=11727)\u001b[0m 2019-05-18 19:21:41.212956: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x289e840 executing computations on platform Host. Devices:\n",
            "\u001b[2m\u001b[36m(pid=11727)\u001b[0m 2019-05-18 19:21:41.213001: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "\u001b[2m\u001b[36m(pid=11727)\u001b[0m WARNING:tensorflow:From /content/ray-distr/python/ray/rllib/models/fcnet.py:37: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=11727)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=11727)\u001b[0m Use keras.layers.dense instead.\n",
            "\u001b[2m\u001b[36m(pid=11727)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=11727)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=11727)\u001b[0m Colocations handled automatically by placer.\n",
            "\u001b[2m\u001b[36m(pid=11727)\u001b[0m WARNING:tensorflow:From /content/ray-distr/python/ray/rllib/models/action_dist.py:123: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=11727)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=11727)\u001b[0m Use tf.random.categorical instead.\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m Use tf.cast instead.\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m   \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "\u001b[2m\u001b[36m(pid=11727)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=11727)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=11727)\u001b[0m Use tf.cast instead.\n",
            "\u001b[2m\u001b[36m(pid=11727)\u001b[0m /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "\u001b[2m\u001b[36m(pid=11727)\u001b[0m   \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m Deprecated in favor of operator or tf.math.divide.\n",
            "\u001b[2m\u001b[36m(pid=11727)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=11727)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=11727)\u001b[0m Deprecated in favor of operator or tf.math.divide.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNgdi5mK7pLB",
        "colab_type": "code",
        "outputId": "09e4a008-1b5f-4ce8-b9b1-b5110eae6d4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3380
        }
      },
      "source": [
        "for i in range(2):\n",
        "    result = agent.train()\n",
        "    print(pretty_print(result))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m 2019-05-18 19:22:07,265\tINFO policy_evaluator.py:438 -- Generating sample batch of size 200\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m 2019-05-18 19:22:07,266\tINFO sampler.py:308 -- Raw obs from env: { 0: { 'agent0': np.ndarray((4,), dtype=float64, min=-0.048, max=0.037, mean=-0.014)}}\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m 2019-05-18 19:22:07,266\tINFO sampler.py:309 -- Info return from env: {0: {'agent0': None}}\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m 2019-05-18 19:22:07,266\tINFO sampler.py:407 -- Preprocessed obs: np.ndarray((4,), dtype=float64, min=-0.048, max=0.037, mean=-0.014)\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m 2019-05-18 19:22:07,266\tINFO sampler.py:411 -- Filtered obs: np.ndarray((4,), dtype=float64, min=-0.048, max=0.037, mean=-0.014)\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m 2019-05-18 19:22:07,267\tINFO sampler.py:525 -- Inputs to compute_actions():\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m { 'default_policy': [ { 'data': { 'agent_id': 'agent0',\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m                                   'env_id': 0,\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m                                   'info': None,\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m                                   'obs': np.ndarray((4,), dtype=float64, min=-0.048, max=0.037, mean=-0.014),\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m                                   'prev_action': np.ndarray((), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m                                   'prev_reward': 0.0,\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m                                   'rnn_state': []},\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m                         'type': 'PolicyEvalData'}]}\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m 2019-05-18 19:22:07,267\tINFO tf_run_builder.py:92 -- Executing TF run without tracing. To dump TF timeline traces to disk, set the TF_TIMELINE_DIR environment variable.\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m 2019-05-18 19:22:07,378\tINFO sampler.py:552 -- Outputs of compute_actions():\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m { 'default_policy': ( np.ndarray((1,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m                       [],\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m                       { 'action_prob': np.ndarray((1,), dtype=float32, min=0.5, max=0.5, mean=0.5),\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m                         'behaviour_logits': np.ndarray((1, 2), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m                         'vf_preds': np.ndarray((1,), dtype=float32, min=0.0, max=0.0, mean=0.0)})}\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m 2019-05-18 19:22:07,406\tINFO sample_batch_builder.py:161 -- Trajectory fragment after postprocess_trajectory():\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m { 'agent0': { 'data': { 'action_prob': np.ndarray((19,), dtype=float32, min=0.5, max=0.5, mean=0.5),\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m                         'actions': np.ndarray((19,), dtype=int64, min=0.0, max=1.0, mean=0.684),\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m                         'advantages': np.ndarray((19,), dtype=float32, min=0.995, max=17.383, mean=9.423),\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m                         'agent_index': np.ndarray((19,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m                         'behaviour_logits': np.ndarray((19, 2), dtype=float32, min=-0.005, max=0.006, mean=0.002),\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m                         'dones': np.ndarray((19,), dtype=bool, min=0.0, max=1.0, mean=0.053),\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m                         'eps_id': np.ndarray((19,), dtype=int64, min=267614943.0, max=267614943.0, mean=267614943.0),\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m                         'infos': np.ndarray((19,), dtype=object, head={}),\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m                         'new_obs': np.ndarray((19, 4), dtype=float32, min=-2.243, max=1.324, mean=-0.074),\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m                         'obs': np.ndarray((19, 4), dtype=float32, min=-2.149, max=1.321, mean=-0.061),\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m                         'prev_actions': np.ndarray((19,), dtype=int64, min=0.0, max=1.0, mean=0.632),\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m                         'prev_rewards': np.ndarray((19,), dtype=float32, min=0.0, max=1.0, mean=0.947),\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m                         'rewards': np.ndarray((19,), dtype=float32, min=1.0, max=1.0, mean=1.0),\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m                         't': np.ndarray((19,), dtype=int64, min=0.0, max=18.0, mean=9.0),\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m                         'unroll_id': np.ndarray((19,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m                         'value_targets': np.ndarray((19,), dtype=float32, min=1.0, max=17.383, mean=9.425),\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m                         'vf_preds': np.ndarray((19,), dtype=float32, min=-0.003, max=0.005, mean=0.001)},\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m               'type': 'SampleBatch'}}\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m 2019-05-18 19:22:07,713\tINFO policy_evaluator.py:475 -- Completed sample batch:\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m { 'data': { 'action_prob': np.ndarray((200,), dtype=float32, min=0.499, max=0.501, mean=0.5),\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m             'actions': np.ndarray((200,), dtype=int64, min=0.0, max=1.0, mean=0.55),\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m             'advantages': np.ndarray((200,), dtype=float32, min=0.995, max=33.103, mean=11.298),\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m             'agent_index': np.ndarray((200,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m             'behaviour_logits': np.ndarray((200, 2), dtype=float32, min=-0.007, max=0.007, mean=0.001),\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m             'dones': np.ndarray((200,), dtype=bool, min=0.0, max=1.0, mean=0.05),\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m             'eps_id': np.ndarray((200,), dtype=int64, min=267614943.0, max=1685907032.0, mean=1210634953.95),\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m             'infos': np.ndarray((200,), dtype=object, head={}),\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m             'new_obs': np.ndarray((200, 4), dtype=float32, min=-2.258, max=1.914, mean=-0.012),\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m             'obs': np.ndarray((200, 4), dtype=float32, min=-2.258, max=1.603, mean=-0.008),\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m             'prev_actions': np.ndarray((200,), dtype=int64, min=0.0, max=1.0, mean=0.525),\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m             'prev_rewards': np.ndarray((200,), dtype=float32, min=0.0, max=1.0, mean=0.945),\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m             'rewards': np.ndarray((200,), dtype=float32, min=1.0, max=1.0, mean=1.0),\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m             't': np.ndarray((200,), dtype=int64, min=0.0, max=39.0, mean=11.35),\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m             'unroll_id': np.ndarray((200,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m             'value_targets': np.ndarray((200,), dtype=float32, min=0.997, max=33.103, mean=11.299),\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m             'vf_preds': np.ndarray((200,), dtype=float32, min=-0.004, max=0.005, mean=0.001)},\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m   'type': 'SampleBatch'}\n",
            "\u001b[2m\u001b[36m(pid=11726)\u001b[0m \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-05-18 19:22:10,333\tINFO multi_gpu_impl.py:146 -- Training on concatenated sample batches:\n",
            "\n",
            "{ 'inputs': [ np.ndarray((4000, 4), dtype=float32, min=-2.671, max=2.54, mean=0.01),\n",
            "              np.ndarray((4000,), dtype=float32, min=0.996, max=51.984, mean=12.926),\n",
            "              np.ndarray((4000,), dtype=float32, min=-1.266, max=4.144, mean=-0.0),\n",
            "              np.ndarray((4000,), dtype=int64, min=0.0, max=1.0, mean=0.5),\n",
            "              np.ndarray((4000, 2), dtype=float32, min=-0.008, max=0.007, mean=-0.0),\n",
            "              np.ndarray((4000,), dtype=float32, min=-0.005, max=0.005, mean=-0.0),\n",
            "              np.ndarray((4000,), dtype=int64, min=0.0, max=1.0, mean=0.477),\n",
            "              np.ndarray((4000,), dtype=float32, min=0.0, max=1.0, mean=0.956)],\n",
            "  'placeholders': [ <tf.Tensor 'default_policy/obs:0' shape=(?, 4) dtype=float32>,\n",
            "                    <tf.Tensor 'default_policy/value_targets:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'default_policy/advantages:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'default_policy/action:0' shape=(?,) dtype=int64>,\n",
            "                    <tf.Tensor 'default_policy/logits:0' shape=(?, 2) dtype=float32>,\n",
            "                    <tf.Tensor 'default_policy/vf_preds:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'default_policy/action_1:0' shape=(?,) dtype=int64>,\n",
            "                    <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>],\n",
            "  'state_inputs': []}\n",
            "\n",
            "2019-05-18 19:22:10,336\tINFO multi_gpu_impl.py:191 -- Divided 4000 rollout sequences, each of length 1, among 3 devices.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "custom_metrics: {}\n",
            "date: 2019-05-18_19-22-15\n",
            "done: false\n",
            "episode_len_mean: 22.977011494252874\n",
            "episode_reward_max: 78.0\n",
            "episode_reward_mean: 22.977011494252874\n",
            "episode_reward_min: 9.0\n",
            "episodes_this_iter: 174\n",
            "episodes_total: 174\n",
            "experiment_id: 9ae62e6c9087415bb982b06d080c2260\n",
            "hostname: 202c4c6687c7\n",
            "info:\n",
            "  grad_time_ms: 4804.961\n",
            "  learner:\n",
            "    default_policy:\n",
            "      cur_kl_coeff: 0.19999995827674866\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 0.6644614934921265\n",
            "      kl: 0.029476119205355644\n",
            "      policy_loss: -0.04188487306237221\n",
            "      total_loss: 176.8184814453125\n",
            "      vf_explained_var: 0.02176438644528389\n",
            "      vf_loss: 176.8544921875\n",
            "  load_time_ms: 138.061\n",
            "  num_steps_sampled: 4000\n",
            "  num_steps_trained: 3906\n",
            "  sample_time_ms: 3111.643\n",
            "  update_time_ms: 1341.804\n",
            "iterations_since_restore: 1\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 125\n",
            "policy_reward_mean: {}\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 0.0887114286492576\n",
            "  mean_inference_ms: 1.1505512324388427\n",
            "  mean_processing_ms: 0.2587060407865904\n",
            "time_since_restore: 9.543073177337646\n",
            "time_this_iter_s: 9.543073177337646\n",
            "time_total_s: 9.543073177337646\n",
            "timestamp: 1558207335\n",
            "timesteps_since_restore: 4000\n",
            "timesteps_this_iter: 4000\n",
            "timesteps_total: 4000\n",
            "training_iteration: 1\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-05-18_19-22-21\n",
            "done: false\n",
            "episode_len_mean: 40.23\n",
            "episode_reward_max: 156.0\n",
            "episode_reward_mean: 40.23\n",
            "episode_reward_min: 10.0\n",
            "episodes_this_iter: 96\n",
            "episodes_total: 270\n",
            "experiment_id: 9ae62e6c9087415bb982b06d080c2260\n",
            "hostname: 202c4c6687c7\n",
            "info:\n",
            "  grad_time_ms: 4184.573\n",
            "  learner:\n",
            "    default_policy:\n",
            "      cur_kl_coeff: 0.30000004172325134\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 0.6190447807312012\n",
            "      kl: 0.01683896780014038\n",
            "      policy_loss: -0.018905755132436752\n",
            "      total_loss: 370.9048156738281\n",
            "      vf_explained_var: 0.01380076538771391\n",
            "      vf_loss: 370.91864013671875\n",
            "  load_time_ms: 69.617\n",
            "  num_steps_sampled: 8000\n",
            "  num_steps_trained: 7812\n",
            "  sample_time_ms: 2951.314\n",
            "  update_time_ms: 673.98\n",
            "iterations_since_restore: 2\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 125\n",
            "policy_reward_mean: {}\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 0.08768772859889658\n",
            "  mean_inference_ms: 1.1003933881127714\n",
            "  mean_processing_ms: 0.2387933555927532\n",
            "time_since_restore: 15.917731046676636\n",
            "time_this_iter_s: 6.374657869338989\n",
            "time_total_s: 15.917731046676636\n",
            "timestamp: 1558207341\n",
            "timesteps_since_restore: 8000\n",
            "timesteps_this_iter: 4000\n",
            "timesteps_total: 8000\n",
            "training_iteration: 2\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHrL98S57uIl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}